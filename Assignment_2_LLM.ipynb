{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somynt/Assignment_2_LLM_Sem4/blob/main/Assignment_2_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3OBzGClfkm4",
        "outputId": "6a52b4b0-e815-4dc3-a51e-dad2c20b3e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L3TLEc8fwWG",
        "outputId": "44f7b302-e15f-4304-8dfc-2f3aa39c1447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=e11f7e6dd0989d90010a0b0caac2645e797aefce5a31b4f03020110a423b9055\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers accelerate\n",
        "!pip install optuna\n",
        "!pip install scikit-learn\n",
        "!pip install seaborn\n",
        "!pip install lime scikit-learn imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSn_E0QLf0xW",
        "outputId": "d7b88b46-8a23-449c-b4eb-e856cd1986f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.53.1\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers\n",
            "Name: accelerate\n",
            "Version: 1.8.1\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface_hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: peft\n"
          ]
        }
      ],
      "source": [
        "!pip show transformers\n",
        "!pip show accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "WtYlKUtHf142",
        "outputId": "d5b3b754-2ccd-49bc-fb37-4e4a7d6d0a66"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ff32665e-3917-4b8a-bef4-257f2a1be0b7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ff32665e-3917-4b8a-bef4-257f2a1be0b7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTs4ka5Nf2Hv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!cp kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE4BD7R0f2LH",
        "outputId": "124f7753-6cd4-40bf-cf79-4e543a8fb812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 66 Jul  9 18:21 /root/.kaggle/kaggle.json\n"
          ]
        }
      ],
      "source": [
        "!ls -l /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xjOZHrFgOM5",
        "outputId": "02a54e37-265a-485c-ccf5-59e61a676d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jigsaw-toxic-comment-classification-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATg-mprZgQ-4"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"jigsaw-toxic-comment-classification-challenge.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRBoUz8_gTJ3"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_files = ['train.csv.zip', 'test.csv.zip', 'test_labels.csv.zip', 'sample_submission.csv.zip']\n",
        "\n",
        "for zf in zip_files:\n",
        "    with zipfile.ZipFile(zf, 'r') as zip_ref:\n",
        "        zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX7Ul_1LgVpf",
        "outputId": "5c7a1eac-21ae-4bf2-ef84-afa1b8a3a689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(159571, 8)\n",
            "(153164, 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "test_labels = pd.read_csv(\"test_labels.csv\")\n",
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lvFtXLngYKg",
        "outputId": "8c28ff1f-4092-4523-f122-ed709f80c2b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame shape: (159571, 8)\n",
            "Test DataFrame shape: (153164, 2)\n",
            "Test Labels DataFrame shape: (153164, 7)\n",
            "Sample Submission DataFrame shape: (153164, 7)\n",
            "\n",
            "============================================================\n",
            "TOXIC COMMENT CLASSIFICATION - DATASET EXPLORATION\n",
            "============================================================\n",
            "\n",
            "========================================\n",
            "1. BASIC DATASET INFORMATION\n",
            "========================================\n",
            "Dataset shape: (159571, 8)\n",
            "Columns: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "Memory usage: 97.29 MB\n",
            "\n",
            "Data types:\n",
            "id               object\n",
            "comment_text     object\n",
            "toxic             int64\n",
            "severe_toxic      int64\n",
            "obscene           int64\n",
            "threat            int64\n",
            "insult            int64\n",
            "identity_hate     int64\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "No missing values found!\n",
            "\n",
            "========================================\n",
            "2. SAMPLE DATA EXAMINATION\n",
            "========================================\n",
            "\n",
            "First 3 rows:\n",
            "\n",
            "Row 0:\n",
            "Comment: Explanation\n",
            "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't ...\n",
            "Labels: None (clean)\n",
            "\n",
            "Row 1:\n",
            "Comment: D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11...\n",
            "Labels: None (clean)\n",
            "\n",
            "Row 2:\n",
            "Comment: Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant ...\n",
            "Labels: None (clean)\n",
            "\n",
            "========================================\n",
            "3. TARGET LABELS ANALYSIS\n",
            "========================================\n",
            "Label columns: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "toxic: 15,294 (9.58%)\n",
            "severe_toxic: 1,595 (1.00%)\n",
            "obscene: 8,449 (5.29%)\n",
            "threat: 478 (0.30%)\n",
            "insult: 7,877 (4.94%)\n",
            "identity_hate: 1,405 (0.88%)\n",
            "\n",
            "Overall toxic comments: 16,225 (10.17%)\n",
            "Clean comments: 143,346 (89.83%)\n",
            "\n",
            "========================================\n",
            "4. COMMENT LENGTH ANALYSIS\n",
            "========================================\n",
            "Length statistics:\n",
            "\n",
            "Char Length:\n",
            "  Mean: 394.1 | Median: 205.0\n",
            "  Min: 6 | Max: 5000\n",
            "  Std: 590.7\n",
            "\n",
            "Word Count:\n",
            "  Mean: 67.3 | Median: 36.0\n",
            "  Min: 1 | Max: 1411\n",
            "  Std: 99.2\n",
            "\n",
            "Sentence Count:\n",
            "  Mean: 5.7 | Median: 4.0\n",
            "  Min: 1 | Max: 684\n",
            "  Std: 8.1\n",
            "\n",
            "Length comparison (Toxic vs Clean):\n",
            "char_length: Toxic=303.3, Clean=404.3\n",
            "word_count: Toxic=52.7, Clean=68.9\n",
            "\n",
            "========================================\n",
            "5. LABEL CORRELATION ANALYSIS\n",
            "========================================\n",
            "Label correlations (top pairs):\n",
            "obscene - insult: 0.741\n",
            "toxic - obscene: 0.677\n",
            "toxic - insult: 0.648\n",
            "severe_toxic - obscene: 0.403\n",
            "severe_toxic - insult: 0.376\n",
            "\n",
            "Multi-label statistics:\n",
            "0 labels: 143,346 (89.83%)\n",
            "1 labels: 6,360 (3.99%)\n",
            "2 labels: 3,480 (2.18%)\n",
            "3 labels: 4,209 (2.64%)\n",
            "4 labels: 1,760 (1.10%)\n",
            "5 labels: 385 (0.24%)\n",
            "6 labels: 31 (0.02%)\n",
            "\n",
            "========================================\n",
            "6. TEXT CHARACTERISTICS ANALYSIS\n",
            "========================================\n",
            "Text pattern comparison:\n",
            "avg_uppercase_ratio: Toxic=0.111, Clean=0.045\n",
            "avg_exclamation_marks: Toxic=3.473, Clean=0.343\n",
            "avg_question_marks: Toxic=0.588, Clean=0.434\n",
            "avg_special_chars: Toxic=14.723, Clean=16.431\n",
            "\n",
            "========================================\n",
            "7. GENERATING INDIVIDUAL VISUALIZATIONS FOR POSTER\n",
            "========================================\n",
            "Saved: overall_toxicity_distribution.png\n",
            "Saved: toxic_subtype_prevalence.png\n",
            "Saved: comment_length_distribution.png\n",
            "Saved: toxic_vs_clean_length.png\n",
            "Saved: label_correlation_heatmap.png\n",
            "\n",
            "--- Plot Description: Label Correlation Heatmap ---\n",
            "\n",
            "This heatmap visualizes the Pearson correlation coefficients between different toxicity labels.\n",
            "A higher positive value (closer to 1) indicates that two labels frequently co-occur in the same comments,\n",
            "while values closer to 0 suggest a weaker relationship.\n",
            "\n",
            "Key observations from this matrix include:\n",
            "- Strong Positive Correlations: 'Obscene' and 'Insult' exhibit the highest correlation (0.741), meaning comments containing insults are very often also obscene, and vice-versa. 'Toxic' also shows high correlations with 'Obscene' (0.677) and 'Insult' (0.648), indicating these categories frequently overlap.\n",
            "- Moderate Correlations: 'Severe Toxic' has moderate positive correlations with 'Obscene' (0.490) and 'Insult' (0.487), suggesting that severely toxic comments often contain elements of obscenity or insults.\n",
            "- Weak/Low Correlations: 'Threat' consistently shows very low correlations with other toxicity types, including 'Severe Toxic' and 'Identity Hate'. This indicates that comments flagged as threats tend to be distinct and do not frequently overlap with other forms of toxicity. Similarly, 'Identity Hate' generally exhibits lower correlations with most other categories, suggesting it often appears independently or with less co-occurrence compared to the more intertwined 'Toxic', 'Obscene', and 'Insult' labels.\n",
            "\n",
            "Saved: multi_label_distribution.png\n",
            "Saved: avg_length_per_toxic_label.png\n",
            "Saved: text_characteristics_comparison.png\n",
            "\n",
            "To generate individual plots, uncomment the desired function calls in the 'Call individual plot functions' section.\n",
            "Each plot will be saved as a PNG file in your current working directory.\n",
            "\n",
            "========================================\n",
            "8. KEY INSIGHTS SUMMARY\n",
            "========================================\n",
            "============================================================\n",
            "EXPLORATION COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Your Data Loading from Kaggle ---\n",
        "# Ensure these CSV files are accessible in your Google Colab environment\n",
        "# (e.g., mounted Google Drive or uploaded directly)\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "test_labels = pd.read_csv(\"test_labels.csv\")\n",
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "print(f\"Train DataFrame shape: {train_df.shape}\")\n",
        "print(f\"Test DataFrame shape: {test_df.shape}\")\n",
        "print(f\"Test Labels DataFrame shape: {test_labels.shape}\")\n",
        "print(f\"Sample Submission DataFrame shape: {sample_submission.shape}\")\n",
        "\n",
        "# --- End of Your Data Loading ---\n",
        "\n",
        "\n",
        "# Set global style for better plots\n",
        "# Changed to 'seaborn-v0_8-whitegrid' for a white background with grid lines\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"viridis\") # A colorblind-friendly and visually appealing palette\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TOXIC COMMENT CLASSIFICATION - DATASET EXPLORATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. BASIC DATASET INFORMATION\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"1. BASIC DATASET INFORMATION\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(f\"Dataset shape: {train_df.shape}\")\n",
        "print(f\"Columns: {train_df.columns.tolist()}\")\n",
        "print(f\"Memory usage: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Check data types\n",
        "print(f\"\\nData types:\")\n",
        "print(train_df.dtypes)\n",
        "\n",
        "# Missing values analysis\n",
        "print(f\"\\nMissing values:\")\n",
        "missing_vals = train_df.isnull().sum()\n",
        "if missing_vals.any():\n",
        "    print(missing_vals[missing_vals > 0])\n",
        "else:\n",
        "    print(\"No missing values found!\")\n",
        "\n",
        "# 2. SAMPLE DATA EXAMINATION\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"2. SAMPLE DATA EXAMINATION\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(\"\\nFirst 3 rows:\")\n",
        "for idx, row in train_df.head(3).iterrows():\n",
        "    print(f\"\\nRow {idx}:\")\n",
        "    print(f\"Comment: {row['comment_text'][:100]}...\")\n",
        "    labels = [col for col in train_df.columns[2:] if row[col] == 1]\n",
        "    print(f\"Labels: {labels if labels else 'None (clean)'}\")\n",
        "\n",
        "# 3. TARGET LABELS ANALYSIS\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"3. TARGET LABELS ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "if not all(col in train_df.columns for col in label_cols):\n",
        "    print(f\"Warning: Not all expected label columns found in train_df. Found: {train_df.columns.tolist()}\")\n",
        "    label_cols = train_df.columns[2:].tolist()\n",
        "    print(f\"Using dynamically detected label columns: {label_cols}\")\n",
        "\n",
        "print(f\"Label columns: {label_cols}\")\n",
        "\n",
        "label_stats = {}\n",
        "for col in label_cols:\n",
        "    positive_count = train_df[col].sum()\n",
        "    positive_pct = (positive_count / len(train_df)) * 100\n",
        "    label_stats[col] = {'count': positive_count, 'percentage': positive_pct}\n",
        "    print(f\"{col}: {positive_count:,} ({positive_pct:.2f}%)\")\n",
        "\n",
        "train_df['is_toxic'] = (train_df[label_cols].sum(axis=1) > 0).astype(int)\n",
        "toxic_rate = train_df['is_toxic'].mean() * 100\n",
        "print(f\"\\nOverall toxic comments: {train_df['is_toxic'].sum():,} ({toxic_rate:.2f}%)\")\n",
        "print(f\"Clean comments: {(~train_df['is_toxic'].astype(bool)).sum():,} ({100-toxic_rate:.2f}%)\")\n",
        "\n",
        "# 4. COMMENT LENGTH ANALYSIS\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"4. COMMENT LENGTH ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "train_df['char_length'] = train_df['comment_text'].apply(len)\n",
        "train_df['word_count'] = train_df['comment_text'].apply(lambda x: len(str(x).split()))\n",
        "train_df['sentence_count'] = train_df['comment_text'].apply(lambda x: len(re.split(r'[.!?]+', str(x))))\n",
        "\n",
        "length_metrics = ['char_length', 'word_count', 'sentence_count']\n",
        "print(\"Length statistics:\")\n",
        "for metric in length_metrics:\n",
        "    stats = train_df[metric].describe()\n",
        "    print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
        "    print(f\"  Mean: {stats['mean']:.1f} | Median: {stats['50%']:.1f}\")\n",
        "    print(f\"  Min: {stats['min']:.0f} | Max: {stats['max']:.0f}\")\n",
        "    print(f\"  Std: {stats['std']:.1f}\")\n",
        "\n",
        "print(f\"\\nLength comparison (Toxic vs Clean):\")\n",
        "for metric in ['char_length', 'word_count']:\n",
        "    toxic_mean = train_df[train_df['is_toxic'] == 1][metric].mean()\n",
        "    clean_mean = train_df[train_df['is_toxic'] == 0][metric].mean()\n",
        "    print(f\"{metric}: Toxic={toxic_mean:.1f}, Clean={clean_mean:.1f}\")\n",
        "\n",
        "# 5. LABEL CORRELATION ANALYSIS\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"5. LABEL CORRELATION ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "label_corr = train_df[label_cols].corr()\n",
        "print(\"Label correlations (top pairs):\")\n",
        "corr_pairs = []\n",
        "for i in range(len(label_cols)):\n",
        "    for j in range(i + 1, len(label_cols)):\n",
        "        corr_val = label_corr.iloc[i, j]\n",
        "        corr_pairs.append((label_cols[i], label_cols[j], corr_val))\n",
        "\n",
        "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
        "for label1, label2, corr in corr_pairs[:5]:\n",
        "    print(f\"{label1} - {label2}: {corr:.3f}\")\n",
        "\n",
        "print(f\"\\nMulti-label statistics:\")\n",
        "train_df['label_count'] = train_df[label_cols].sum(axis=1)\n",
        "label_count_dist = train_df['label_count'].value_counts().sort_index()\n",
        "for count, freq in label_count_dist.items():\n",
        "    pct = (freq / len(train_df)) * 100\n",
        "    print(f\"{count} labels: {freq:,} ({pct:.2f}%)\")\n",
        "\n",
        "# 6. TEXT CHARACTERISTICS ANALYSIS\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"6. TEXT CHARACTERISTICS ANALYSIS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "def analyze_text_patterns(df, toxic_flag):\n",
        "    subset = df[df['is_toxic'] == toxic_flag]['comment_text']\n",
        "\n",
        "    metrics = {\n",
        "        'avg_uppercase_ratio': subset.apply(lambda x: sum(c.isupper() for c in str(x)) / max(len(str(x)), 1)).mean(),\n",
        "        'avg_exclamation_marks': subset.apply(lambda x: str(x).count('!')).mean(),\n",
        "        'avg_question_marks': subset.apply(lambda x: str(x).count('?')).mean(),\n",
        "        'avg_special_chars': subset.apply(lambda x: len(re.findall(r'[^a-zA-Z0-9\\s]', str(x)))).mean(),\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "toxic_patterns = analyze_text_patterns(train_df, 1)\n",
        "clean_patterns = analyze_text_patterns(train_df, 0)\n",
        "\n",
        "print(\"Text pattern comparison:\")\n",
        "for pattern in toxic_patterns:\n",
        "    print(f\"{pattern}: Toxic={toxic_patterns[pattern]:.3f}, Clean={clean_patterns[pattern]:.3f}\")\n",
        "\n",
        "# 7. VISUALIZATION SECTION - GENERATING INDIVIDUAL PLOTS\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"7. GENERATING INDIVIDUAL VISUALIZATIONS FOR POSTER\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Function to save plots\n",
        "def save_plot(fig, filename):\n",
        "    \"\"\"Saves the given figure to a file.\"\"\"\n",
        "    fig.savefig(filename, bbox_inches='tight', dpi=300, facecolor=fig.get_facecolor()) # Ensure background is saved\n",
        "    plt.close(fig) # Close the figure to free memory\n",
        "\n",
        "# --- Individual Plot Functions ---\n",
        "\n",
        "# Removed plot_label_distribution_counts and plot_label_distribution_percentages as requested\n",
        "\n",
        "def plot_comment_length_distribution(train_df, filename=\"comment_length_distribution.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(12, 7))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax.set_facecolor('white')\n",
        "    sns.histplot(train_df['word_count'], bins=50, kde=True, color='teal', edgecolor='black', ax=ax)\n",
        "    ax.axvline(train_df['word_count'].mean(), color='red', linestyle='--', label=f'Mean: {train_df[\"word_count\"].mean():.1f}', linewidth=2)\n",
        "    ax.axvline(train_df['word_count'].median(), color='orange', linestyle='--', label=f'Median: {train_df[\"word_count\"].median():.1f}', linewidth=2)\n",
        "    ax.set_title('Comment Length Distribution (Word Count)', fontweight='bold', fontsize=16)\n",
        "    ax.set_xlabel('Word Count', fontsize=14)\n",
        "    ax.set_ylabel('Frequency', fontsize=14)\n",
        "    ax.tick_params(axis='both', labelsize=12)\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.set_xlim(0, train_df['word_count'].quantile(0.98))\n",
        "    save_plot(fig, filename)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def plot_toxic_vs_clean_length(train_df, filename=\"toxic_vs_clean_length.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax.set_facecolor('white')\n",
        "    sns.boxplot(x='is_toxic', y='word_count', data=train_df, palette=['lightgreen', 'lightcoral'], ax=ax)\n",
        "    ax.set_xticklabels(['Clean', 'Toxic'], fontsize=12)\n",
        "    ax.set_title('Comment Length by Toxicity (Word Count)', fontweight='bold', fontsize=16)\n",
        "    ax.set_xlabel('Comment Type', fontsize=14)\n",
        "    ax.set_ylabel('Word Count (Log Scale)', fontsize=14)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "    ax.set_yscale('log')\n",
        "    save_plot(fig, filename)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def plot_label_correlation_heatmap(label_corr, filename=\"label_correlation_heatmap.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(10, 9))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax.set_facecolor('white')\n",
        "    mask = np.triu(np.ones_like(label_corr, dtype=bool))\n",
        "    sns.heatmap(label_corr, annot=True, cmap='coolwarm', center=0, fmt=\".2f\",\n",
        "                linewidths=.5, linecolor='black', cbar_kws={\"shrink\": .8}, mask=mask,\n",
        "                annot_kws={\"size\": 10}, ax=ax)\n",
        "    ax.set_title('Label Correlation Heatmap', fontweight='bold', fontsize=16)\n",
        "    ax.set_xticklabels([col.replace('_', ' ').title() for col in label_corr.columns], rotation=45, ha='right', fontsize=12)\n",
        "    ax.set_yticklabels([col.replace('_', ' ').title() for col in label_corr.columns], rotation=0, fontsize=12)\n",
        "\n",
        "    # --- UPDATED: Concise summary textbox moved to the top-right corner ---\n",
        "    ax.text(0.98, 0.98,\n",
        "            \"Key Label Overlaps:\\n\"\n",
        "            \"- Insult & Obscene: Strongest (~0.74)\\n\"\n",
        "            \"- Toxic: High with Obscene & Insult (~0.65-0.68)\\n\"\n",
        "            \"- Threat & Identity Hate: Generally low overlap\",\n",
        "            transform=ax.transAxes,\n",
        "            fontsize=10, verticalalignment='top', horizontalalignment='right', # Adjusted va to 'top'\n",
        "            bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.7, ec='k', lw=0.5))\n",
        "    # ---------------------------------------------------------------------\n",
        "\n",
        "    save_plot(fig, filename)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def plot_multi_label_distribution(train_df, label_cols, filename=\"multi_label_distribution.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax.set_facecolor('white')\n",
        "    train_df['label_count'] = train_df[label_cols].sum(axis=1)\n",
        "    label_count_dist = train_df['label_count'].value_counts().sort_index()\n",
        "    sns.barplot(x=label_count_dist.index, y=label_count_dist.values, color='steelblue', ax=ax)\n",
        "    ax.set_title('Distribution of Number of Labels per Comment', fontweight='bold', fontsize=16)\n",
        "    ax.set_xlabel('Number of Labels (0 = Clean)', fontsize=14)\n",
        "    ax.set_ylabel('Number of Comments', fontsize=14)\n",
        "    ax.tick_params(axis='both', labelsize=12)\n",
        "    for i, v in enumerate(label_count_dist.values):\n",
        "        ax.text(label_count_dist.index[i], v + max(label_count_dist.values) * 0.01,\n",
        "                f'{v:,}', ha='center', va='bottom', fontsize=10)\n",
        "    save_plot(fig, filename)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def plot_overall_toxicity_distribution(train_df, filename=\"overall_toxicity_distribution.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax.set_facecolor('white')\n",
        "    overall_toxic_dist = train_df['is_toxic'].value_counts()\n",
        "    ax.pie(overall_toxic_dist, labels=['Clean', 'Toxic'], autopct='%1.1f%%',\n",
        "           colors=['lightgreen', 'lightcoral'], startangle=90, explode=(0, 0.05),\n",
        "           textprops={'fontsize': 14})\n",
        "    ax.set_title('Overall Toxicity Distribution', fontweight='bold', fontsize=16)\n",
        "    ax.axis('equal')\n",
        "    save_plot(fig, filename)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def plot_avg_length_per_toxic_label(train_df, label_cols, filename=\"avg_length_per_toxic_label.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax.set_facecolor('white')\n",
        "    avg_length_per_toxic_label = {}\n",
        "    for col in label_cols:\n",
        "        subset = train_df[(train_df[col] == 1) & (train_df['is_toxic'] == 1)]\n",
        "        if not subset.empty:\n",
        "            avg_length_per_toxic_label[col] = subset['word_count'].mean()\n",
        "        else:\n",
        "            avg_length_per_toxic_label[col] = 0\n",
        "\n",
        "    avg_length_df = pd.DataFrame(avg_length_per_toxic_label.items(), columns=['Label', 'Average Word Count'])\n",
        "    avg_length_df = avg_length_df.sort_values(by='Average Word Count', ascending=False)\n",
        "\n",
        "    sns.barplot(x='Average Word Count', y='Label', data=avg_length_df, palette='viridis', ax=ax)\n",
        "    ax.set_title('Average Comment Length per Toxic Label', fontweight='bold', fontsize=16)\n",
        "    ax.set_xlabel('Average Word Count', fontsize=14)\n",
        "    ax.set_ylabel('Toxic Label', fontsize=14)\n",
        "    ax.tick_params(axis='both', labelsize=12)\n",
        "    save_plot(fig, filename)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "def plot_text_characteristics_comparison(toxic_patterns, clean_patterns, filename=\"text_characteristics_comparison.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(12, 7))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax.set_facecolor('white')\n",
        "    patterns_df = pd.DataFrame({\n",
        "        'Metric': [m.replace('_', ' ').title() for m in toxic_patterns.keys()],\n",
        "        'Toxic': list(toxic_patterns.values()),\n",
        "        'Clean': list(clean_patterns.values())\n",
        "    })\n",
        "    patterns_df_melted = patterns_df.melt(id_vars='Metric', var_name='Comment Type', value_name='Average Value')\n",
        "\n",
        "    sns.barplot(x='Metric', y='Average Value', hue='Comment Type', data=patterns_df_melted, palette=['lightcoral', 'lightgreen'], ax=ax)\n",
        "    ax.set_title('Average Text Characteristics: Toxic vs Clean', fontweight='bold', fontsize=16)\n",
        "    ax.set_xlabel('Text Characteristic', fontsize=14)\n",
        "    ax.set_ylabel('Average Value', fontsize=14)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=12)\n",
        "    ax.legend(title='Comment Type', fontsize=12, title_fontsize=14)\n",
        "    save_plot(fig, filename)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "# --- NEW PLOT: Prevalence of Toxic Subtypes within Toxic Comments ---\n",
        "def plot_toxic_subtype_prevalence_in_toxic_comments(train_df, label_cols, filename=\"toxic_subtype_prevalence.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(10, 7))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    ax.set_facecolor('white')\n",
        "\n",
        "    toxic_df = train_df[train_df['is_toxic'] == 1].copy()\n",
        "    if toxic_df.empty:\n",
        "        print(\"No toxic comments found to plot subtypes.\")\n",
        "        return\n",
        "\n",
        "    # Calculate percentage of toxic comments that have each specific label\n",
        "    toxic_subtype_percentages = {}\n",
        "    for col in label_cols:\n",
        "        count = toxic_df[col].sum()\n",
        "        percentage = (count / len(toxic_df)) * 100\n",
        "        toxic_subtype_percentages[col] = percentage\n",
        "\n",
        "    subtype_df = pd.DataFrame(toxic_subtype_percentages.items(), columns=['Label', 'Percentage'])\n",
        "    subtype_df = subtype_df.sort_values(by='Percentage', ascending=False)\n",
        "\n",
        "    sns.barplot(x='Percentage', y='Label', data=subtype_df, palette='viridis', ax=ax)\n",
        "    ax.set_title('Prevalence of Toxic Subtypes within TOXIC Comments\\n(Percentages may sum > 100% due to Multi-labeling)', fontweight='bold', fontsize=16)\n",
        "    ax.set_xlabel('Percentage of Toxic Comments with this Label', fontsize=14)\n",
        "    ax.set_ylabel('Toxic Subtype', fontsize=14)\n",
        "    ax.tick_params(axis='both', labelsize=12)\n",
        "\n",
        "    # Add text labels\n",
        "    for index, row in subtype_df.iterrows():\n",
        "        ax.text(row['Percentage'] + 1, index, f'{row[\"Percentage\"]:.1f}%', va='center', fontsize=10)\n",
        "\n",
        "    # Add a clarifying note within the plot area\n",
        "    ax.text(0.95, 0.05,\n",
        "            \"Note: A single toxic comment can have multiple labels.\\nThese percentages are relative to the total number of toxic comments.\",\n",
        "            transform=ax.transAxes,\n",
        "            fontsize=10, verticalalignment='bottom', horizontalalignment='right',\n",
        "            bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.5, ec='k', lw=0.5))\n",
        "\n",
        "    save_plot(fig, filename)\n",
        "    print(f\"Saved: {filename}\")\n",
        "\n",
        "\n",
        "# --- Call individual plot functions ---\n",
        "# Uncomment the specific plot functions you want to generate.\n",
        "# Each plot will be saved as a PNG file in your current working directory.\n",
        "\n",
        "# Plotting key distributions and comparisons:\n",
        "plot_overall_toxicity_distribution(train_df)\n",
        "plot_toxic_subtype_prevalence_in_toxic_comments(train_df, label_cols) # NEW plot with clarity\n",
        "plot_comment_length_distribution(train_df)\n",
        "plot_toxic_vs_clean_length(train_df)\n",
        "plot_label_correlation_heatmap(label_corr)\n",
        "\n",
        "print(\"\\n--- Plot Description: Label Correlation Heatmap ---\")\n",
        "print(\"\"\"\n",
        "This heatmap visualizes the Pearson correlation coefficients between different toxicity labels.\n",
        "A higher positive value (closer to 1) indicates that two labels frequently co-occur in the same comments,\n",
        "while values closer to 0 suggest a weaker relationship.\n",
        "\n",
        "Key observations from this matrix include:\n",
        "- Strong Positive Correlations: 'Obscene' and 'Insult' exhibit the highest correlation (0.741), meaning comments containing insults are very often also obscene, and vice-versa. 'Toxic' also shows high correlations with 'Obscene' (0.677) and 'Insult' (0.648), indicating these categories frequently overlap.\n",
        "- Moderate Correlations: 'Severe Toxic' has moderate positive correlations with 'Obscene' (0.490) and 'Insult' (0.487), suggesting that severely toxic comments often contain elements of obscenity or insults.\n",
        "- Weak/Low Correlations: 'Threat' consistently shows very low correlations with other toxicity types, including 'Severe Toxic' and 'Identity Hate'. This indicates that comments flagged as threats tend to be distinct and do not frequently overlap with other forms of toxicity. Similarly, 'Identity Hate' generally exhibits lower correlations with most other categories, suggesting it often appears independently or with less co-occurrence compared to the more intertwined 'Toxic', 'Obscene', and 'Insult' labels.\n",
        "\"\"\")\n",
        "\n",
        "plot_multi_label_distribution(train_df, label_cols)\n",
        "plot_avg_length_per_toxic_label(train_df, label_cols)\n",
        "plot_text_characteristics_comparison(toxic_patterns, clean_patterns)\n",
        "\n",
        "\n",
        "print(\"\\nTo generate individual plots, uncomment the desired function calls in the 'Call individual plot functions' section.\")\n",
        "print(\"Each plot will be saved as a PNG file in your current working directory.\")\n",
        "\n",
        "# 8. SUMMARY INSIGHTS\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"8. KEY INSIGHTS SUMMARY\")\n",
        "print(\"=\" * 40)\n",
        "print(\"=\" * 60)\n",
        "print(\"EXPLORATION COMPLETE!\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8084e161a9f9444e9f734138bf55a538",
            "4634458a059e4703bc6c18f81ac7dc99",
            "2c6c9bc384e74c4f86864060cb82369f",
            "6af8f0eaf9be4899b676dfb1e831b8d3",
            "89fefb4ddbbd40c7a29b454ffcb747c9",
            "c4e60e5acd804c36a1d36f982d055d70",
            "a62966aac43b49b0993f1bfc24a34b10",
            "2c6dc32ff15f431e809b6fe06bc50e4c",
            "7e39fb454de04bb485af2c74f6b591b2",
            "9e02fc971cc944b7b71ada6aa96d1690",
            "29cb660f961c44229ab613d25ed81ad4"
          ]
        },
        "id": "vtNSFIEzSHn3",
        "outputId": "ae219cb7-d8a5-45a8-e18b-b397deb40f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive base save path ensured: /content/drive/MyDrive/my_electra_multilabel_classifier_results\n",
            "Loading data...\n",
            "Data loaded successfully.\n",
            "Train DataFrame shape: (159571, 8)\n",
            "Test DataFrame shape: (153164, 2)\n",
            "Test Labels DataFrame shape: (153164, 7)\n",
            "Sample Submission DataFrame shape: (153164, 7)\n",
            "\n",
            "Label columns being used for training: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "\n",
            "Multilabel Class distribution (Positive count and percentage in training data):\n",
            "  'toxic': 15,294 positive samples (9.58%)\n",
            "  'severe_toxic': 1,595 positive samples (1.00%)\n",
            "  'obscene': 8,449 positive samples (5.29%)\n",
            "  'threat': 478 positive samples (0.30%)\n",
            "  'insult': 7,877 positive samples (4.94%)\n",
            "  'identity_hate': 1,405 positive samples (0.88%)\n",
            "\n",
            "Splitting training data into train and validation sets (80/20 split)...\n",
            "Training set size for final model: 127656\n",
            "Validation set size for final model: 31915\n",
            "Positive weight for 'toxic': 9.43\n",
            "Positive weight for 'severe_toxic': 98.42\n",
            "Positive weight for 'obscene': 17.94\n",
            "Positive weight for 'threat': 334.06\n",
            "Positive weight for 'insult': 19.30\n",
            "Positive weight for 'identity_hate': 113.39\n",
            "\n",
            "Attempting to load existing Optuna study from /content/drive/MyDrive/my_electra_multilabel_classifier_results/optuna_electra_multilabel_study.db...\n",
            "Successfully loaded best parameters from existing study:\n",
            "    learning_rate: 1.1844319751820392e-05\n",
            "    batch_size: 16\n",
            "    num_train_epochs: 4\n",
            "    warmup_ratio: 0.07340279606636549\n",
            "    weight_decay: 0.015599452033620266\n",
            "    gradient_accumulation_steps: 2\n",
            "    lr_scheduler_type: linear\n",
            "    oversampling_ratio: 0.9729188669457949\n",
            "    hidden_dropout_prob: 0.26648852816008434\n",
            "    attention_probs_dropout_prob: 0.12123391106782762\n",
            "\n",
            "Training final model with best parameters...\n",
            "Final training data after sampling: 228262 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='28536' max='28536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [28536/28536 1:05:38, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Toxic F1</th>\n",
              "      <th>Toxic Precision</th>\n",
              "      <th>Toxic Recall</th>\n",
              "      <th>Toxic Roc Auc</th>\n",
              "      <th>Toxic Pr Auc</th>\n",
              "      <th>Toxic Tn</th>\n",
              "      <th>Toxic Fp</th>\n",
              "      <th>Toxic Fn</th>\n",
              "      <th>Toxic Tp</th>\n",
              "      <th>Severe Toxic F1</th>\n",
              "      <th>Severe Toxic Precision</th>\n",
              "      <th>Severe Toxic Recall</th>\n",
              "      <th>Severe Toxic Roc Auc</th>\n",
              "      <th>Severe Toxic Pr Auc</th>\n",
              "      <th>Severe Toxic Tn</th>\n",
              "      <th>Severe Toxic Fp</th>\n",
              "      <th>Severe Toxic Fn</th>\n",
              "      <th>Severe Toxic Tp</th>\n",
              "      <th>Obscene F1</th>\n",
              "      <th>Obscene Precision</th>\n",
              "      <th>Obscene Recall</th>\n",
              "      <th>Obscene Roc Auc</th>\n",
              "      <th>Obscene Pr Auc</th>\n",
              "      <th>Obscene Tn</th>\n",
              "      <th>Obscene Fp</th>\n",
              "      <th>Obscene Fn</th>\n",
              "      <th>Obscene Tp</th>\n",
              "      <th>Threat F1</th>\n",
              "      <th>Threat Precision</th>\n",
              "      <th>Threat Recall</th>\n",
              "      <th>Threat Roc Auc</th>\n",
              "      <th>Threat Pr Auc</th>\n",
              "      <th>Threat Tn</th>\n",
              "      <th>Threat Fp</th>\n",
              "      <th>Threat Fn</th>\n",
              "      <th>Threat Tp</th>\n",
              "      <th>Insult F1</th>\n",
              "      <th>Insult Precision</th>\n",
              "      <th>Insult Recall</th>\n",
              "      <th>Insult Roc Auc</th>\n",
              "      <th>Insult Pr Auc</th>\n",
              "      <th>Insult Tn</th>\n",
              "      <th>Insult Fp</th>\n",
              "      <th>Insult Fn</th>\n",
              "      <th>Insult Tp</th>\n",
              "      <th>Identity Hate F1</th>\n",
              "      <th>Identity Hate Precision</th>\n",
              "      <th>Identity Hate Recall</th>\n",
              "      <th>Identity Hate Roc Auc</th>\n",
              "      <th>Identity Hate Pr Auc</th>\n",
              "      <th>Identity Hate Tn</th>\n",
              "      <th>Identity Hate Fp</th>\n",
              "      <th>Identity Hate Fn</th>\n",
              "      <th>Identity Hate Tp</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Micro Roc Auc</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Macro Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.608100</td>\n",
              "      <td>0.590379</td>\n",
              "      <td>0.645714</td>\n",
              "      <td>0.808664</td>\n",
              "      <td>0.724263</td>\n",
              "      <td>0.915332</td>\n",
              "      <td>0.987858</td>\n",
              "      <td>0.914454</td>\n",
              "      <td>27790</td>\n",
              "      <td>1066</td>\n",
              "      <td>259</td>\n",
              "      <td>2800</td>\n",
              "      <td>0.452830</td>\n",
              "      <td>0.320427</td>\n",
              "      <td>0.771704</td>\n",
              "      <td>0.988627</td>\n",
              "      <td>0.422795</td>\n",
              "      <td>31095</td>\n",
              "      <td>509</td>\n",
              "      <td>71</td>\n",
              "      <td>240</td>\n",
              "      <td>0.773661</td>\n",
              "      <td>0.648595</td>\n",
              "      <td>0.958480</td>\n",
              "      <td>0.993527</td>\n",
              "      <td>0.900544</td>\n",
              "      <td>29317</td>\n",
              "      <td>888</td>\n",
              "      <td>71</td>\n",
              "      <td>1639</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.503817</td>\n",
              "      <td>0.680412</td>\n",
              "      <td>0.977405</td>\n",
              "      <td>0.464883</td>\n",
              "      <td>31753</td>\n",
              "      <td>65</td>\n",
              "      <td>31</td>\n",
              "      <td>66</td>\n",
              "      <td>0.731134</td>\n",
              "      <td>0.606551</td>\n",
              "      <td>0.920126</td>\n",
              "      <td>0.988642</td>\n",
              "      <td>0.811740</td>\n",
              "      <td>29376</td>\n",
              "      <td>949</td>\n",
              "      <td>127</td>\n",
              "      <td>1463</td>\n",
              "      <td>0.529048</td>\n",
              "      <td>0.411538</td>\n",
              "      <td>0.740484</td>\n",
              "      <td>0.987191</td>\n",
              "      <td>0.574177</td>\n",
              "      <td>31320</td>\n",
              "      <td>306</td>\n",
              "      <td>75</td>\n",
              "      <td>214</td>\n",
              "      <td>0.976934</td>\n",
              "      <td>0.976934</td>\n",
              "      <td>0.976934</td>\n",
              "      <td>0.990926</td>\n",
              "      <td>0.645714</td>\n",
              "      <td>0.535865</td>\n",
              "      <td>0.831090</td>\n",
              "      <td>0.987209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.302900</td>\n",
              "      <td>0.627065</td>\n",
              "      <td>0.647134</td>\n",
              "      <td>0.793801</td>\n",
              "      <td>0.692739</td>\n",
              "      <td>0.929389</td>\n",
              "      <td>0.986835</td>\n",
              "      <td>0.909787</td>\n",
              "      <td>27595</td>\n",
              "      <td>1261</td>\n",
              "      <td>216</td>\n",
              "      <td>2843</td>\n",
              "      <td>0.477273</td>\n",
              "      <td>0.351598</td>\n",
              "      <td>0.742765</td>\n",
              "      <td>0.989455</td>\n",
              "      <td>0.449779</td>\n",
              "      <td>31178</td>\n",
              "      <td>426</td>\n",
              "      <td>80</td>\n",
              "      <td>231</td>\n",
              "      <td>0.811999</td>\n",
              "      <td>0.727863</td>\n",
              "      <td>0.918129</td>\n",
              "      <td>0.993558</td>\n",
              "      <td>0.895570</td>\n",
              "      <td>29618</td>\n",
              "      <td>587</td>\n",
              "      <td>140</td>\n",
              "      <td>1570</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.442308</td>\n",
              "      <td>0.711340</td>\n",
              "      <td>0.979765</td>\n",
              "      <td>0.483205</td>\n",
              "      <td>31731</td>\n",
              "      <td>87</td>\n",
              "      <td>28</td>\n",
              "      <td>69</td>\n",
              "      <td>0.741230</td>\n",
              "      <td>0.622014</td>\n",
              "      <td>0.916981</td>\n",
              "      <td>0.988653</td>\n",
              "      <td>0.799376</td>\n",
              "      <td>29439</td>\n",
              "      <td>886</td>\n",
              "      <td>132</td>\n",
              "      <td>1458</td>\n",
              "      <td>0.513043</td>\n",
              "      <td>0.374010</td>\n",
              "      <td>0.816609</td>\n",
              "      <td>0.988585</td>\n",
              "      <td>0.572882</td>\n",
              "      <td>31231</td>\n",
              "      <td>395</td>\n",
              "      <td>53</td>\n",
              "      <td>236</td>\n",
              "      <td>0.977592</td>\n",
              "      <td>0.977592</td>\n",
              "      <td>0.977592</td>\n",
              "      <td>0.991236</td>\n",
              "      <td>0.647134</td>\n",
              "      <td>0.535088</td>\n",
              "      <td>0.839202</td>\n",
              "      <td>0.987809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.205500</td>\n",
              "      <td>0.887501</td>\n",
              "      <td>0.663888</td>\n",
              "      <td>0.792669</td>\n",
              "      <td>0.692834</td>\n",
              "      <td>0.926120</td>\n",
              "      <td>0.984219</td>\n",
              "      <td>0.886975</td>\n",
              "      <td>27600</td>\n",
              "      <td>1256</td>\n",
              "      <td>226</td>\n",
              "      <td>2833</td>\n",
              "      <td>0.493082</td>\n",
              "      <td>0.404959</td>\n",
              "      <td>0.630225</td>\n",
              "      <td>0.989108</td>\n",
              "      <td>0.441843</td>\n",
              "      <td>31316</td>\n",
              "      <td>288</td>\n",
              "      <td>115</td>\n",
              "      <td>196</td>\n",
              "      <td>0.821238</td>\n",
              "      <td>0.755152</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.992221</td>\n",
              "      <td>0.891017</td>\n",
              "      <td>29706</td>\n",
              "      <td>499</td>\n",
              "      <td>171</td>\n",
              "      <td>1539</td>\n",
              "      <td>0.546154</td>\n",
              "      <td>0.435583</td>\n",
              "      <td>0.731959</td>\n",
              "      <td>0.980264</td>\n",
              "      <td>0.470178</td>\n",
              "      <td>31726</td>\n",
              "      <td>92</td>\n",
              "      <td>26</td>\n",
              "      <td>71</td>\n",
              "      <td>0.757559</td>\n",
              "      <td>0.663671</td>\n",
              "      <td>0.882390</td>\n",
              "      <td>0.987728</td>\n",
              "      <td>0.792052</td>\n",
              "      <td>29614</td>\n",
              "      <td>711</td>\n",
              "      <td>187</td>\n",
              "      <td>1403</td>\n",
              "      <td>0.572626</td>\n",
              "      <td>0.480094</td>\n",
              "      <td>0.709343</td>\n",
              "      <td>0.985552</td>\n",
              "      <td>0.562001</td>\n",
              "      <td>31404</td>\n",
              "      <td>222</td>\n",
              "      <td>84</td>\n",
              "      <td>205</td>\n",
              "      <td>0.979754</td>\n",
              "      <td>0.979754</td>\n",
              "      <td>0.979754</td>\n",
              "      <td>0.990480</td>\n",
              "      <td>0.663888</td>\n",
              "      <td>0.572049</td>\n",
              "      <td>0.796673</td>\n",
              "      <td>0.986515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.145100</td>\n",
              "      <td>1.006753</td>\n",
              "      <td>0.667716</td>\n",
              "      <td>0.816482</td>\n",
              "      <td>0.738177</td>\n",
              "      <td>0.913370</td>\n",
              "      <td>0.985344</td>\n",
              "      <td>0.900385</td>\n",
              "      <td>27865</td>\n",
              "      <td>991</td>\n",
              "      <td>265</td>\n",
              "      <td>2794</td>\n",
              "      <td>0.483173</td>\n",
              "      <td>0.385797</td>\n",
              "      <td>0.646302</td>\n",
              "      <td>0.988721</td>\n",
              "      <td>0.421466</td>\n",
              "      <td>31284</td>\n",
              "      <td>320</td>\n",
              "      <td>110</td>\n",
              "      <td>201</td>\n",
              "      <td>0.822872</td>\n",
              "      <td>0.754634</td>\n",
              "      <td>0.904678</td>\n",
              "      <td>0.991831</td>\n",
              "      <td>0.886228</td>\n",
              "      <td>29702</td>\n",
              "      <td>503</td>\n",
              "      <td>163</td>\n",
              "      <td>1547</td>\n",
              "      <td>0.541833</td>\n",
              "      <td>0.441558</td>\n",
              "      <td>0.701031</td>\n",
              "      <td>0.978552</td>\n",
              "      <td>0.455903</td>\n",
              "      <td>31732</td>\n",
              "      <td>86</td>\n",
              "      <td>29</td>\n",
              "      <td>68</td>\n",
              "      <td>0.759804</td>\n",
              "      <td>0.670029</td>\n",
              "      <td>0.877358</td>\n",
              "      <td>0.987401</td>\n",
              "      <td>0.776451</td>\n",
              "      <td>29638</td>\n",
              "      <td>687</td>\n",
              "      <td>195</td>\n",
              "      <td>1395</td>\n",
              "      <td>0.582133</td>\n",
              "      <td>0.498765</td>\n",
              "      <td>0.698962</td>\n",
              "      <td>0.982079</td>\n",
              "      <td>0.561049</td>\n",
              "      <td>31423</td>\n",
              "      <td>203</td>\n",
              "      <td>87</td>\n",
              "      <td>202</td>\n",
              "      <td>0.980996</td>\n",
              "      <td>0.980996</td>\n",
              "      <td>0.980996</td>\n",
              "      <td>0.990346</td>\n",
              "      <td>0.667716</td>\n",
              "      <td>0.581493</td>\n",
              "      <td>0.790284</td>\n",
              "      <td>0.985655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Model Evaluation Results:\n",
            "    f1: 0.6677\n",
            "    loss: 1.0068\n",
            "    toxic_f1: 0.8165\n",
            "    toxic_precision: 0.7382\n",
            "    toxic_recall: 0.9134\n",
            "    toxic_roc_auc: 0.9853\n",
            "    toxic_pr_auc: 0.9004\n",
            "    toxic_tn: 27865.0000\n",
            "    toxic_fp: 991.0000\n",
            "    toxic_fn: 265.0000\n",
            "    toxic_tp: 2794.0000\n",
            "    severe_toxic_f1: 0.4832\n",
            "    severe_toxic_precision: 0.3858\n",
            "    severe_toxic_recall: 0.6463\n",
            "    severe_toxic_roc_auc: 0.9887\n",
            "    severe_toxic_pr_auc: 0.4215\n",
            "    severe_toxic_tn: 31284.0000\n",
            "    severe_toxic_fp: 320.0000\n",
            "    severe_toxic_fn: 110.0000\n",
            "    severe_toxic_tp: 201.0000\n",
            "    obscene_f1: 0.8229\n",
            "    obscene_precision: 0.7546\n",
            "    obscene_recall: 0.9047\n",
            "    obscene_roc_auc: 0.9918\n",
            "    obscene_pr_auc: 0.8862\n",
            "    obscene_tn: 29702.0000\n",
            "    obscene_fp: 503.0000\n",
            "    obscene_fn: 163.0000\n",
            "    obscene_tp: 1547.0000\n",
            "    threat_f1: 0.5418\n",
            "    threat_precision: 0.4416\n",
            "    threat_recall: 0.7010\n",
            "    threat_roc_auc: 0.9786\n",
            "    threat_pr_auc: 0.4559\n",
            "    threat_tn: 31732.0000\n",
            "    threat_fp: 86.0000\n",
            "    threat_fn: 29.0000\n",
            "    threat_tp: 68.0000\n",
            "    insult_f1: 0.7598\n",
            "    insult_precision: 0.6700\n",
            "    insult_recall: 0.8774\n",
            "    insult_roc_auc: 0.9874\n",
            "    insult_pr_auc: 0.7765\n",
            "    insult_tn: 29638.0000\n",
            "    insult_fp: 687.0000\n",
            "    insult_fn: 195.0000\n",
            "    insult_tp: 1395.0000\n",
            "    identity_hate_f1: 0.5821\n",
            "    identity_hate_precision: 0.4988\n",
            "    identity_hate_recall: 0.6990\n",
            "    identity_hate_roc_auc: 0.9821\n",
            "    identity_hate_pr_auc: 0.5610\n",
            "    identity_hate_tn: 31423.0000\n",
            "    identity_hate_fp: 203.0000\n",
            "    identity_hate_fn: 87.0000\n",
            "    identity_hate_tp: 202.0000\n",
            "    micro_f1: 0.9810\n",
            "    micro_precision: 0.9810\n",
            "    micro_recall: 0.9810\n",
            "    micro_roc_auc: 0.9903\n",
            "    macro_f1: 0.6677\n",
            "    macro_precision: 0.5815\n",
            "    macro_recall: 0.7903\n",
            "    macro_roc_auc: 0.9857\n",
            "    runtime: 58.0945\n",
            "    samples_per_second: 549.3640\n",
            "    steps_per_second: 34.3410\n",
            "\n",
            "Optimizing classification thresholds for final model evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-09 19:32:39,679] A new study created in memory with name: multilabel_threshold_optimization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8084e161a9f9444e9f734138bf55a538"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-07-09 19:32:39,703] Trial 0 finished with value: 0.9805681758838581 and parameters: {'threshold_toxic': 0.22323583077071776, 'threshold_severe_toxic': 0.1733485978739659, 'threshold_obscene': 0.6670869540338911, 'threshold_threat': 0.5189033379274536, 'threshold_insult': 0.8422024163010693, 'threshold_identity_hate': 0.45258171007393855}. Best is trial 0 with value: 0.9805681758838581.\n",
            "[I 2025-07-09 19:32:39,716] Trial 1 finished with value: 0.9804428429683012 and parameters: {'threshold_toxic': 0.5116042770514322, 'threshold_severe_toxic': 0.47801045732770886, 'threshold_obscene': 0.2745389364212583, 'threshold_threat': 0.13796264095507854, 'threshold_insult': 0.179759147383185, 'threshold_identity_hate': 0.6814491967306048}. Best is trial 0 with value: 0.9805681758838581.\n",
            "[I 2025-07-09 19:32:39,730] Trial 2 finished with value: 0.9814872839312758 and parameters: {'threshold_toxic': 0.7522295340246085, 'threshold_severe_toxic': 0.8815877199980144, 'threshold_obscene': 0.4070043891267616, 'threshold_threat': 0.591093404614735, 'threshold_insult': 0.43916032497815527, 'threshold_identity_hate': 0.33171680404924253}. Best is trial 2 with value: 0.9814872839312758.\n",
            "[I 2025-07-09 19:32:39,743] Trial 3 finished with value: 0.9812575069194214 and parameters: {'threshold_toxic': 0.6989273350150748, 'threshold_severe_toxic': 0.21152151381094175, 'threshold_obscene': 0.12613212532078794, 'threshold_threat': 0.7144504055545822, 'threshold_insult': 0.8196565284007636, 'threshold_identity_hate': 0.8702661367708658}. Best is trial 2 with value: 0.9814872839312758.\n",
            "[I 2025-07-09 19:32:39,757] Trial 4 finished with value: 0.981560394798684 and parameters: {'threshold_toxic': 0.8608784621813728, 'threshold_severe_toxic': 0.7008592442904817, 'threshold_obscene': 0.30116101717188526, 'threshold_threat': 0.6571995741762311, 'threshold_insult': 0.4212617869184767, 'threshold_identity_hate': 0.40221496202896223}. Best is trial 4 with value: 0.981560394798684.\n",
            "[I 2025-07-09 19:32:39,771] Trial 5 finished with value: 0.9810225077027521 and parameters: {'threshold_toxic': 0.6943912725070294, 'threshold_severe_toxic': 0.13629721411617712, 'threshold_obscene': 0.42215019969897183, 'threshold_threat': 0.7982683217935155, 'threshold_insult': 0.5836366257720209, 'threshold_identity_hate': 0.36994599023797625}. Best is trial 4 with value: 0.981560394798684.\n",
            "[I 2025-07-09 19:32:39,785] Trial 6 finished with value: 0.9815551725938692 and parameters: {'threshold_toxic': 0.8040074859095055, 'threshold_severe_toxic': 0.6020328444965336, 'threshold_obscene': 0.5517196582707864, 'threshold_threat': 0.2830091603687902, 'threshold_insult': 0.3602606414584665, 'threshold_identity_hate': 0.8117206144871271}. Best is trial 4 with value: 0.981560394798684.\n",
            "[I 2025-07-09 19:32:39,798] Trial 7 finished with value: 0.9813097289675701 and parameters: {'threshold_toxic': 0.7442596055615821, 'threshold_severe_toxic': 0.29837879524203126, 'threshold_obscene': 0.8706036798669221, 'threshold_threat': 0.724911681393042, 'threshold_insult': 0.434729546464221, 'threshold_identity_hate': 0.22870296623519454}. Best is trial 4 with value: 0.981560394798684.\n",
            "[I 2025-07-09 19:32:39,810] Trial 8 finished with value: 0.9820251710272077 and parameters: {'threshold_toxic': 0.765564301545191, 'threshold_severe_toxic': 0.7378541699669107, 'threshold_obscene': 0.8458502962843644, 'threshold_threat': 0.6338190142358695, 'threshold_insult': 0.4670842451929319, 'threshold_identity_hate': 0.7923887774672332}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:39,825] Trial 9 finished with value: 0.981194840461643 and parameters: {'threshold_toxic': 0.27795726703382817, 'threshold_severe_toxic': 0.7177385768632817, 'threshold_obscene': 0.7651655092463793, 'threshold_threat': 0.6182044440148665, 'threshold_insult': 0.7188142064795056, 'threshold_identity_hate': 0.5127268941521618}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:39,858] Trial 10 finished with value: 0.9812000626664578 and parameters: {'threshold_toxic': 0.5105768851922885, 'threshold_severe_toxic': 0.8919708093841708, 'threshold_obscene': 0.8783511562563546, 'threshold_threat': 0.8926281961860567, 'threshold_insult': 0.10832019018584332, 'threshold_identity_hate': 0.6680252867249752}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:39,892] Trial 11 finished with value: 0.9815029505457205 and parameters: {'threshold_toxic': 0.8904068124613761, 'threshold_severe_toxic': 0.7082249616451682, 'threshold_obscene': 0.2831387431035134, 'threshold_threat': 0.39426274118447424, 'threshold_insult': 0.2811283257887584, 'threshold_identity_hate': 0.5783597359981054}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:39,926] Trial 12 finished with value: 0.9818528382683169 and parameters: {'threshold_toxic': 0.8993055940425355, 'threshold_severe_toxic': 0.7058884029944912, 'threshold_obscene': 0.576965925073905, 'threshold_threat': 0.4235539454307806, 'threshold_insult': 0.6090400033782218, 'threshold_identity_hate': 0.27106055415343}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:39,960] Trial 13 finished with value: 0.9809755078594182 and parameters: {'threshold_toxic': 0.6161368842881282, 'threshold_severe_toxic': 0.49730424484407465, 'threshold_obscene': 0.6359333403129485, 'threshold_threat': 0.4088406045629195, 'threshold_insult': 0.6047526469301611, 'threshold_identity_hate': 0.14187150271053428}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:39,996] Trial 14 finished with value: 0.9811478406183091 and parameters: {'threshold_toxic': 0.604875420306924, 'threshold_severe_toxic': 0.7896564660689563, 'threshold_obscene': 0.734239607873684, 'threshold_threat': 0.4360007061619297, 'threshold_insult': 0.5784187594254702, 'threshold_identity_hate': 0.10166735464134508}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:40,029] Trial 15 finished with value: 0.9811426184134941 and parameters: {'threshold_toxic': 0.385895020891794, 'threshold_severe_toxic': 0.5988061200593887, 'threshold_obscene': 0.5765524531217616, 'threshold_threat': 0.2848751895507916, 'threshold_insult': 0.653756717986425, 'threshold_identity_hate': 0.7520314309350669}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:40,063] Trial 16 finished with value: 0.9817483941720194 and parameters: {'threshold_toxic': 0.8912716955335661, 'threshold_severe_toxic': 0.3769242515132519, 'threshold_obscene': 0.7857967171031262, 'threshold_threat': 0.5023989179503269, 'threshold_insult': 0.7258513330231946, 'threshold_identity_hate': 0.2617177886763722}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:40,098] Trial 17 finished with value: 0.9812522847146065 and parameters: {'threshold_toxic': 0.6237925043608736, 'threshold_severe_toxic': 0.5928925275655739, 'threshold_obscene': 0.4926170452169197, 'threshold_threat': 0.3110161190435492, 'threshold_insult': 0.4980389721659962, 'threshold_identity_hate': 0.5562679004993274}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:40,132] Trial 18 finished with value: 0.9798945114627395 and parameters: {'threshold_toxic': 0.10359023085689356, 'threshold_severe_toxic': 0.7923240824002754, 'threshold_obscene': 0.6739549372567195, 'threshold_threat': 0.13209096301722995, 'threshold_insult': 0.27475304766791464, 'threshold_identity_hate': 0.6413799712197924}. Best is trial 8 with value: 0.9820251710272077.\n",
            "[I 2025-07-09 19:32:40,166] Trial 19 finished with value: 0.9821922815812836 and parameters: {'threshold_toxic': 0.8149987900304365, 'threshold_severe_toxic': 0.8042904322975084, 'threshold_obscene': 0.8308097739719096, 'threshold_threat': 0.5508253398436866, 'threshold_insult': 0.5149482177498403, 'threshold_identity_hate': 0.8931116089799791}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,202] Trial 20 finished with value: 0.9813619510157189 and parameters: {'threshold_toxic': 0.43022422538006594, 'threshold_severe_toxic': 0.8055841928055094, 'threshold_obscene': 0.8195423559026378, 'threshold_threat': 0.8219637298910767, 'threshold_insult': 0.34814721405466853, 'threshold_identity_hate': 0.8982183244681524}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,235] Trial 21 finished with value: 0.9821400595331349 and parameters: {'threshold_toxic': 0.811927190804446, 'threshold_severe_toxic': 0.6650613651676669, 'threshold_obscene': 0.8984113591526226, 'threshold_threat': 0.5505868365725703, 'threshold_insult': 0.5148857171889757, 'threshold_identity_hate': 0.7546980650894388}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,270] Trial 22 finished with value: 0.98213483732832 and parameters: {'threshold_toxic': 0.8077667057640892, 'threshold_severe_toxic': 0.6416596255350416, 'threshold_obscene': 0.8980311980287545, 'threshold_threat': 0.5561606921508981, 'threshold_insult': 0.5205442459667708, 'threshold_identity_hate': 0.7866014289057841}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,305] Trial 23 finished with value: 0.9821452817379498 and parameters: {'threshold_toxic': 0.8174552771708636, 'threshold_severe_toxic': 0.6243754306964318, 'threshold_obscene': 0.8987702918467823, 'threshold_threat': 0.5677688381993647, 'threshold_insult': 0.5430855630733948, 'threshold_identity_hate': 0.7302540286347223}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,342] Trial 24 finished with value: 0.9817379497623897 and parameters: {'threshold_toxic': 0.6851391900602817, 'threshold_severe_toxic': 0.4198114056559471, 'threshold_obscene': 0.7270382694101709, 'threshold_threat': 0.6866473601939393, 'threshold_insult': 0.7072570060097091, 'threshold_identity_hate': 0.7408032183851759}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,381] Trial 25 finished with value: 0.9819781711838739 and parameters: {'threshold_toxic': 0.8003532852288309, 'threshold_severe_toxic': 0.5670573040858925, 'threshold_obscene': 0.8074631198653188, 'threshold_threat': 0.5282469205022079, 'threshold_insult': 0.5306346856347162, 'threshold_identity_hate': 0.8569658147310958}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,414] Trial 26 finished with value: 0.9815447281842394 and parameters: {'threshold_toxic': 0.5589910772656037, 'threshold_severe_toxic': 0.6520221191027529, 'threshold_obscene': 0.8896518533032975, 'threshold_threat': 0.45852384404361335, 'threshold_insult': 0.3557698960591158, 'threshold_identity_hate': 0.7011164378941144}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,448] Trial 27 finished with value: 0.9821400595331349 and parameters: {'threshold_toxic': 0.8306265280011947, 'threshold_severe_toxic': 0.8385449157918196, 'threshold_obscene': 0.721270659641761, 'threshold_threat': 0.3410959560416546, 'threshold_insult': 0.6618710738896211, 'threshold_identity_hate': 0.6112141640895286}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,485] Trial 28 finished with value: 0.9817118387383154 and parameters: {'threshold_toxic': 0.6806342539223259, 'threshold_severe_toxic': 0.5443693959802715, 'threshold_obscene': 0.8216653755946938, 'threshold_threat': 0.5811512045572622, 'threshold_insult': 0.5420229692485254, 'threshold_identity_hate': 0.8406363645455323}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,524] Trial 29 finished with value: 0.9814089508590527 and parameters: {'threshold_toxic': 0.39248246900340655, 'threshold_severe_toxic': 0.6422454545402057, 'threshold_obscene': 0.6409196767757692, 'threshold_threat': 0.5220478407998287, 'threshold_insult': 0.7984640199558728, 'threshold_identity_hate': 0.7323090613034765}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,559] Trial 30 finished with value: 0.9821818371716539 and parameters: {'threshold_toxic': 0.7345439884190743, 'threshold_severe_toxic': 0.7624101041780517, 'threshold_obscene': 0.7069190193820725, 'threshold_threat': 0.47742823031169707, 'threshold_insult': 0.8679215865063354, 'threshold_identity_hate': 0.8167226352628352}. Best is trial 19 with value: 0.9821922815812836.\n",
            "[I 2025-07-09 19:32:40,594] Trial 31 finished with value: 0.982380280954619 and parameters: {'threshold_toxic': 0.8454977903081727, 'threshold_severe_toxic': 0.7734008731313338, 'threshold_obscene': 0.7826778801140388, 'threshold_threat': 0.4814352277913593, 'threshold_insult': 0.7765995298701556, 'threshold_identity_hate': 0.8965910337766585}. Best is trial 31 with value: 0.982380280954619.\n",
            "[I 2025-07-09 19:32:40,628] Trial 32 finished with value: 0.9822392814246175 and parameters: {'threshold_toxic': 0.7462356416455396, 'threshold_severe_toxic': 0.7772472127823373, 'threshold_obscene': 0.6782072859620174, 'threshold_threat': 0.4782669477060749, 'threshold_insult': 0.8731968312851883, 'threshold_identity_hate': 0.827955724053748}. Best is trial 31 with value: 0.982380280954619.\n",
            "[I 2025-07-09 19:32:40,664] Trial 33 finished with value: 0.9822392814246175 and parameters: {'threshold_toxic': 0.7430993484642061, 'threshold_severe_toxic': 0.8401109778400706, 'threshold_obscene': 0.673645906098302, 'threshold_threat': 0.21228850127966548, 'threshold_insult': 0.8993522621812736, 'threshold_identity_hate': 0.8857147626303778}. Best is trial 31 with value: 0.982380280954619.\n",
            "[I 2025-07-09 19:32:40,697] Trial 34 finished with value: 0.9820303932320226 and parameters: {'threshold_toxic': 0.6463409643530884, 'threshold_severe_toxic': 0.8416268774249049, 'threshold_obscene': 0.655230964419506, 'threshold_threat': 0.1829474368038796, 'threshold_insult': 0.8992079005670095, 'threshold_identity_hate': 0.8964360256008703}. Best is trial 31 with value: 0.982380280954619.\n",
            "[I 2025-07-09 19:32:40,732] Trial 35 finished with value: 0.981889393702021 and parameters: {'threshold_toxic': 0.5625498084427553, 'threshold_severe_toxic': 0.8682108648756097, 'threshold_obscene': 0.7603744618249956, 'threshold_threat': 0.20804974131532777, 'threshold_insult': 0.782923821384156, 'threshold_identity_hate': 0.8547613184449394}. Best is trial 31 with value: 0.982380280954619.\n",
            "[I 2025-07-09 19:32:40,767] Trial 36 finished with value: 0.9822288370149878 and parameters: {'threshold_toxic': 0.764469959255453, 'threshold_severe_toxic': 0.8210908685014834, 'threshold_obscene': 0.6023048351383185, 'threshold_threat': 0.3665504921404228, 'threshold_insult': 0.8595067936747085, 'threshold_identity_hate': 0.8979053203452814}. Best is trial 31 with value: 0.982380280954619.\n",
            "[I 2025-07-09 19:32:40,805] Trial 37 finished with value: 0.9820408376416523 and parameters: {'threshold_toxic': 0.7334184383117173, 'threshold_severe_toxic': 0.8385741856396975, 'threshold_obscene': 0.5267977877501456, 'threshold_threat': 0.24860253774013416, 'threshold_insult': 0.8441881236126431, 'threshold_identity_hate': 0.8288167017395791}. Best is trial 31 with value: 0.982380280954619.\n",
            "[I 2025-07-09 19:32:40,838] Trial 38 finished with value: 0.9817797274009087 and parameters: {'threshold_toxic': 0.7636078520720322, 'threshold_severe_toxic': 0.758503493608272, 'threshold_obscene': 0.4720554354966493, 'threshold_threat': 0.3899184002683553, 'threshold_insult': 0.7610046955107835, 'threshold_identity_hate': 0.45972718463989076}. Best is trial 31 with value: 0.982380280954619.\n",
            "[I 2025-07-09 19:32:40,873] Trial 39 finished with value: 0.9824325030027677 and parameters: {'threshold_toxic': 0.8546498803296695, 'threshold_severe_toxic': 0.8877331227284294, 'threshold_obscene': 0.6050807016973827, 'threshold_threat': 0.3497931609801758, 'threshold_insult': 0.8944929247287459, 'threshold_identity_hate': 0.7820578556306699}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:40,909] Trial 40 finished with value: 0.9819102825212804 and parameters: {'threshold_toxic': 0.848201579558721, 'threshold_severe_toxic': 0.8837500184864622, 'threshold_obscene': 0.1471537303369514, 'threshold_threat': 0.20240935901753104, 'threshold_insult': 0.8979225792321073, 'threshold_identity_hate': 0.7895699168799242}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:40,946] Trial 41 finished with value: 0.9821870593764688 and parameters: {'threshold_toxic': 0.7789800731385635, 'threshold_severe_toxic': 0.8446319320942127, 'threshold_obscene': 0.5951562786799064, 'threshold_threat': 0.3694249553579924, 'threshold_insult': 0.8345388957295818, 'threshold_identity_hate': 0.8572869529836921}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:40,980] Trial 42 finished with value: 0.982176614966839 and parameters: {'threshold_toxic': 0.7096479174043606, 'threshold_severe_toxic': 0.8966167486539969, 'threshold_obscene': 0.6892834429661167, 'threshold_threat': 0.35930138897180297, 'threshold_insult': 0.8527538416543413, 'threshold_identity_hate': 0.8102026140328551}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,016] Trial 43 finished with value: 0.982176614966839 and parameters: {'threshold_toxic': 0.8606549756817495, 'threshold_severe_toxic': 0.7424159572988069, 'threshold_obscene': 0.6130060087542227, 'threshold_threat': 0.10605824575110923, 'threshold_insult': 0.8074624887193795, 'threshold_identity_hate': 0.6902999600377527}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,053] Trial 44 finished with value: 0.9816752833046112 and parameters: {'threshold_toxic': 0.6643564192790257, 'threshold_severe_toxic': 0.7752064577609771, 'threshold_obscene': 0.39808535722060917, 'threshold_threat': 0.3325085296245216, 'threshold_insult': 0.753385808156758, 'threshold_identity_hate': 0.7846479638138392}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,087] Trial 45 finished with value: 0.9822340592198026 and parameters: {'threshold_toxic': 0.8652372750316134, 'threshold_severe_toxic': 0.6790058439318193, 'threshold_obscene': 0.5189953911290002, 'threshold_threat': 0.275935953741764, 'threshold_insult': 0.8727116951710479, 'threshold_identity_hate': 0.870023439272555}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,126] Trial 46 finished with value: 0.982218392605358 and parameters: {'threshold_toxic': 0.8681209076708712, 'threshold_severe_toxic': 0.6849669622935178, 'threshold_obscene': 0.448339485041459, 'threshold_threat': 0.24599262562066482, 'threshold_insult': 0.8930503290708895, 'threshold_identity_hate': 0.8429368533045825}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,164] Trial 47 finished with value: 0.981811060629798 and parameters: {'threshold_toxic': 0.8525470553267157, 'threshold_severe_toxic': 0.22555144820975453, 'threshold_obscene': 0.5303622862685098, 'threshold_threat': 0.273694824321514, 'threshold_insult': 0.8183602640447863, 'threshold_identity_hate': 0.7658566681627594}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,199] Trial 48 finished with value: 0.9818162828346128 and parameters: {'threshold_toxic': 0.7218172983237003, 'threshold_severe_toxic': 0.7357916730494738, 'threshold_obscene': 0.3669528027696013, 'threshold_threat': 0.17001027551169778, 'threshold_insult': 0.7819558946154246, 'threshold_identity_hate': 0.8665815065246228}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,234] Trial 49 finished with value: 0.9823541699305447 and parameters: {'threshold_toxic': 0.8966361255302445, 'threshold_severe_toxic': 0.862621919468684, 'threshold_obscene': 0.7581528736599672, 'threshold_threat': 0.47234911369384674, 'threshold_insult': 0.8609300122888276, 'threshold_identity_hate': 0.3877612893282083}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,271] Trial 50 finished with value: 0.982218392605358 and parameters: {'threshold_toxic': 0.8941260897465841, 'threshold_severe_toxic': 0.8626168297447652, 'threshold_obscene': 0.7870291611420496, 'threshold_threat': 0.45839463200346753, 'threshold_insult': 0.6799006557916323, 'threshold_identity_hate': 0.38323850204767973}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,305] Trial 51 finished with value: 0.982093059689801 and parameters: {'threshold_toxic': 0.7821310446069393, 'threshold_severe_toxic': 0.8108506121269484, 'threshold_obscene': 0.7517008741884137, 'threshold_threat': 0.488979010685751, 'threshold_insult': 0.872105739448196, 'threshold_identity_hate': 0.339181085493907}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,340] Trial 52 finished with value: 0.9821661705572092 and parameters: {'threshold_toxic': 0.8486852567025851, 'threshold_severe_toxic': 0.8973306955049023, 'threshold_obscene': 0.6822960609049804, 'threshold_threat': 0.2997708629417885, 'threshold_insult': 0.8168588130783084, 'threshold_identity_hate': 0.41662497856430136}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,378] Trial 53 finished with value: 0.9820617264609118 and parameters: {'threshold_toxic': 0.8773837357025445, 'threshold_severe_toxic': 0.7095973691166968, 'threshold_obscene': 0.561588542579971, 'threshold_threat': 0.61319218970202, 'threshold_insult': 0.7525844593466473, 'threshold_identity_hate': 0.42235552278040545}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,413] Trial 54 finished with value: 0.9821505039427646 and parameters: {'threshold_toxic': 0.8300348328515373, 'threshold_severe_toxic': 0.7796856656256943, 'threshold_obscene': 0.6449376360350014, 'threshold_threat': 0.4371580663089548, 'threshold_insult': 0.8693230817969041, 'threshold_identity_hate': 0.4705834807790728}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,449] Trial 55 finished with value: 0.9813358399916444 and parameters: {'threshold_toxic': 0.28302667560363937, 'threshold_severe_toxic': 0.8509488531320434, 'threshold_obscene': 0.8555779896129867, 'threshold_threat': 0.2476428973375488, 'threshold_insult': 0.8347895958406385, 'threshold_identity_hate': 0.5368123108436715}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,488] Trial 56 finished with value: 0.9818319494490574 and parameters: {'threshold_toxic': 0.7865584959461986, 'threshold_severe_toxic': 0.6840483036930748, 'threshold_obscene': 0.614403027256663, 'threshold_threat': 0.4118700129927949, 'threshold_insult': 0.8982705700998385, 'threshold_identity_hate': 0.21229528457737717}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,523] Trial 57 finished with value: 0.9820042822079482 and parameters: {'threshold_toxic': 0.7501768904325719, 'threshold_severe_toxic': 0.808635336448403, 'threshold_obscene': 0.5231374468959717, 'threshold_threat': 0.33138563820352007, 'threshold_insult': 0.7788065111971012, 'threshold_identity_hate': 0.8192157650972353}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,559] Trial 58 finished with value: 0.9823071700872108 and parameters: {'threshold_toxic': 0.8401465556879292, 'threshold_severe_toxic': 0.7329840886929282, 'threshold_obscene': 0.6960647013087102, 'threshold_threat': 0.2280699983915616, 'threshold_insult': 0.8335405599247366, 'threshold_identity_hate': 0.8712606566610301}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,598] Trial 59 finished with value: 0.9819102825212804 and parameters: {'threshold_toxic': 0.8319744085965456, 'threshold_severe_toxic': 0.7474629272755269, 'threshold_obscene': 0.7785818586707369, 'threshold_threat': 0.13898179060716065, 'threshold_insult': 0.7302204558182656, 'threshold_identity_hate': 0.2943898178685658}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,633] Trial 60 finished with value: 0.9821139485090605 and parameters: {'threshold_toxic': 0.892839428044382, 'threshold_severe_toxic': 0.8694642439598828, 'threshold_obscene': 0.7062901804855131, 'threshold_threat': 0.22247424387571837, 'threshold_insult': 0.7015295704794658, 'threshold_identity_hate': 0.49295131393203906}. Best is trial 39 with value: 0.9824325030027677.\n",
            "[I 2025-07-09 19:32:41,669] Trial 61 finished with value: 0.9824429474123975 and parameters: {'threshold_toxic': 0.8692388215920741, 'threshold_severe_toxic': 0.721196334453228, 'threshold_obscene': 0.74639860431129, 'threshold_threat': 0.2683646520169821, 'threshold_insult': 0.8461856869923801, 'threshold_identity_hate': 0.8703739390239699}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,708] Trial 62 finished with value: 0.9822758368583215 and parameters: {'threshold_toxic': 0.7999410137542466, 'threshold_severe_toxic': 0.7263043500506439, 'threshold_obscene': 0.7416553149570378, 'threshold_threat': 0.15718881385549252, 'threshold_insult': 0.8361869305864117, 'threshold_identity_hate': 0.8825628534859444}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,744] Trial 63 finished with value: 0.9822236148101728 and parameters: {'threshold_toxic': 0.7968539134745553, 'threshold_severe_toxic': 0.7869606596969989, 'threshold_obscene': 0.7370698750841103, 'threshold_threat': 0.16793278377772491, 'threshold_insult': 0.8320854358633202, 'threshold_identity_hate': 0.8074079616731223}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,780] Trial 64 finished with value: 0.9823489477257298 and parameters: {'threshold_toxic': 0.8339755019175269, 'threshold_severe_toxic': 0.7186989563795362, 'threshold_obscene': 0.7855712405280435, 'threshold_threat': 0.4569476373060024, 'threshold_insult': 0.7988972203845465, 'threshold_identity_hate': 0.7153632617587833}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,817] Trial 65 finished with value: 0.9824168363883231 and parameters: {'threshold_toxic': 0.896987677307814, 'threshold_severe_toxic': 0.7370212253438947, 'threshold_obscene': 0.8008793790990635, 'threshold_threat': 0.3132156895236704, 'threshold_insult': 0.8019443349607736, 'threshold_identity_hate': 0.6446564478386544}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,853] Trial 66 finished with value: 0.9823071700872108 and parameters: {'threshold_toxic': 0.8953479212064945, 'threshold_severe_toxic': 0.71848974884217, 'threshold_obscene': 0.858971073062446, 'threshold_threat': 0.3086102548298614, 'threshold_insult': 0.6325293785106767, 'threshold_identity_hate': 0.6296150800707625}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,889] Trial 67 finished with value: 0.9821035040994308 and parameters: {'threshold_toxic': 0.8316572656427911, 'threshold_severe_toxic': 0.45771410401529716, 'threshold_obscene': 0.8114643277802253, 'threshold_threat': 0.43531631699665574, 'threshold_insult': 0.8004038466334306, 'threshold_identity_hate': 0.7134896615498537}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,927] Trial 68 finished with value: 0.9811112851846049 and parameters: {'threshold_toxic': 0.4616069806077714, 'threshold_severe_toxic': 0.11037730866089646, 'threshold_obscene': 0.798321806989295, 'threshold_threat': 0.401140124799142, 'threshold_insult': 0.7294701316946507, 'threshold_identity_hate': 0.6485284600871423}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,963] Trial 69 finished with value: 0.9822497258342472 and parameters: {'threshold_toxic': 0.8764848310076129, 'threshold_severe_toxic': 0.6134009333607593, 'threshold_obscene': 0.8387975282531389, 'threshold_threat': 0.5065932363601702, 'threshold_insult': 0.7626636306818882, 'threshold_identity_hate': 0.5801619593006998}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:41,999] Trial 70 finished with value: 0.981685727714241 and parameters: {'threshold_toxic': 0.8453307219124432, 'threshold_severe_toxic': 0.6958933317638961, 'threshold_obscene': 0.7746602827592333, 'threshold_threat': 0.3754656734198366, 'threshold_insult': 0.22053827221713507, 'threshold_identity_hate': 0.6680556734995606}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,039] Trial 71 finished with value: 0.9823071700872108 and parameters: {'threshold_toxic': 0.8982744836811443, 'threshold_severe_toxic': 0.7197898634444364, 'threshold_obscene': 0.8532520095162406, 'threshold_threat': 0.3271076477661291, 'threshold_insult': 0.6135493249298213, 'threshold_identity_hate': 0.6300001211265727}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,075] Trial 72 finished with value: 0.9818215050394277 and parameters: {'threshold_toxic': 0.8731057766123491, 'threshold_severe_toxic': 0.3275395483942132, 'threshold_obscene': 0.7093638485023641, 'threshold_threat': 0.2944993961975974, 'threshold_insult': 0.6890128157908181, 'threshold_identity_hate': 0.598099728208674}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,112] Trial 73 finished with value: 0.982385503159434 and parameters: {'threshold_toxic': 0.8999828224012332, 'threshold_severe_toxic': 0.6601338049678975, 'threshold_obscene': 0.8657733483308838, 'threshold_threat': 0.5335000263695592, 'threshold_insult': 0.6364655628920588, 'threshold_identity_hate': 0.7209101194860682}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,151] Trial 74 finished with value: 0.9822027259909134 and parameters: {'threshold_toxic': 0.8240675496851044, 'threshold_severe_toxic': 0.5514959318735738, 'threshold_obscene': 0.8296824498195878, 'threshold_threat': 0.5927313112581691, 'threshold_insult': 0.7968262067537677, 'threshold_identity_hate': 0.7267050311055909}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,186] Trial 75 finished with value: 0.9822497258342472 and parameters: {'threshold_toxic': 0.8527077734832355, 'threshold_severe_toxic': 0.6641580494123775, 'threshold_obscene': 0.7586621086011552, 'threshold_threat': 0.5283695242276002, 'threshold_insult': 0.7464145392099838, 'threshold_identity_hate': 0.761737922592561}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,222] Trial 76 finished with value: 0.981972948979059 and parameters: {'threshold_toxic': 0.810450082951515, 'threshold_severe_toxic': 0.7589463728954816, 'threshold_obscene': 0.7841914218792608, 'threshold_threat': 0.6580543438723612, 'threshold_insult': 0.39628064195177715, 'threshold_identity_hate': 0.7726398981677693}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,262] Trial 77 finished with value: 0.9822810590631365 and parameters: {'threshold_toxic': 0.8747047599005477, 'threshold_severe_toxic': 0.82786846200058, 'threshold_obscene': 0.8075142404797987, 'threshold_threat': 0.4602675488959304, 'threshold_insult': 0.5799577270663876, 'threshold_identity_hate': 0.7020543995248859}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,298] Trial 78 finished with value: 0.981847616063502 and parameters: {'threshold_toxic': 0.7749519204341498, 'threshold_severe_toxic': 0.5772329130933537, 'threshold_obscene': 0.8743362948108655, 'threshold_threat': 0.3526369244671092, 'threshold_insult': 0.4812646933453899, 'threshold_identity_hate': 0.6698196444055411}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,335] Trial 79 finished with value: 0.9823385033161001 and parameters: {'threshold_toxic': 0.8366586967903027, 'threshold_severe_toxic': 0.625758619209522, 'threshold_obscene': 0.7302013981767881, 'threshold_threat': 0.5081643563497317, 'threshold_insult': 0.8548603446930019, 'threshold_identity_hate': 0.8467685260653418}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,373] Trial 80 finished with value: 0.9824272807979529 and parameters: {'threshold_toxic': 0.8760518963906799, 'threshold_severe_toxic': 0.6679712060471034, 'threshold_obscene': 0.7653719186563753, 'threshold_threat': 0.5381511733790756, 'threshold_insult': 0.8537686042216777, 'threshold_identity_hate': 0.744273851835919}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,408] Trial 81 finished with value: 0.9823750587498041 and parameters: {'threshold_toxic': 0.8718385447689421, 'threshold_severe_toxic': 0.6342944349697957, 'threshold_obscene': 0.7311039458931037, 'threshold_threat': 0.5387600371924994, 'threshold_insult': 0.8531288826664469, 'threshold_identity_hate': 0.7376933650269317}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,446] Trial 82 finished with value: 0.9821296151235052 and parameters: {'threshold_toxic': 0.8737065495892268, 'threshold_severe_toxic': 0.527354752812946, 'threshold_obscene': 0.7626484188537809, 'threshold_threat': 0.5361430720457981, 'threshold_insult': 0.7750847412461528, 'threshold_identity_hate': 0.7298524419491836}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,486] Trial 83 finished with value: 0.9823176144968405 and parameters: {'threshold_toxic': 0.815445584277642, 'threshold_severe_toxic': 0.6480596208448594, 'threshold_obscene': 0.8304987772055233, 'threshold_threat': 0.5774633144375081, 'threshold_insult': 0.8142067194179275, 'threshold_identity_hate': 0.6911661921629041}. Best is trial 61 with value: 0.9824429474123975.\n",
            "[I 2025-07-09 19:32:42,522] Trial 84 finished with value: 0.9824795028461016 and parameters: {'threshold_toxic': 0.8584568228232955, 'threshold_severe_toxic': 0.673470365357388, 'threshold_obscene': 0.7931584879906691, 'threshold_threat': 0.5441347266196583, 'threshold_insult': 0.8784842298643036, 'threshold_identity_hate': 0.7478705843681726}. Best is trial 84 with value: 0.9824795028461016.\n",
            "[I 2025-07-09 19:32:42,560] Trial 85 finished with value: 0.9809128414016398 and parameters: {'threshold_toxic': 0.12279445951220547, 'threshold_severe_toxic': 0.6651777549289014, 'threshold_obscene': 0.8707337597875918, 'threshold_threat': 0.5525429262544939, 'threshold_insult': 0.8797119985446851, 'threshold_identity_hate': 0.7466469218786038}. Best is trial 84 with value: 0.9824795028461016.\n",
            "[I 2025-07-09 19:32:42,598] Trial 86 finished with value: 0.9823071700872108 and parameters: {'threshold_toxic': 0.8590685154672267, 'threshold_severe_toxic': 0.5876279617018371, 'threshold_obscene': 0.6647649328864595, 'threshold_threat': 0.6044261528698583, 'threshold_insult': 0.8521823860343698, 'threshold_identity_hate': 0.800401157585801}. Best is trial 84 with value: 0.9824795028461016.\n",
            "[I 2025-07-09 19:32:42,634] Trial 87 finished with value: 0.9824325030027677 and parameters: {'threshold_toxic': 0.8823973619820168, 'threshold_severe_toxic': 0.6117927701639909, 'threshold_obscene': 0.718334802026622, 'threshold_threat': 0.6538856186092743, 'threshold_insult': 0.8797325314490532, 'threshold_identity_hate': 0.748481592408802}. Best is trial 84 with value: 0.9824795028461016.\n",
            "[I 2025-07-09 19:32:42,670] Trial 88 finished with value: 0.9824429474123975 and parameters: {'threshold_toxic': 0.8734088610371338, 'threshold_severe_toxic': 0.6090362601513025, 'threshold_obscene': 0.7970213837610209, 'threshold_threat': 0.6395641820766669, 'threshold_insult': 0.8803804189479045, 'threshold_identity_hate': 0.7821841371641565}. Best is trial 84 with value: 0.9824795028461016.\n",
            "[I 2025-07-09 19:32:42,709] Trial 89 finished with value: 0.9825108360749909 and parameters: {'threshold_toxic': 0.8837429341182598, 'threshold_severe_toxic': 0.6034813113927875, 'threshold_obscene': 0.802713516462491, 'threshold_threat': 0.7811964487288102, 'threshold_insult': 0.8824885649675641, 'threshold_identity_hate': 0.7708013098283905}. Best is trial 89 with value: 0.9825108360749909.\n",
            "[I 2025-07-09 19:32:42,746] Trial 90 finished with value: 0.9823698365449893 and parameters: {'threshold_toxic': 0.879696759792946, 'threshold_severe_toxic': 0.5128568050200766, 'threshold_obscene': 0.8027479477856353, 'threshold_threat': 0.7721424073615886, 'threshold_insult': 0.8738064077153959, 'threshold_identity_hate': 0.7839288823673405}. Best is trial 89 with value: 0.9825108360749909.\n",
            "[I 2025-07-09 19:32:42,783] Trial 91 finished with value: 0.9825735025327693 and parameters: {'threshold_toxic': 0.899171916942717, 'threshold_severe_toxic': 0.6087025708591208, 'threshold_obscene': 0.841705147263323, 'threshold_threat': 0.7314018786196219, 'threshold_insult': 0.886325356983573, 'threshold_identity_hate': 0.7658695627137007}. Best is trial 91 with value: 0.9825735025327693.\n",
            "[I 2025-07-09 19:32:42,823] Trial 92 finished with value: 0.9825526137135099 and parameters: {'threshold_toxic': 0.8984492023121018, 'threshold_severe_toxic': 0.6052909550890525, 'threshold_obscene': 0.8422234679823121, 'threshold_threat': 0.7144630989346628, 'threshold_insult': 0.8799010447564459, 'threshold_identity_hate': 0.7566389701727303}. Best is trial 91 with value: 0.9825735025327693.\n",
            "[I 2025-07-09 19:32:42,861] Trial 93 finished with value: 0.9824951694605463 and parameters: {'threshold_toxic': 0.8586263117095859, 'threshold_severe_toxic': 0.6012062503901221, 'threshold_obscene': 0.8395011849960521, 'threshold_threat': 0.7375151743102137, 'threshold_insult': 0.886480665438572, 'threshold_identity_hate': 0.770909702029031}. Best is trial 91 with value: 0.9825735025327693.\n",
            "[I 2025-07-09 19:32:42,898] Trial 94 finished with value: 0.982505613870176 and parameters: {'threshold_toxic': 0.8588980137556022, 'threshold_severe_toxic': 0.6058661705534866, 'threshold_obscene': 0.8410813001862929, 'threshold_threat': 0.7322996175574947, 'threshold_insult': 0.8838308000192167, 'threshold_identity_hate': 0.7607843537873994}. Best is trial 91 with value: 0.9825735025327693.\n",
            "[I 2025-07-09 19:32:42,937] Trial 95 finished with value: 0.98254216930388 and parameters: {'threshold_toxic': 0.8558931578360338, 'threshold_severe_toxic': 0.6023585381954227, 'threshold_obscene': 0.8821387399679391, 'threshold_threat': 0.7381192291443655, 'threshold_insult': 0.8831445353628473, 'threshold_identity_hate': 0.770905634136076}. Best is trial 91 with value: 0.9825735025327693.\n",
            "[I 2025-07-09 19:32:42,975] Trial 96 finished with value: 0.9825003916653611 and parameters: {'threshold_toxic': 0.8589215614107465, 'threshold_severe_toxic': 0.5613614873828296, 'threshold_obscene': 0.8854813591049177, 'threshold_threat': 0.7319091812578588, 'threshold_insult': 0.8864063087718834, 'threshold_identity_hate': 0.7716753613662224}. Best is trial 91 with value: 0.9825735025327693.\n",
            "[I 2025-07-09 19:32:43,011] Trial 97 finished with value: 0.9824533918220273 and parameters: {'threshold_toxic': 0.8164528984783703, 'threshold_severe_toxic': 0.5510658998742992, 'threshold_obscene': 0.8843595558750078, 'threshold_threat': 0.7437404892533452, 'threshold_insult': 0.8831479279747253, 'threshold_identity_hate': 0.8272487225951242}. Best is trial 91 with value: 0.9825735025327693.\n",
            "[I 2025-07-09 19:32:43,049] Trial 98 finished with value: 0.9824429474123975 and parameters: {'threshold_toxic': 0.8032507151120266, 'threshold_severe_toxic': 0.5557098070473216, 'threshold_obscene': 0.892560125662666, 'threshold_threat': 0.7326873836866846, 'threshold_insult': 0.8872732396592472, 'threshold_identity_hate': 0.837000220184102}. Best is trial 91 with value: 0.9825735025327693.\n",
            "[I 2025-07-09 19:32:43,085] Trial 99 finished with value: 0.9822079481957282 and parameters: {'threshold_toxic': 0.819262177905972, 'threshold_severe_toxic': 0.46459927795663947, 'threshold_obscene': 0.84076020593354, 'threshold_threat': 0.836991724291225, 'threshold_insult': 0.830685855341794, 'threshold_identity_hate': 0.8000023957632622}. Best is trial 91 with value: 0.9825735025327693.\n",
            "Optimized micro F1 (threshold tuning): 0.9826\n",
            "Optimized thresholds:\n",
            "    0.899\n",
            "    0.609\n",
            "    0.842\n",
            "    0.731\n",
            "    0.886\n",
            "    0.766\n",
            "    Saved training history plot to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/training_metrics_plot_Final_Model.png\n",
            "    Saved multilabel confusion matrix plots to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/multilabel_confusion_matrices_Final_Model.png\n",
            "    Saved Multi-label Precision-Recall Curves to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/multilabel_precision_recall_curves_Final_Model.png\n",
            "    Saved Multi-label ROC Curves to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/multilabel_roc_curves_Final_Model.png\n",
            "    Saved Multi-label Probability Distributions to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/multilabel_probability_distributions_Final_Model.png\n",
            "Final optimized thresholds saved to /content/drive/MyDrive/my_electra_multilabel_classifier_results/optimized_thresholds_multilabel.csv\n",
            "Final model saved to /content/drive/MyDrive/my_electra_multilabel_classifier_results/best_electra_multilabel_model\n",
            "\n",
            "Training and optimization complete! \n",
            "Results, model checkpoints, and plots are saved in: /content/drive/MyDrive/my_electra_multilabel_classifier_results\n",
            "\n",
            "--- Optuna Optimization Summary Data ---\n",
            "{\n",
            "  \"total_trials_completed\": 7,\n",
            "  \"best_trial_number\": 0,\n",
            "  \"best_objective_value\": 0.6659698987376466,\n",
            "  \"best_hyperparameters\": {\n",
            "    \"learning_rate\": 1.1844319751820392e-05,\n",
            "    \"batch_size\": 16,\n",
            "    \"num_train_epochs\": 4,\n",
            "    \"warmup_ratio\": 0.07340279606636549,\n",
            "    \"weight_decay\": 0.015599452033620266,\n",
            "    \"gradient_accumulation_steps\": 2,\n",
            "    \"lr_scheduler_type\": \"linear\",\n",
            "    \"oversampling_ratio\": 0.9729188669457949,\n",
            "    \"hidden_dropout_prob\": 0.26648852816008434,\n",
            "    \"attention_probs_dropout_prob\": 0.12123391106782762\n",
            "  },\n",
            "  \"trial_history\": [\n",
            "    {\n",
            "      \"trial_number\": 0,\n",
            "      \"state\": \"1\",\n",
            "      \"value\": 0.6659698987376466,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 1.1844319751820392e-05,\n",
            "        \"batch_size\": 16,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.07340279606636549,\n",
            "        \"weight_decay\": 0.015599452033620266,\n",
            "        \"gradient_accumulation_steps\": 2,\n",
            "        \"lr_scheduler_type\": \"linear\",\n",
            "        \"oversampling_ratio\": 0.9729188669457949,\n",
            "        \"hidden_dropout_prob\": 0.26648852816008434,\n",
            "        \"attention_probs_dropout_prob\": 0.12123391106782762\n",
            "      },\n",
            "      \"duration_seconds\": 16009.889635\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 1,\n",
            "      \"state\": \"0\",\n",
            "      \"value\": null,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 7.599674150654901e-06,\n",
            "        \"batch_size\": 32,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.11479175279631737,\n",
            "        \"weight_decay\": 0.029122914019804193,\n",
            "        \"gradient_accumulation_steps\": 1,\n",
            "        \"lr_scheduler_type\": \"cosine\",\n",
            "        \"oversampling_ratio\": 0.8066583652537123,\n",
            "        \"hidden_dropout_prob\": 0.13993475643167194,\n",
            "        \"attention_probs_dropout_prob\": 0.15142344384136117\n",
            "      },\n",
            "      \"duration_seconds\": null\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 2,\n",
            "      \"state\": \"3\",\n",
            "      \"value\": null,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 1.1844319751820392e-05,\n",
            "        \"batch_size\": 16,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.07340279606636549,\n",
            "        \"weight_decay\": 0.015599452033620266,\n",
            "        \"gradient_accumulation_steps\": 2,\n",
            "        \"lr_scheduler_type\": \"linear\",\n",
            "        \"oversampling_ratio\": 0.9729188669457949,\n",
            "        \"hidden_dropout_prob\": 0.26648852816008434,\n",
            "        \"attention_probs_dropout_prob\": 0.12123391106782762\n",
            "      },\n",
            "      \"duration_seconds\": 117.676056\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 3,\n",
            "      \"state\": \"1\",\n",
            "      \"value\": 0.6659698987376466,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 1.1844319751820392e-05,\n",
            "        \"batch_size\": 16,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.07340279606636549,\n",
            "        \"weight_decay\": 0.015599452033620266,\n",
            "        \"gradient_accumulation_steps\": 2,\n",
            "        \"lr_scheduler_type\": \"linear\",\n",
            "        \"oversampling_ratio\": 0.9729188669457949,\n",
            "        \"hidden_dropout_prob\": 0.26648852816008434,\n",
            "        \"attention_probs_dropout_prob\": 0.12123391106782762\n",
            "      },\n",
            "      \"duration_seconds\": 16026.689383\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 4,\n",
            "      \"state\": \"1\",\n",
            "      \"value\": 0.6520154997162748,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 7.599674150654901e-06,\n",
            "        \"batch_size\": 32,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.11479175279631737,\n",
            "        \"weight_decay\": 0.029122914019804193,\n",
            "        \"gradient_accumulation_steps\": 1,\n",
            "        \"lr_scheduler_type\": \"cosine\",\n",
            "        \"oversampling_ratio\": 0.8066583652537123,\n",
            "        \"hidden_dropout_prob\": 0.13993475643167194,\n",
            "        \"attention_probs_dropout_prob\": 0.15142344384136117\n",
            "      },\n",
            "      \"duration_seconds\": 13492.704154\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 5,\n",
            "      \"state\": \"1\",\n",
            "      \"value\": 0.6515064462064342,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 1.9560708142748497e-05,\n",
            "        \"batch_size\": 32,\n",
            "        \"num_train_epochs\": 2,\n",
            "        \"warmup_ratio\": 0.05975773894779193,\n",
            "        \"weight_decay\": 0.09488855372533334,\n",
            "        \"gradient_accumulation_steps\": 1,\n",
            "        \"lr_scheduler_type\": \"cosine\",\n",
            "        \"oversampling_ratio\": 0.4961372443656412,\n",
            "        \"hidden_dropout_prob\": 0.12440764696895577,\n",
            "        \"attention_probs_dropout_prob\": 0.14951769101112702\n",
            "      },\n",
            "      \"duration_seconds\": 6870.479842\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 6,\n",
            "      \"state\": \"3\",\n",
            "      \"value\": null,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 5.412009190750477e-06,\n",
            "        \"batch_size\": 16,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.09675666141341166,\n",
            "        \"weight_decay\": 0.05200680211778108,\n",
            "        \"gradient_accumulation_steps\": 4,\n",
            "        \"lr_scheduler_type\": \"cosine\",\n",
            "        \"oversampling_ratio\": 0.905344615384884,\n",
            "        \"hidden_dropout_prob\": 0.21957999576221704,\n",
            "        \"attention_probs_dropout_prob\": 0.1921874235023117\n",
            "      },\n",
            "      \"duration_seconds\": 3407.762144\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- End of Optuna Optimization Summary Data ---\n",
            "\n",
            "--- Starting Explainable AI (XAI) Analysis with LIME ---\n",
            "Loaded final model and tokenizer from /content/drive/MyDrive/my_electra_multilabel_classifier_results/best_electra_multilabel_model\n",
            "\n",
            "--- XAI Example 1 ---\n",
            "Comment: '\"\n",
            "Welcome!\n",
            "\n",
            "Hello, , and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are a few good links for newcomers:\n",
            "The five pillars of Wikipedia\n",
            "How to edit a page\n",
            "Help pages\n",
            "Tutorial\n",
            "How to write a great article\n",
            "Manual of Style\n",
            "I hope you enjoy editing here and being a Wikipedian! Please sign your name on talk pages using four tildes (~~~~); this will automatically produce your name and the date. If you need help, check out Wikipedia:Questions, ask me on my talk page, or place {{helpme}} on your talk page and someone will show up shortly to answer your questions. Again, welcome!  '''''' (E@) T \"'\n",
            "True Labels: [0 0 0 0 0 0]\n",
            "Model Probabilities: [0. 0. 0. 0. 0. 0.]\n",
            "  Skipping explanation for label 'toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'severe_toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'obscene' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'insult' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Example 2 ---\n",
            "Comment: 'Heads up\n",
            "You're being discussed here, in regards to that Sheree Silver articles for deletion. The creator, Spring12, seems bound and determined to belittle and discount anyone who voted delete.'\n",
            "True Labels: [0 0 0 0 0 0]\n",
            "Model Probabilities: [0. 0. 0. 0. 0. 0.]\n",
            "  Skipping explanation for label 'toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'severe_toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'obscene' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'insult' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Example 3 ---\n",
            "Comment: 'You're an asshole.  Seriously.  I've been  here for three years.  I know edit summaries are encouraged.  But I've  never heard that it is encouraged that we revert articles simply because no edit summary is provided.  That's ridiculous.'\n",
            "True Labels: [1 0 1 0 0 0]\n",
            "Model Probabilities: [1.    0.593 1.    0.001 1.    0.002]\n",
            "\n",
            "  Explanation for label: 'toxic' (True: 1, Predicted Prob: 1.000)\n",
            "[(np.str_('asshole'), 0.549280793994119), (np.str_('ridiculous'), 0.19375430108118313), (np.str_('You'), 0.12985114980260523), (np.str_('no'), 0.06479844562897914), (np.str_('re'), 0.06040016179074532), (np.str_('Seriously'), 0.054604821264122534), (np.str_('But'), -0.0487922973352476), (np.str_('That'), -0.04721873533753866), (np.str_('three'), -0.03743954651666489), (np.str_('summary'), 0.036647007273078756)]\n",
            "\n",
            "  Explanation for label: 'severe_toxic' (True: 0, Predicted Prob: 0.593)\n",
            "  Error generating LIME explanation for label 'severe_toxic': 1\n",
            "\n",
            "  Explanation for label: 'obscene' (True: 1, Predicted Prob: 1.000)\n",
            "  Error generating LIME explanation for label 'obscene': 2\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.001 - not a strong prediction or true positive)\n",
            "\n",
            "  Explanation for label: 'insult' (True: 0, Predicted Prob: 1.000)\n",
            "  Error generating LIME explanation for label 'insult': 4\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.002 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Example 4 ---\n",
            "Comment: '\"\n",
            "Ha, so if I quote only the relevant bits, I'm \"\"selectively quoting\"\"?  Should I have copied and pasted the entire MOS?  Anyway the thing still seems extremely clear to me.  Putting \"\"best known as...\"\" is redundant because the article title shows that, and it also carries the implication that he was known by at least one other name in daily life.  190.44.158.38  \"'\n",
            "True Labels: [0 0 0 0 0 0]\n",
            "Model Probabilities: [0. 0. 0. 0. 0. 0.]\n",
            "  Skipping explanation for label 'toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'severe_toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'obscene' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'insult' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Example 5 ---\n",
            "Comment: '\" \n",
            "(Note: If the above link doesn't work manually add a colon \"\":\"\" to end of address bar)\"'\n",
            "True Labels: [0 0 0 0 0 0]\n",
            "Model Probabilities: [0. 0. 0. 0. 0. 0.]\n",
            "  Skipping explanation for label 'toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'severe_toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'obscene' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'insult' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Analysis Complete ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random # Import random for set_seed\n",
        "import re # Import re for text processing in EDA (if you combine)\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt # Import matplotlib for plotting\n",
        "import sqlite3 # Added for database integrity checks\n",
        "import json # For handling JSON data\n",
        "\n",
        "# For Hugging Face Transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# For scikit-learn utilities\n",
        "from sklearn.model_selection import KFold, train_test_split # Use KFold for CV, train_test_split for main split\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score, roc_auc_score,\n",
        "    confusion_matrix, precision_recall_curve, roc_curve, auc,\n",
        "    average_precision_score # For PR-AUC\n",
        ")\n",
        "\n",
        "# For Optuna hyperparameter optimization\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner, HyperbandPruner\n",
        "from optuna.samplers import TPESampler # Explicitly import TPESampler\n",
        "\n",
        "# For Imbalance Handling (SMOTE and SMOTETomek)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# For Explainable AI (XAI)\n",
        "from lime.lime_text import LimeTextExplainer # Import LIME\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- IMPORTANT: Explicitly disable Weights & Biases logging entirely ---\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Configuration Class\n",
        "\n",
        "class Config:\n",
        "    # Model and Tokenizer Settings\n",
        "    MODEL_NAME = \"google/electra-base-discriminator\"\n",
        "    MAX_LENGTH = 256  # Maximum sequence length for tokenization\n",
        "\n",
        "    # Device Configuration\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU if available, else CPU\n",
        "\n",
        "    # Reproducibility\n",
        "    RANDOM_SEED = 42 # Seed for all random number generators to ensure reproducibility\n",
        "\n",
        "    # Optuna Hyperparameter Optimization Settings\n",
        "    N_TRIALS = 5 # Number of Optuna trials for hyperparameter optimization\n",
        "    CV_FOLDS = 5  # Number of folds for cross-validation during Optuna trials\n",
        "    PATIENCE = 3  # Early stopping patience for the Trainer\n",
        "\n",
        "    # Label Columns for Multi-label Classification\n",
        "    LABEL_COLS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "    # Original multi-labels (kept for reference, same as LABEL_COLS now)\n",
        "    ORIGINAL_LABEL_COLS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "    # Optuna Search Spaces for Hyperparameters\n",
        "    SEARCH_SPACE = {\n",
        "        'learning_rate': (5e-6, 5e-5), # General range for transformer fine-tuning (log-uniform)\n",
        "        'batch_size': [16, 32],        # Recommended batch sizes (categorical)\n",
        "        'num_train_epochs': (2, 5),    # Recommended epoch range for transformers (integer)\n",
        "        'warmup_ratio': (0.05, 0.2),   # Warmup ratio for learning rate scheduler (float)\n",
        "        'weight_decay': (0.0, 0.1),    # Regularization to prevent overfitting (float)\n",
        "        'hidden_dropout_prob': (0.1, 0.3), # Dropout for hidden layers (float)\n",
        "        'attention_probs_dropout_prob': (0.1, 0.2), # Dropout for attention probabilities (float)\n",
        "        'gradient_accumulation_steps': [1, 2, 4], # Accumulate gradients to simulate larger batch sizes (categorical)\n",
        "        'lr_scheduler_type': ['linear', 'cosine'], # Learning rate scheduler types (categorical)\n",
        "        # New hyperparameter for oversampling ratio (for SMOTE/SMOTETomek)\n",
        "        'oversampling_ratio': (0.1, 1.0) # From 10% to 100% of minority class size (float)\n",
        "    }\n",
        "\n",
        "    # --- Google Drive Save Path Configuration ---\n",
        "    # IMPORTANT: Ensure your Google Drive is mounted at /content/drive/\n",
        "    # This is the base path where all models, plots, and CSVs will be saved.\n",
        "    GOOGLE_DRIVE_SAVE_BASE_PATH = \"/content/drive/MyDrive/my_electra_multilabel_classifier_results\"\n",
        "\n",
        "    # --- Optuna Persistent Storage Path ---\n",
        "    # This is where Optuna's study state will be saved (SQLite database)\n",
        "    # Using the defined GOOGLE_DRIVE_SAVE_BASE_PATH directly\n",
        "    OPTUNA_DB_PATH = os.path.join(GOOGLE_DRIVE_SAVE_BASE_PATH, 'optuna_electra_multilabel_study.db')\n",
        "\n",
        "    # --- New: Option to load existing Optuna study results ---\n",
        "    # Set to True if you want to skip re-running Optuna optimization\n",
        "    # and instead load the best parameters from a saved Optuna DB.\n",
        "    LOAD_EXISTING_STUDY_RESULTS = True # Changed to True to stop further optimization\n",
        "\n",
        "# Set seeds for reproducibility across different libraries\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed) # For Python's built-in random module\n",
        "\n",
        "# Dataset Class\n",
        "class ToxicDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Enhanced dataset class for multi-label toxic comment classification.\n",
        "    Supports text augmentation and prepares data for Hugging Face models.\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels_df, tokenizer, max_length, augment=False):\n",
        "        self.texts = texts\n",
        "        self.labels = labels_df # Now a DataFrame with multiple label columns\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.augment = augment # Flag to enable/disable augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves a sample from the dataset.\n",
        "        Applies augmentation if enabled and randomly triggered.\n",
        "        Tokenizes the text and returns a dictionary of input features and a multi-label tensor.\n",
        "        \"\"\"\n",
        "        text = str(self.texts.iloc[idx])\n",
        "\n",
        "        # Simple augmentation for toxic comments to increase diversity\n",
        "        if self.augment and np.random.random() < 0.3:\n",
        "            text = self._augment_text(text)\n",
        "\n",
        "        # Tokenize the text using the pre-trained tokenizer\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,        # Truncate to max_length if longer\n",
        "            padding='max_length',   # Pad to max_length if shorter\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'     # Return PyTorch tensors\n",
        "        )\n",
        "\n",
        "        # Return a FloatTensor of shape [num_labels] for multi-label classification\n",
        "        # Ensure labels are converted to float32\n",
        "        labels_tensor = torch.FloatTensor(self.labels.iloc[idx].values)\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),      # Flatten input_ids tensor\n",
        "            'attention_mask': encoding['attention_mask'].flatten(), # Flatten attention_mask tensor\n",
        "            'labels': labels_tensor # Tensor of shape [num_labels]\n",
        "        }\n",
        "\n",
        "    def _augment_text(self, text):\n",
        "        \"\"\"\n",
        "        Applies simple text augmentation techniques.\n",
        "        Currently implements random case changes for a single word.\n",
        "        \"\"\"\n",
        "        words = text.split()\n",
        "        if len(words) > 2:\n",
        "            # Randomly select a word and change its case\n",
        "            idx = np.random.randint(0, len(words))\n",
        "            if np.random.random() < 0.5:\n",
        "                words[idx] = words[idx].upper() # Convert to uppercase\n",
        "            else:\n",
        "                words[idx] = words[idx].lower() # Convert to lowercase\n",
        "        return ' '.join(words)\n",
        "\n",
        "# AdvancedTrainer Class\n",
        "class AdvancedTrainer(Trainer):\n",
        "    \"\"\"\n",
        "    Custom Hugging Face Trainer with advanced features:\n",
        "    - Custom loss function for class weighting (BCEWithLogitsLoss with pos_weight).\n",
        "    - Stores prediction thresholds for evaluation.\n",
        "    \"\"\"\n",
        "    def __init__(self, pos_weights=None, thresholds=None, **kwargs):\n",
        "        _pos_weights = pos_weights\n",
        "        _thresholds = thresholds\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # pos_weights should now be a tensor of shape [num_labels]\n",
        "        self.pos_weights = _pos_weights\n",
        "        # thresholds will be a list of floats, one for each label\n",
        "        self.thresholds = _thresholds or [0.5] * len(Config.LABEL_COLS)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        \"\"\"\n",
        "        Custom loss computation using BCEWithLogitsLoss for multi-label classification.\n",
        "        Applies `pos_weight` for class imbalance handling if provided.\n",
        "        \"\"\"\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "\n",
        "        # Logits will be [batch_size, num_labels], labels will be [batch_size, num_labels]\n",
        "        # No squeezing needed here, as BCEWithLogitsLoss expects this shape for multi-label\n",
        "\n",
        "        # Explicitly cast to float32 to prevent potential dtype mismatches with CUDA kernels\n",
        "        if labels.dtype != torch.float32:\n",
        "            labels = labels.to(torch.float32)\n",
        "        if logits.dtype != torch.float32:\n",
        "            logits = logits.to(torch.float32)\n",
        "\n",
        "        # Use BCEWithLogitsLoss which is numerically stable and handles sigmoid internally.\n",
        "        # Apply pos_weight for class balancing as recommended.\n",
        "        if self.pos_weights is not None:\n",
        "            # pos_weight needs to be a tensor of shape [num_labels]\n",
        "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights.to(logits.device))\n",
        "        else:\n",
        "            loss_fct = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        # The 'num_items_in_batch' argument is now accepted to align with Hugging Face Trainer API changes.\n",
        "        # You do not need to explicitly use this argument within your loss calculation for BCEWithLogitsLoss,\n",
        "        # but its presence in the signature is essential to avoid the TypeError.\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# MetricsCalculator Class\n",
        "class MetricsCalculator:\n",
        "    \"\"\"\n",
        "    Handles calculation of various classification metrics and threshold optimization\n",
        "    for multi-label classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, label_cols):\n",
        "        self.label_cols = label_cols\n",
        "\n",
        "    def compute_metrics(self, eval_pred, thresholds=None):\n",
        "        \"\"\"\n",
        "        Computes comprehensive evaluation metrics (F1, Precision, Recall, AUC, PR-AUC)\n",
        "        for multi-label classification, including per-label, micro, and macro averages.\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "\n",
        "        # Apply sigmoid to logits to get probabilities\n",
        "        sigmoid_preds = torch.sigmoid(torch.tensor(predictions)).numpy()\n",
        "        labels = labels.astype(int) # Ensure labels are integers for sklearn metrics\n",
        "\n",
        "        # Use provided thresholds or default to 0.5 for all labels\n",
        "        thresholds = thresholds if thresholds is not None else [0.5] * len(self.label_cols)\n",
        "\n",
        "        metrics = {}\n",
        "        all_binary_preds = []\n",
        "        all_y_true = []\n",
        "        all_y_proba = []\n",
        "\n",
        "        # Calculate metrics for each label and store for macro/micro averaging\n",
        "        for i, label_name in enumerate(self.label_cols):\n",
        "            y_true_label = labels[:, i]\n",
        "            y_pred_proba_label = sigmoid_preds[:, i]\n",
        "            threshold_label = thresholds[i]\n",
        "\n",
        "            binary_preds_label = (y_pred_proba_label > threshold_label).astype(int)\n",
        "\n",
        "            # Store flattened arrays for micro averaging later\n",
        "            all_y_true.extend(y_true_label)\n",
        "            all_binary_preds.extend(binary_preds_label)\n",
        "            all_y_proba.extend(y_pred_proba_label)\n",
        "\n",
        "            # Per-label metrics with robust error handling for AUC/PR-AUC\n",
        "            try:\n",
        "                f1 = f1_score(y_true_label, binary_preds_label, zero_division=0)\n",
        "                precision = precision_score(y_true_label, binary_preds_label, zero_division=0)\n",
        "                recall = recall_score(y_true_label, binary_preds_label, zero_division=0)\n",
        "\n",
        "                auc_score = 0.0\n",
        "                if len(np.unique(y_true_label)) > 1: # AUC needs at least two unique classes\n",
        "                    auc_score = roc_auc_score(y_true_label, y_pred_proba_label)\n",
        "\n",
        "                avg_precision = 0.0\n",
        "                if len(np.unique(y_true_label)) > 1: # PR-AUC also needs at least two unique classes\n",
        "                    avg_precision = average_precision_score(y_true_label, y_pred_proba_label)\n",
        "\n",
        "                tn, fp, fn, tp = confusion_matrix(y_true_label, binary_preds_label).ravel()\n",
        "            except Exception as e:\n",
        "                # Catch any error during per-label calculation and assign defaults\n",
        "                print(f\"Warning: Error computing per-label metrics for '{label_name}': {e}\", flush=True)\n",
        "                f1, precision, recall, auc_score, avg_precision = 0.0, 0.0, 0.0, 0.0, 0.0\n",
        "                tn, fp, fn, tp = 0, 0, 0, 0\n",
        "\n",
        "            metrics[f'{label_name}_f1'] = f1\n",
        "            metrics[f'{label_name}_precision'] = precision\n",
        "            metrics[f'{label_name}_recall'] = recall\n",
        "            metrics[f'{label_name}_roc_auc'] = auc_score\n",
        "            metrics[f'{label_name}_pr_auc'] = avg_precision # Average Precision (PR AUC)\n",
        "            metrics[f'{label_name}_tn'] = tn\n",
        "            metrics[f'{label_name}_fp'] = fp\n",
        "            metrics[f'{label_name}_fn'] = fn\n",
        "            metrics[f'{label_name}_tp'] = tp\n",
        "\n",
        "        # Calculate Micro F1/Precision/Recall/AUC\n",
        "        try:\n",
        "            metrics['micro_f1'] = f1_score(all_y_true, all_binary_preds, average='micro', zero_division=0)\n",
        "            metrics['micro_precision'] = precision_score(all_y_true, all_binary_preds, average='micro', zero_division=0)\n",
        "            metrics['micro_recall'] = recall_score(all_y_true, all_binary_preds, average='micro', zero_division=0)\n",
        "\n",
        "            # Micro-AUC on flattened arrays\n",
        "            if len(np.unique(all_y_true)) > 1 and len(np.unique(all_y_proba)) > 1:\n",
        "                metrics['micro_roc_auc'] = roc_auc_score(all_y_true, all_y_proba)\n",
        "            else:\n",
        "                metrics['micro_roc_auc'] = 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Error computing micro metrics: {e}\", flush=True)\n",
        "            metrics['micro_f1'], metrics['micro_precision'], metrics['micro_recall'], metrics['micro_roc_auc'] = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "\n",
        "        # Calculate Macro F1/Precision/Recall/AUC\n",
        "        binary_preds_all_labels = (sigmoid_preds > np.array(thresholds)).astype(int)\n",
        "\n",
        "        try:\n",
        "            metrics['macro_f1'] = f1_score(labels, binary_preds_all_labels, average='macro', zero_division=0)\n",
        "            metrics['macro_precision'] = precision_score(labels, binary_preds_all_labels, average='macro', zero_division=0)\n",
        "            metrics['macro_recall'] = recall_score(labels, binary_preds_all_labels, average='macro', zero_division=0)\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Failed to compute overall macro F1/Precision/Recall: {e}\", flush=True)\n",
        "            metrics['macro_f1'], metrics['macro_precision'], metrics['macro_recall'] = 0.0, 0.0, 0.0\n",
        "\n",
        "        # Macro AUC (average of per-label AUCs)\n",
        "        metrics['macro_roc_auc'] = np.mean([metrics[f'{label_name}_roc_auc'] for label_name in self.label_cols])\n",
        "\n",
        "        # Trainer uses this as the primary metric for best model selection.\n",
        "        # This key must match `metric_for_best_model` in your TrainingArguments.\n",
        "        # We're setting it to macro_f1 as discussed for Optuna optimization.\n",
        "        metrics['eval_f1'] = metrics['macro_f1']\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def optimize_thresholds(self, y_true, y_pred_proba, n_trials=100):\n",
        "        \"\"\"\n",
        "        Optimizes classification thresholds for each label in a multi-label setting using Optuna.\n",
        "        The objective is to maximize the micro F1 score across all labels.\n",
        "        \"\"\"\n",
        "        num_labels = y_true.shape[1]\n",
        "        best_thresholds = []\n",
        "\n",
        "        def objective(trial):\n",
        "            thresholds = []\n",
        "            for i, label_name in enumerate(self.label_cols):\n",
        "                # Suggest a threshold for each label\n",
        "                threshold = trial.suggest_float(f'threshold_{label_name}', 0.1, 0.9)\n",
        "                thresholds.append(threshold)\n",
        "\n",
        "            # Binarize predictions using the suggested thresholds\n",
        "            binary_preds = (y_pred_proba > np.array(thresholds)).astype(int)\n",
        "\n",
        "            # Calculate micro F1 score across all labels\n",
        "            micro_f1 = f1_score(y_true.flatten(), binary_preds.flatten(), average='micro', zero_division=0)\n",
        "\n",
        "            return micro_f1\n",
        "\n",
        "        # Create an Optuna study to maximize the micro F1 score\n",
        "        study = optuna.create_study(direction='maximize', study_name='multilabel_threshold_optimization')\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "        # Extract the best thresholds found by Optuna\n",
        "        for i, label_name in enumerate(self.label_cols):\n",
        "            best_thresholds.append(study.best_params[f'threshold_{label_name}'])\n",
        "\n",
        "        return best_thresholds, study.best_value # Return as a list and the best score\n",
        "\n",
        "# ModelOptimizer Class\n",
        "class ModelOptimizer:\n",
        "    \"\"\"\n",
        "    Main class for orchestrating multi-label model training and hyperparameter optimization\n",
        "    using Optuna and cross-validation, incorporating imbalance handling.\n",
        "    \"\"\"\n",
        "    def __init__(self, train_df, val_df=None):\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "        self.metrics_calculator = MetricsCalculator(Config.LABEL_COLS)\n",
        "\n",
        "        # Calculate positive weights for all labels\n",
        "        self.pos_weights = self._calculate_pos_weights()\n",
        "\n",
        "    def _calculate_pos_weights(self):\n",
        "        \"\"\"\n",
        "        Calculates positive weights for each label to be used in BCEWithLogitsLoss.\n",
        "        Weight_i = Number of negative samples_i / Number of positive samples_i.\n",
        "        \"\"\"\n",
        "        pos_weights = []\n",
        "        for label_col in Config.LABEL_COLS:\n",
        "            pos_count = self.train_df[label_col].sum()\n",
        "            neg_count = len(self.train_df) - pos_count\n",
        "            # Avoid division by zero, set min pos_count to 1\n",
        "            pos_weight = neg_count / max(pos_count, 1)\n",
        "            pos_weights.append(pos_weight)\n",
        "            print(f\"Positive weight for '{label_col}': {pos_weight:.2f}\", flush=True)\n",
        "\n",
        "        return torch.FloatTensor(pos_weights)\n",
        "\n",
        "    def _create_model(self, trial=None):\n",
        "        \"\"\"\n",
        "        Creates an AutoModelForSequenceClassification model from the pre-trained name.\n",
        "        Applies trial-specific dropout hyperparameters if an Optuna trial is provided.\n",
        "        \"\"\"\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            Config.MODEL_NAME,\n",
        "            num_labels=len(Config.LABEL_COLS), # Now based on all labels\n",
        "            problem_type=\"multi_label_classification\", # Correct for multi-label BCEWithLogitsLoss\n",
        "            use_safetensors=True\n",
        "        )\n",
        "\n",
        "        # Apply dropout hyperparameters suggested by Optuna if in a trial\n",
        "        if trial is not None:\n",
        "            hidden_dropout = trial.suggest_float('hidden_dropout_prob', *Config.SEARCH_SPACE['hidden_dropout_prob'])\n",
        "            attention_dropout = trial.suggest_float('attention_probs_dropout_prob', *Config.SEARCH_SPACE['attention_probs_dropout_prob'])\n",
        "            model.config.hidden_dropout_prob = hidden_dropout\n",
        "            model.config.attention_probs_dropout_prob = attention_dropout\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _apply_sampling(self, X_train, y_train, oversampling_ratio, sampling_strategy='hybrid'):\n",
        "        \"\"\"\n",
        "        Applies synthetic oversampling (SMOTE) or hybrid sampling (SMOTETomek) to the training data.\n",
        "        Only applies to the training set.\n",
        "        For text data with imblearn, we oversample the *indices* based on a pseudo-label\n",
        "        (whether a comment has ANY toxic label).\n",
        "        \"\"\"\n",
        "        # Create a \"pseudo-label\" for sampling: 1 if any label is positive, 0 otherwise\n",
        "        y_pseudo = (y_train.sum(axis=1) > 0).astype(int)\n",
        "\n",
        "        if len(np.unique(y_pseudo)) < 2:\n",
        "            print(\"Warning: Only one class present in pseudo-labels for sampling. Skipping oversampling.\", flush=True)\n",
        "            return X_train, y_train\n",
        "\n",
        "        original_indices = np.arange(len(X_train))\n",
        "        y_pseudo_for_sampling = pd.Series(y_pseudo, index=original_indices) # Keep original indices\n",
        "\n",
        "        resampled_indices = original_indices\n",
        "        if sampling_strategy == 'smote':\n",
        "            # SMOTE works on features. Here we use indices as a proxy.\n",
        "            # k_neighbors must be less than the number of samples in the minority class.\n",
        "            # If your minority class is very small, k_neighbors might need adjustment.\n",
        "            smote_sampler = SMOTE(random_state=Config.RANDOM_SEED, sampling_strategy=oversampling_ratio, k_neighbors=min(3, y_pseudo_for_sampling.value_counts().min() - 1))\n",
        "            try:\n",
        "                resampled_indices, _ = smote_sampler.fit_resample(original_indices.reshape(-1, 1), y_pseudo_for_sampling)\n",
        "            except ValueError as e:\n",
        "                print(f\"SMOTE failed: {e}. Skipping oversampling.\", flush=True)\n",
        "                return X_train, y_train\n",
        "            resampled_indices = resampled_indices.flatten()\n",
        "\n",
        "        elif sampling_strategy == 'hybrid':\n",
        "            # SMOTETomek also works on features.\n",
        "            smotetomek_sampler = SMOTETomek(random_state=Config.RANDOM_SEED, sampling_strategy=oversampling_ratio, smote=SMOTE(k_neighbors=min(3, y_pseudo_for_sampling.value_counts().min() - 1)))\n",
        "            try:\n",
        "                resampled_indices, _ = smotetomek_sampler.fit_resample(original_indices.reshape(-1, 1), y_pseudo_for_sampling)\n",
        "            except ValueError as e:\n",
        "                print(f\"SMOTETomek failed: {e}. Skipping oversampling.\", flush=True)\n",
        "                return X_train, y_train\n",
        "            resampled_indices = resampled_indices.flatten()\n",
        "\n",
        "        # Reconstruct the resampled DataFrame using the resampled indices\n",
        "        resampled_X_train = X_train.iloc[resampled_indices].reset_index(drop=True)\n",
        "        resampled_y_train = y_train.iloc[resampled_indices].reset_index(drop=True)\n",
        "\n",
        "        return resampled_X_train, resampled_y_train\n",
        "\n",
        "    def _plot_training_history(self, history, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots training and evaluation metrics over epochs for multi-label.\n",
        "        Focuses on loss and the main 'eval_f1' (micro-f1).\n",
        "        \"\"\"\n",
        "        epochs = [entry['epoch'] for entry in history if 'loss' in entry]\n",
        "        train_losses = [entry['loss'] for entry in history if 'loss' in entry]\n",
        "\n",
        "        eval_epochs = [entry['epoch'] for entry in history if 'eval_loss' in entry]\n",
        "        val_losses = [entry['eval_loss'] for entry in history if 'eval_loss' in entry]\n",
        "        val_micro_f1s = [entry['eval_f1'] for entry in history if 'eval_f1' in entry] # eval_f1 is micro_f1\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, train_losses, label='Training Loss')\n",
        "        plt.plot(eval_epochs, val_losses, label='Validation Loss')\n",
        "        plt.title(f'Loss per Epoch {title_suffix}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(eval_epochs, val_micro_f1s, label='Validation Micro F1-Score', color='orange')\n",
        "        plt.title(f'Micro F1-Score per Epoch {title_suffix}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Micro F1-Score')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'training_metrics_plot_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved training history plot to {plot_filename}\", flush=True)\n",
        "\n",
        "    def _plot_multilabel_confusion_matrix(self, y_true, y_pred_binary, label_cols, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots confusion matrices for each label in a multi-label setting.\n",
        "        \"\"\"\n",
        "        num_labels = len(label_cols)\n",
        "        # Calculate number of rows needed for subplots\n",
        "        nrows = int(np.ceil(num_labels / 3))\n",
        "        fig, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(15, 5 * nrows))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            ax = axes[i]\n",
        "            cm = confusion_matrix(y_true[:, i], y_pred_binary[:, i])\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "            ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "            ax.set_title(f'CM for {label_name} {title_suffix}')\n",
        "            tick_marks = np.arange(2)\n",
        "            ax.set_xticks(tick_marks, ['0', '1'])\n",
        "            ax.set_yticks(tick_marks, ['0', '1'])\n",
        "            ax.set_xlabel('Predicted')\n",
        "            ax.set_ylabel('True')\n",
        "\n",
        "            thresh = cm.max() / 2.\n",
        "            for x in range(cm.shape[0]):\n",
        "                for y in range(cm.shape[1]):\n",
        "                    ax.text(y, x, format(cm[x, y], 'd'),\n",
        "                            ha=\"center\", va=\"center\",\n",
        "                            color=\"white\" if cm[x, y] > thresh else \"black\")\n",
        "        # Hide unused subplots\n",
        "        for i in range(num_labels, len(axes)):\n",
        "            fig.delaxes(axes[i])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'multilabel_confusion_matrices_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved multilabel confusion matrix plots to {plot_filename}\", flush=True)\n",
        "\n",
        "    def _plot_precision_recall_curve_multilabel(self, y_true, y_pred_proba, label_cols, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots Precision-Recall Curves for each label.\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            precision, recall, _ = precision_recall_curve(y_true[:, i], y_pred_proba[:, i])\n",
        "            pr_auc = average_precision_score(y_true[:, i], y_pred_proba[:, i])\n",
        "            plt.plot(recall, precision, label=f'{label_name} (PR-AUC = {pr_auc:.2f})')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title(f'Precision-Recall Curves {title_suffix}')\n",
        "        plt.legend(loc='lower left')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'multilabel_precision_recall_curves_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved Multi-label Precision-Recall Curves to {plot_filename}\", flush=True)\n",
        "\n",
        "    def _plot_roc_curve_multilabel(self, y_true, y_pred_proba, label_cols, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots ROC Curves for each label.\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            fpr, tpr, _ = roc_curve(y_true[:, i], y_pred_proba[:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label=f'{label_name} (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'Receiver Operating Characteristic (ROC) Curves {title_suffix}')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'multilabel_roc_curves_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved Multi-label ROC Curves to {plot_filename}\", flush=True)\n",
        "\n",
        "    def _plot_probability_distribution_multilabel(self, y_true, y_pred_proba, label_cols, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots the distribution of predicted probabilities for each class (true positive/negative split).\n",
        "        \"\"\"\n",
        "        num_labels = len(label_cols)\n",
        "        nrows = int(np.ceil(num_labels / 2))\n",
        "        fig, axes = plt.subplots(nrows=nrows, ncols=2, figsize=(12, 4 * nrows))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            ax = axes[i]\n",
        "            # Probabilities for true negatives for this label\n",
        "            ax.hist(y_pred_proba[y_true[:, i] == 0, i], bins=50, alpha=0.7, label=f'{label_name} (True Negative)', color='skyblue')\n",
        "            # Probabilities for true positives for this label\n",
        "            ax.hist(y_pred_proba[y_true[:, i] == 1, i], bins=50, alpha=0.7, label=f'{label_name} (True Positive)', color='lightcoral')\n",
        "\n",
        "            ax.set_xlabel('Predicted Probability')\n",
        "            ax.set_ylabel('Frequency')\n",
        "            ax.set_title(f'Prob. Dist. for {label_name} {title_suffix}')\n",
        "            ax.legend()\n",
        "            ax.grid(True)\n",
        "        # Hide unused subplots\n",
        "        for i in range(num_labels, len(axes)):\n",
        "            fig.delaxes(axes[i])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'multilabel_probability_distributions_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved Multi-label Probability Distributions to {plot_filename}\", flush=True)\n",
        "\n",
        "\n",
        "    def objective(self, trial):\n",
        "        \"\"\"\n",
        "        The main Optuna objective function for hyperparameter optimization for multi-label.\n",
        "        It performs cross-validation for each trial to get a robust evaluation score.\n",
        "        \"\"\"\n",
        "        # Suggest hyperparameters for the current trial based on the search space\n",
        "        params = {\n",
        "            'learning_rate': trial.suggest_loguniform('learning_rate', *Config.SEARCH_SPACE['learning_rate']),\n",
        "            'per_device_train_batch_size': trial.suggest_categorical('batch_size', Config.SEARCH_SPACE['batch_size']),\n",
        "            'num_train_epochs': trial.suggest_int('num_train_epochs', *Config.SEARCH_SPACE['num_train_epochs']),\n",
        "            'warmup_ratio': trial.suggest_float('warmup_ratio', *Config.SEARCH_SPACE['warmup_ratio']),\n",
        "            'weight_decay': trial.suggest_float('weight_decay', *Config.SEARCH_SPACE['weight_decay']),\n",
        "            'gradient_accumulation_steps': trial.suggest_categorical('gradient_accumulation_steps', Config.SEARCH_SPACE['gradient_accumulation_steps']),\n",
        "            'lr_scheduler_type': trial.suggest_categorical('lr_scheduler_type', Config.SEARCH_SPACE['lr_scheduler_type']),\n",
        "            'oversampling_ratio': trial.suggest_float('oversampling_ratio', *Config.SEARCH_SPACE['oversampling_ratio'])\n",
        "        }\n",
        "\n",
        "        # Extract oversampling_ratio as it's a custom parameter, not for TrainingArguments\n",
        "        oversampling_ratio = params.pop('oversampling_ratio') # Use .pop() to remove it from params\n",
        "\n",
        "        print(f\"\\nTrial {trial.number} parameters:\", flush=True)\n",
        "        for key, value in params.items():\n",
        "            print(f\"    {key}: {value}\", flush=True)\n",
        "        print(f\"    oversampling_ratio: {oversampling_ratio}\", flush=True)\n",
        "\n",
        "        cv_scores = [] # To store micro-F1 scores from each fold\n",
        "\n",
        "        # Use KFold for cross-validation on indices.\n",
        "        kf = KFold(n_splits=Config.CV_FOLDS, shuffle=True, random_state=Config.RANDOM_SEED)\n",
        "\n",
        "        # Split on the indices of the original dataframe\n",
        "        for fold, (train_idx, val_idx) in enumerate(kf.split(self.train_df)):\n",
        "            print(f\"\\n    Fold {fold + 1}/{Config.CV_FOLDS}\", flush=True)\n",
        "\n",
        "            fold_train_df_original = self.train_df.iloc[train_idx].reset_index(drop=True)\n",
        "            fold_val_df = self.train_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "            # --- Apply Hybrid Sampling only on the training set for this fold ---\n",
        "            resampled_texts, resampled_labels_df = self._apply_sampling(\n",
        "                X_train=fold_train_df_original['comment_text'],\n",
        "                y_train=fold_train_df_original[Config.LABEL_COLS],\n",
        "                oversampling_ratio=oversampling_ratio, # Use the extracted oversampling_ratio\n",
        "                sampling_strategy='hybrid' # Using hybrid sampling (SMOTETomek)\n",
        "            )\n",
        "            print(f\"    Training data after sampling: {len(resampled_texts)} samples\", flush=True)\n",
        "\n",
        "            train_dataset = ToxicDataset(\n",
        "                resampled_texts, # Use resampled texts\n",
        "                resampled_labels_df, # Use resampled labels\n",
        "                self.tokenizer,\n",
        "                Config.MAX_LENGTH,\n",
        "                augment=True\n",
        "            )\n",
        "\n",
        "            val_dataset = ToxicDataset(\n",
        "                fold_val_df['comment_text'],\n",
        "                fold_val_df[Config.LABEL_COLS],\n",
        "                self.tokenizer,\n",
        "                Config.MAX_LENGTH\n",
        "            )\n",
        "\n",
        "            safety_model = self._create_model(trial)\n",
        "\n",
        "            output_dir_fold = os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, f'results_trial_{trial.number}_fold_{fold}')\n",
        "            os.makedirs(output_dir_fold, exist_ok=True)\n",
        "\n",
        "            training_args = TrainingArguments(\n",
        "                output_dir=output_dir_fold,\n",
        "                eval_strategy=\"epoch\",\n",
        "                save_strategy=\"epoch\",\n",
        "                logging_strategy=\"epoch\",\n",
        "                per_device_eval_batch_size=params['per_device_train_batch_size'],\n",
        "                save_total_limit=2,\n",
        "                load_best_model_at_end=True,\n",
        "                metric_for_best_model=\"eval_f1\",\n",
        "                greater_is_better=True,\n",
        "                report_to=\"none\",\n",
        "                seed=Config.RANDOM_SEED,\n",
        "                fp16=torch.cuda.is_available(),\n",
        "                dataloader_pin_memory=False,\n",
        "                learning_rate=params['learning_rate'],\n",
        "                per_device_train_batch_size=params['per_device_train_batch_size'],\n",
        "                num_train_epochs=params['num_train_epochs'],\n",
        "                warmup_ratio=params['warmup_ratio'],\n",
        "                weight_decay=params['weight_decay'],\n",
        "                gradient_accumulation_steps=params['gradient_accumulation_steps'],\n",
        "                lr_scheduler_type=params['lr_scheduler_type']\n",
        "            )\n",
        "\n",
        "            trainer = AdvancedTrainer(\n",
        "                model=safety_model,\n",
        "                args=training_args,\n",
        "                train_dataset=train_dataset,\n",
        "                eval_dataset=val_dataset,\n",
        "                compute_metrics=self.metrics_calculator.compute_metrics,\n",
        "                pos_weights=self.pos_weights,\n",
        "                callbacks=[EarlyStoppingCallback(early_stopping_patience=Config.PATIENCE)],\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                trainer.train()\n",
        "                eval_results = trainer.evaluate()\n",
        "                # 'eval_f1' is correctly used as the primary metric, which your\n",
        "                # compute_metrics function should set to be the macro F1 for optimization.\n",
        "                fold_score = eval_results['eval_f1']\n",
        "\n",
        "                print(f\"    Fold {fold + 1} Results (Optimized Metric: Macro F1): {fold_score:.4f}\", flush=True)\n",
        "                print(f\"      Macro F1 (from eval_results): {eval_results.get('eval_macro_f1', fold_score):.4f}\", flush=True)\n",
        "                print(f\"      Micro F1: {eval_results.get('eval_micro_f1', 'N/A'):.4f}\", flush=True)\n",
        "                print(f\"      Micro Precision: {eval_results.get('eval_micro_precision', 'N/A'):.4f}\", flush=True)\n",
        "                print(f\"      Micro Recall: {eval_results.get('eval_micro_recall', 'N/A'):.4f}\", flush=True)\n",
        "                print(f\"      Micro ROC-AUC: {eval_results.get('eval_micro_roc_auc', 'N/A'):.4f}\", flush=True)\n",
        "\n",
        "                self._plot_training_history(trainer.state.log_history, output_dir_fold, f\"Fold {fold + 1}\")\n",
        "\n",
        "                cv_scores.append(fold_score)\n",
        "            except Exception as e:\n",
        "                # Improved error reporting for easier debugging\n",
        "                print(f\"    Fold {fold + 1} failed: {type(e).__name__}: {str(e)}\", flush=True)\n",
        "                cv_scores.append(0.0) # Append 0.0 or handle as per your Optuna study design\n",
        "\n",
        "        mean_cv_score = np.mean(cv_scores)\n",
        "        std_cv_score = np.std(cv_scores)\n",
        "\n",
        "        print(f\"\\nTrial {trial.number} Results:\", flush=True)\n",
        "        print(f\"    Mean CV Micro F1: {mean_cv_score:.4f} ± {std_cv_score:.4f}\", flush=True)\n",
        "\n",
        "        return mean_cv_score\n",
        "\n",
        "    def run_optimization(self): # Renamed from optimize to run_optimization for clarity\n",
        "        \"\"\"\n",
        "        Runs the Optuna hyperparameter optimization study for multi-label classification.\n",
        "        Incorporates Hyperband pruning for efficient search.\n",
        "        \"\"\"\n",
        "        print(\"Starting hyperparameter optimization...\", flush=True)\n",
        "        print(f\"Search space: {Config.SEARCH_SPACE}\", flush=True)\n",
        "\n",
        "        # Determine max_resource for Hyperband Pruner based on your Config.N_TRAIN_EPOCHS range\n",
        "        # Assuming Config.SEARCH_SPACE['num_train_epochs'] is the upper bound of your epochs search space\n",
        "        max_epochs_for_pruner = Config.SEARCH_SPACE['num_train_epochs'][1]\n",
        "\n",
        "        # Initialize Hyperband Pruner\n",
        "        pruner = HyperbandPruner(\n",
        "            min_resource=1,         # Pruning can start after the first epoch/step\n",
        "            max_resource=max_epochs_for_pruner, # Max epochs a trial can run, matching your search space\n",
        "            reduction_factor=3      # Common reduction factor for Hyperband\n",
        "        )\n",
        "\n",
        "        # Ensure the directory for the Optuna DB exists\n",
        "        db_dir = os.path.dirname(Config.OPTUNA_DB_PATH.replace(\"sqlite:///\", \"\"))\n",
        "        os.makedirs(db_dir, exist_ok=True)\n",
        "        print(f\"Optuna DB directory ensured: {db_dir}\", flush=True)\n",
        "\n",
        "        study = optuna.create_study(\n",
        "            direction='maximize',\n",
        "            study_name='electra_toxic_multilabel_classification',\n",
        "            storage=f'sqlite:///{Config.OPTUNA_DB_PATH}',\n",
        "            load_if_exists=True,\n",
        "            sampler=TPESampler(seed=Config.RANDOM_SEED), # Use TPESampler for efficient search\n",
        "            pruner=pruner # Use the Hyperband Pruner\n",
        "        )\n",
        "\n",
        "        print(f\"Running {Config.N_TRIALS} trials with Hyperband Pruner...\", flush=True)\n",
        "        study.optimize(self.objective, n_trials=Config.N_TRIALS, show_progress_bar=True)\n",
        "\n",
        "        print(\"\\nOptimization completed! ✨\", flush=True)\n",
        "        print(f\"Best trial number: {study.best_trial.number}\", flush=True)\n",
        "\n",
        "        # Ensure this matches your metric_for_best_model, which should be 'macro_f1'\n",
        "        print(f\"Best Macro F1: {study.best_value:.4f}\", flush=True)\n",
        "\n",
        "        print(\"Best parameters found: 🚀\", flush=True)\n",
        "        for key, value in study.best_params.items():\n",
        "            print(f\"   {key}: {value}\", flush=True)\n",
        "\n",
        "        return study\n",
        "\n",
        "    def get_optuna_summary_data(self, study):\n",
        "        \"\"\"\n",
        "        Collects summary data for all Optuna trials.\n",
        "        \"\"\"\n",
        "        summary_data = {\n",
        "            \"total_trials_completed\": len(study.trials),\n",
        "            \"best_trial_number\": study.best_trial.number,\n",
        "            \"best_objective_value\": study.best_value,\n",
        "            \"best_hyperparameters\": study.best_trial.params,\n",
        "            \"trial_history\": []\n",
        "        }\n",
        "\n",
        "        # Collect summary for each trial\n",
        "        for trial in study.trials:\n",
        "            trial_info = {\n",
        "                \"trial_number\": trial.number,\n",
        "                \"state\": str(trial.state),\n",
        "                \"value\": trial.value,\n",
        "                \"params\": trial.params,\n",
        "                \"duration_seconds\": trial.duration.total_seconds() if trial.duration else None\n",
        "            }\n",
        "            summary_data[\"trial_history\"].append(trial_info)\n",
        "\n",
        "        return summary_data\n",
        "\n",
        "    def train_final_model(self, best_params, save_path=None):\n",
        "        \"\"\"\n",
        "        Trains the final model using the best hyperparameters found during optimization.\n",
        "        \"\"\"\n",
        "        if save_path is None:\n",
        "            save_path = os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, \"best_electra_multilabel_model\")\n",
        "\n",
        "        print(\"\\nTraining final model with best parameters...\", flush=True)\n",
        "\n",
        "        # Apply sampling to the entire training set for the final model\n",
        "        resampled_texts, resampled_labels_df = self._apply_sampling(\n",
        "            X_train=self.train_df['comment_text'],\n",
        "            y_train=self.train_df[Config.LABEL_COLS],\n",
        "            oversampling_ratio=best_params.get('oversampling_ratio', 0.5), # Use optimized ratio or default\n",
        "            sampling_strategy='hybrid'\n",
        "        )\n",
        "        print(f\"Final training data after sampling: {len(resampled_texts)} samples\", flush=True)\n",
        "\n",
        "\n",
        "        train_dataset = ToxicDataset(\n",
        "            resampled_texts,\n",
        "            resampled_labels_df,\n",
        "            self.tokenizer,\n",
        "            Config.MAX_LENGTH,\n",
        "            augment=True\n",
        "        )\n",
        "\n",
        "        val_dataset = None\n",
        "        if self.val_df is not None:\n",
        "            val_dataset = ToxicDataset(\n",
        "                self.val_df['comment_text'],\n",
        "                self.val_df[Config.LABEL_COLS], # Pass all labels for validation\n",
        "                self.tokenizer,\n",
        "                Config.MAX_LENGTH\n",
        "            )\n",
        "\n",
        "        safety_model = self._create_model()\n",
        "        # Apply dropout parameters from best_params if they exist\n",
        "        if 'hidden_dropout_prob' in best_params:\n",
        "            safety_model.config.hidden_dropout_prob = best_params['hidden_dropout_prob']\n",
        "        if 'attention_probs_dropout_prob' in best_params:\n",
        "            safety_model.config.attention_probs_dropout_prob = best_params['attention_probs_dropout_prob']\n",
        "\n",
        "        output_dir_final = os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, 'final_electra_multilabel_model_results')\n",
        "        os.makedirs(output_dir_final, exist_ok=True)\n",
        "\n",
        "        # Prepare TrainingArguments for the final training run\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir_final,\n",
        "            eval_strategy=\"epoch\" if val_dataset else \"no\",\n",
        "            save_strategy=\"epoch\",\n",
        "            logging_strategy=\"epoch\",\n",
        "            per_device_train_batch_size=best_params.get('batch_size', 16),\n",
        "            per_device_eval_batch_size=best_params.get('batch_size', 16),\n",
        "            num_train_epochs=best_params.get('num_train_epochs', 3),\n",
        "            learning_rate=best_params.get('learning_rate', 2e-5),\n",
        "            warmup_ratio=best_params.get('warmup_ratio', 0.1),\n",
        "            weight_decay=best_params.get('weight_decay', 0.01),\n",
        "            gradient_accumulation_steps=best_params.get('gradient_accumulation_steps', 1),\n",
        "            lr_scheduler_type=best_params.get('lr_scheduler_type', 'linear'),\n",
        "            save_total_limit=3, # Keep up to 3 best checkpoints\n",
        "            load_best_model_at_end=True if val_dataset else False,\n",
        "            metric_for_best_model=\"eval_f1\" if val_dataset else None, # Micro F1 for multilabel\n",
        "            greater_is_better=True,\n",
        "            report_to=\"none\",\n",
        "            seed=Config.RANDOM_SEED,\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            dataloader_pin_memory=False,\n",
        "        )\n",
        "\n",
        "        trainer = AdvancedTrainer(\n",
        "            model=safety_model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            compute_metrics=self.metrics_calculator.compute_metrics,\n",
        "            pos_weights=self.pos_weights, # Pass tensor of pos_weights\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=Config.PATIENCE)] if val_dataset else [],\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        if val_dataset:\n",
        "            final_eval_results = trainer.evaluate()\n",
        "            print(\"\\nFinal Model Evaluation Results:\", flush=True)\n",
        "            for k, v in final_eval_results.items():\n",
        "                if k.startswith('eval_'): # Print metrics that were evaluated\n",
        "                    print(f\"    {k.replace('eval_', '')}: {v:.4f}\", flush=True)\n",
        "                elif k.endswith('_f1') or k.endswith('_precision') or k.endswith('_recall') or k.endswith('_roc_auc') or k.endswith('_pr_auc'):\n",
        "                    print(f\"    {k}: {v:.4f}\", flush=True)\n",
        "\n",
        "\n",
        "            # Get true labels and predicted probabilities from the final evaluation\n",
        "            predictions = trainer.predict(val_dataset)\n",
        "            y_true_final = predictions.label_ids\n",
        "            y_pred_proba_final = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n",
        "\n",
        "            # Optimize thresholds on the final validation set for comprehensive evaluation\n",
        "            print(\"\\nOptimizing classification thresholds for final model evaluation...\", flush=True)\n",
        "            best_thresholds_final, best_threshold_score_final = self.metrics_calculator.optimize_thresholds(\n",
        "                y_true_final, y_pred_proba_final, n_trials=100\n",
        "            )\n",
        "            print(f\"Optimized micro F1 (threshold tuning): {best_threshold_score_final:.4f}\", flush=True)\n",
        "            print(\"Optimized thresholds:\", flush=True)\n",
        "            for i, label_name in enumerate(Config.LABEL_COLS):\n",
        "                print(f\"    {best_thresholds_final[i]:.3f}\", flush=True) # Corrected variable name\n",
        "\n",
        "            # Re-evaluate with optimized thresholds to get final confusion matrices and plots\n",
        "            final_binary_preds = (y_pred_proba_final > np.array(best_thresholds_final)).astype(int)\n",
        "\n",
        "            self._plot_training_history(trainer.state.log_history, output_dir_final, \"Final Model\")\n",
        "            self._plot_multilabel_confusion_matrix(y_true_final, final_binary_preds, Config.LABEL_COLS, output_dir_final, \"Final Model\")\n",
        "            self._plot_precision_recall_curve_multilabel(y_true_final, y_pred_proba_final, Config.LABEL_COLS, output_dir_final, \"Final Model\")\n",
        "            self._plot_roc_curve_multilabel(y_true_final, y_pred_proba_final, Config.LABEL_COLS, output_dir_final, \"Final Model\")\n",
        "            self._plot_probability_distribution_multilabel(y_true_final, y_pred_proba_final, Config.LABEL_COLS, output_dir_final, \"Final Model\")\n",
        "\n",
        "            # Save the optimized thresholds to a CSV file\n",
        "            threshold_df = pd.DataFrame({\n",
        "                'label': Config.LABEL_COLS,\n",
        "                'threshold': best_thresholds_final\n",
        "            })\n",
        "            threshold_df.to_csv(os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, 'optimized_thresholds_multilabel.csv'), index=False)\n",
        "            print(f\"Final optimized thresholds saved to {os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, 'optimized_thresholds_multilabel.csv')}\", flush=True)\n",
        "\n",
        "\n",
        "        trainer.save_model(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "\n",
        "        print(f\"Final model saved to {save_path}\", flush=True)\n",
        "\n",
        "        return trainer\n",
        "\n",
        "\n",
        "# Helper function for LIME predictions (needs to be outside classes to be easily callable by LIME)\n",
        "def predict_proba_for_lime(texts, model, tokenizer, max_length, device):\n",
        "    \"\"\"\n",
        "    Predictor function required by LIME. Takes a list of raw texts and returns\n",
        "    prediction probabilities for each class.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    ).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probabilities = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "    return probabilities\n",
        "\n",
        "def main():\n",
        "    set_seed(Config.RANDOM_SEED) # Ensure reproducibility\n",
        "\n",
        "    # Create the base directory for saving results\n",
        "    os.makedirs(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, exist_ok=True)\n",
        "    print(f\"Google Drive base save path ensured: {Config.GOOGLE_DRIVE_SAVE_BASE_PATH}\", flush=True)\n",
        "\n",
        "    print(\"Loading data...\", flush=True)\n",
        "    try:\n",
        "        # Load your datasets as specified\n",
        "        train_df = pd.read_csv(\"train.csv\")\n",
        "        test_df = pd.read_csv(\"test.csv\")\n",
        "        test_labels = pd.read_csv(\"test_labels.csv\")\n",
        "        sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "        print(\"Data loaded successfully.\", flush=True)\n",
        "        print(f\"Train DataFrame shape: {train_df.shape}\", flush=True)\n",
        "        print(f\"Test DataFrame shape: {test_df.shape}\", flush=True)\n",
        "        print(f\"Test Labels DataFrame shape: {test_labels.shape}\", flush=True)\n",
        "        print(f\"Sample Submission DataFrame shape: {sample_submission.shape}\", flush=True)\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: One or more dataset files (train.csv, test.csv, test_labels.csv, sample_submission.csv) not found.\", flush=True)\n",
        "        print(\"Please ensure all required CSV files are in the same directory as the script.\", flush=True)\n",
        "        return\n",
        "\n",
        "    # Fill NaN values in 'comment_text'\n",
        "    train_df['comment_text'] = train_df['comment_text'].fillna('')\n",
        "    test_df['comment_text'] = test_df['comment_text'].fillna('') # Also fill for test_df if needed\n",
        "\n",
        "    # --- Use all original labels directly for multilabel classification ---\n",
        "    # Ensure all label columns are present\n",
        "    if not all(col in train_df.columns for col in Config.LABEL_COLS):\n",
        "        print(f\"Error: One or more label columns {Config.LABEL_COLS} not found in the training dataset. Exiting.\", flush=True)\n",
        "        return\n",
        "\n",
        "    print(f\"\\nLabel columns being used for training: {Config.LABEL_COLS}\", flush=True)\n",
        "\n",
        "    # Display class distribution for each label (important for multilabel)\n",
        "    print(\"\\nMultilabel Class distribution (Positive count and percentage in training data):\", flush=True)\n",
        "    for col in Config.LABEL_COLS:\n",
        "        pos_count = train_df[col].sum()\n",
        "        total_count = len(train_df)\n",
        "        pos_pct = (pos_count / total_count) * 100\n",
        "        print(f\"  '{col}': {pos_count:,} positive samples ({pos_pct:.2f}%)\", flush=True)\n",
        "\n",
        "    # Splitting the main training data into a training and validation set\n",
        "    # This validation set is used for the *final model training* and evaluation,\n",
        "    # distinct from the CV folds within Optuna.\n",
        "    print(\"\\nSplitting training data into train and validation sets (80/20 split)...\", flush=True)\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        train_df['comment_text'],\n",
        "        train_df[Config.LABEL_COLS],\n",
        "        test_size=0.2,\n",
        "        random_state=Config.RANDOM_SEED,\n",
        "        stratify=train_df['toxic'] # Stratify by 'toxic' label for a more balanced split\n",
        "    )\n",
        "\n",
        "    # Reconstruct dataframes for ModelOptimizer\n",
        "    train_df_for_optimizer = pd.DataFrame({'comment_text': train_texts}).reset_index(drop=True)\n",
        "    train_labels_for_optimizer = train_labels.reset_index(drop=True)\n",
        "    val_df_for_optimizer = pd.DataFrame({'comment_text': val_texts}).reset_index(drop=True)\n",
        "    val_labels_for_optimizer = val_labels.reset_index(drop=True)\n",
        "\n",
        "    # Merge texts and labels back for convenience in ModelOptimizer initialization\n",
        "    # (ModelOptimizer expects the full train_df with 'comment_text' and all label columns)\n",
        "    train_combined_df = pd.concat([train_df_for_optimizer, train_labels_for_optimizer], axis=1)\n",
        "    val_combined_df = pd.concat([val_df_for_optimizer, val_labels_for_optimizer], axis=1) # Pass this to ModelOptimizer\n",
        "\n",
        "    print(f\"Training set size for final model: {len(train_combined_df)}\", flush=True)\n",
        "    print(f\"Validation set size for final model: {len(val_combined_df)}\", flush=True)\n",
        "\n",
        "    optimizer = ModelOptimizer(train_combined_df, val_combined_df) # Pass val_combined_df here\n",
        "\n",
        "    best_params = {}\n",
        "    study = None # Initialize study to None\n",
        "    if Config.LOAD_EXISTING_STUDY_RESULTS:\n",
        "        print(f\"\\nAttempting to load existing Optuna study from {Config.OPTUNA_DB_PATH}...\", flush=True)\n",
        "        try:\n",
        "            study = optuna.load_study(\n",
        "                study_name='electra_toxic_multilabel_classification',\n",
        "                storage=f'sqlite:///{Config.OPTUNA_DB_PATH}'\n",
        "            )\n",
        "            best_params = study.best_trial.params\n",
        "            print(\"Successfully loaded best parameters from existing study:\", flush=True)\n",
        "            for k, v in best_params.items():\n",
        "                print(f\"    {k}: {v}\", flush=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load existing study: {e}. Starting new optimization.\", flush=True)\n",
        "            Config.LOAD_EXISTING_STUDY_RESULTS = False # Fallback to running optimization\n",
        "\n",
        "    if not Config.LOAD_EXISTING_STUDY_RESULTS:\n",
        "        study = optimizer.run_optimization() # Changed from .optimize() to .run_optimization()\n",
        "        best_params = study.best_trial.params\n",
        "\n",
        "    # Train the final model with the best parameters\n",
        "    final_trainer = optimizer.train_final_model(best_params)\n",
        "\n",
        "    print(\"\\nTraining and optimization complete! \", flush=True)\n",
        "    print(f\"Results, model checkpoints, and plots are saved in: {Config.GOOGLE_DRIVE_SAVE_BASE_PATH}\", flush=True)\n",
        "\n",
        "    # --- Generate Optuna Summary Data ---\n",
        "    if study: # Only generate summary if a study object is available\n",
        "        optuna_summary = optimizer.get_optuna_summary_data(study)\n",
        "        print(\"\\n--- Optuna Optimization Summary Data ---\", flush=True)\n",
        "        print(json.dumps(optuna_summary, indent=2), flush=True)\n",
        "        print(\"\\n--- End of Optuna Optimization Summary Data ---\", flush=True)\n",
        "    else:\n",
        "        print(\"\\nSkipping Optuna summary data generation as no study object was available.\", flush=True)\n",
        "\n",
        "\n",
        "    # --- Explainability (XAI) Section using LIME ---\n",
        "    print(\"\\n--- Starting Explainable AI (XAI) Analysis with LIME ---\", flush=True)\n",
        "\n",
        "    # Load the best trained model and tokenizer for XAI\n",
        "    final_model_path = os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, \"best_electra_multilabel_model\")\n",
        "    try:\n",
        "        final_model = AutoModelForSequenceClassification.from_pretrained(final_model_path).to(Config.DEVICE)\n",
        "        final_tokenizer = AutoTokenizer.from_pretrained(final_model_path)\n",
        "        print(f\"Loaded final model and tokenizer from {final_model_path}\", flush=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading final model for XAI: {e}. Skipping XAI analysis.\", flush=True)\n",
        "        final_model = None # Set to None to prevent further errors if loading failed\n",
        "\n",
        "    if final_model:\n",
        "        # Prepare the predictor function for LIME\n",
        "        lime_predictor = lambda texts: predict_proba_for_lime(\n",
        "            texts, final_model, final_tokenizer, Config.MAX_LENGTH, Config.DEVICE\n",
        "        )\n",
        "\n",
        "        # Initialize LIME Explainer\n",
        "        explainer = LimeTextExplainer(class_names=Config.LABEL_COLS)\n",
        "\n",
        "        # Select a few examples for explanation from the validation set\n",
        "        # You can adjust the number of examples or criteria for selection\n",
        "        num_xai_examples = min(5, len(val_combined_df)) # Explain up to 5 examples from validation set\n",
        "        xai_examples_df = val_combined_df.sample(n=num_xai_examples, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "        for idx in range(num_xai_examples):\n",
        "            example_comment_text = xai_examples_df['comment_text'].iloc[idx]\n",
        "            true_labels = xai_examples_df[Config.LABEL_COLS].iloc[idx].values\n",
        "\n",
        "            # Get model's raw probabilities for this example\n",
        "            model_probabilities = lime_predictor([example_comment_text])[0]\n",
        "\n",
        "            print(f\"\\n--- XAI Example {idx + 1} ---\", flush=True)\n",
        "            print(f\"Comment: '{example_comment_text}'\", flush=True)\n",
        "            print(f\"True Labels: {true_labels}\", flush=True)\n",
        "            print(f\"Model Probabilities: {model_probabilities.round(3)}\", flush=True)\n",
        "\n",
        "            # Generate explanation for each relevant label\n",
        "            # You might choose to explain labels where true_label is 1 OR where model_probability > 0.5\n",
        "            for i, label_name in enumerate(Config.LABEL_COLS):\n",
        "                # Decide which labels to explain: e.g., true positive, or high predicted probability\n",
        "                if true_labels[i] == 1 or model_probabilities[i] > 0.5:\n",
        "                    print(f\"\\n  Explanation for label: '{label_name}' (True: {true_labels[i]}, Predicted Prob: {model_probabilities[i]:.3f})\", flush=True)\n",
        "                    try:\n",
        "                        # num_features: how many words to highlight\n",
        "                        # num_samples: how many perturbed samples LIME generates\n",
        "                        exp = explainer.explain_instance(\n",
        "                            example_comment_text,\n",
        "                            lime_predictor,\n",
        "                            top_labels=1, # Only get explanation for the top predicted label (within LIME's internal logic)\n",
        "                            labels=[i],  # Get explanation specifically for this label's index\n",
        "                            num_features=10, # Number of words to highlight\n",
        "                            num_samples=1000 # Number of perturbed samples for LIME to generate\n",
        "                        )\n",
        "                        # Print explanation as a list of (word, importance_score) tuples\n",
        "                        print(exp.as_list(label=i), flush=True)\n",
        "                    except Exception as e:\n",
        "                        print(f\"  Error generating LIME explanation for label '{label_name}': {e}\", flush=True)\n",
        "                else:\n",
        "                    print(f\"  Skipping explanation for label '{label_name}' (True: {true_labels[i]}, Predicted Prob: {model_probabilities[i]:.3f} - not a strong prediction or true positive)\", flush=True)\n",
        "\n",
        "    print(\"\\n--- XAI Analysis Complete ---\", flush=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Mount Google Drive if running in Colab\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    # print(\"\\nGoogle Drive mounted!\", flush=True)\n",
        "\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random # Import random for set_seed\n",
        "import re # Import re for text processing in EDA (if you combine)\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt # Import matplotlib for plotting\n",
        "import sqlite3 # Added for database integrity checks\n",
        "import json # For handling JSON data\n",
        "\n",
        "# For Hugging Face Transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# For scikit-learn utilities\n",
        "from sklearn.model_selection import KFold, train_test_split # Use KFold for CV, train_test_split for main split\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score, roc_auc_score,\n",
        "    confusion_matrix, precision_recall_curve, roc_curve, auc,\n",
        "    average_precision_score # For PR-AUC\n",
        ")\n",
        "\n",
        "# For Optuna hyperparameter optimization\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner, HyperbandPruner\n",
        "from optuna.samplers import TPESampler # Explicitly import TPESampler\n",
        "\n",
        "# For Imbalance Handling (SMOTE and SMOTETomek)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# For Explainable AI (XAI)\n",
        "from lime.lime_text import LimeTextExplainer # Import LIME\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- IMPORTANT: Explicitly disable Weights & Biases logging entirely ---\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# Configuration Class\n",
        "\n",
        "class Config:\n",
        "    # Model and Tokenizer Settings\n",
        "    MODEL_NAME = \"google/electra-base-discriminator\"\n",
        "    MAX_LENGTH = 256  # Maximum sequence length for tokenization\n",
        "\n",
        "    # Device Configuration\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU if available, else CPU\n",
        "\n",
        "    # Reproducibility\n",
        "    RANDOM_SEED = 42 # Seed for all random number generators to ensure reproducibility\n",
        "\n",
        "    # Optuna Hyperparameter Optimization Settings\n",
        "    N_TRIALS = 5 # Number of Optuna trials for hyperparameter optimization\n",
        "    CV_FOLDS = 5  # Number of folds for cross-validation during Optuna trials\n",
        "    PATIENCE = 3  # Early stopping patience for the Trainer\n",
        "\n",
        "    # Label Columns for Multi-label Classification\n",
        "    LABEL_COLS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "    # Original multi-labels (kept for reference, same as LABEL_COLS now)\n",
        "    ORIGINAL_LABEL_COLS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "    # Optuna Search Spaces for Hyperparameters\n",
        "    SEARCH_SPACE = {\n",
        "        'learning_rate': (5e-6, 5e-5), # General range for transformer fine-tuning (log-uniform)\n",
        "        'batch_size': [16, 32],        # Recommended batch sizes (categorical)\n",
        "        'num_train_epochs': (2, 5),    # Recommended epoch range for transformers (integer)\n",
        "        'warmup_ratio': (0.05, 0.2),   # Warmup ratio for learning rate scheduler (float)\n",
        "        'weight_decay': (0.0, 0.1),    # Regularization to prevent overfitting (float)\n",
        "        'hidden_dropout_prob': (0.1, 0.3), # Dropout for hidden layers (float)\n",
        "        'attention_probs_dropout_prob': (0.1, 0.2), # Dropout for attention probabilities (float)\n",
        "        'gradient_accumulation_steps': [1, 2, 4], # Accumulate gradients to simulate larger batch sizes (categorical)\n",
        "        'lr_scheduler_type': ['linear', 'cosine'], # Learning rate scheduler types (categorical)\n",
        "        # New hyperparameter for oversampling ratio (for SMOTE/SMOTETomek)\n",
        "        'oversampling_ratio': (0.1, 1.0) # From 10% to 100% of minority class size (float)\n",
        "    }\n",
        "\n",
        "    # --- Google Drive Save Path Configuration ---\n",
        "    # IMPORTANT: Ensure your Google Drive is mounted at /content/drive/\n",
        "    # This is the base path where all models, plots, and CSVs will be saved.\n",
        "    GOOGLE_DRIVE_SAVE_BASE_PATH = \"/content/drive/MyDrive/my_electra_multilabel_classifier_results\"\n",
        "\n",
        "    # --- Optuna Persistent Storage Path ---\n",
        "    # This is where Optuna's study state will be saved (SQLite database)\n",
        "    # Using the defined GOOGLE_DRIVE_SAVE_BASE_PATH directly\n",
        "    OPTUNA_DB_PATH = os.path.join(GOOGLE_DRIVE_SAVE_BASE_PATH, 'optuna_electra_multilabel_study.db')\n",
        "\n",
        "    # --- New: Option to load existing Optuna study results ---\n",
        "    # Set to True if you want to skip re-running Optuna optimization\n",
        "    # and instead load the best parameters from a saved Optuna DB.\n",
        "    LOAD_EXISTING_STUDY_RESULTS = True # Changed to True to stop further optimization\n",
        "\n",
        "# Set seeds for reproducibility across different libraries\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed) # For Python's built-in random module\n",
        "\n",
        "# Dataset Class\n",
        "class ToxicDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Enhanced dataset class for multi-label toxic comment classification.\n",
        "    Supports text augmentation and prepares data for Hugging Face models.\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels_df, tokenizer, max_length, augment=False):\n",
        "        self.texts = texts\n",
        "        self.labels = labels_df # Now a DataFrame with multiple label columns\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.augment = augment # Flag to enable/disable augmentation\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves a sample from the dataset.\n",
        "        Applies augmentation if enabled and randomly triggered.\n",
        "        Tokenizes the text and returns a dictionary of input features and a multi-label tensor.\n",
        "        \"\"\"\n",
        "        text = str(self.texts.iloc[idx])\n",
        "\n",
        "        # Simple augmentation for toxic comments to increase diversity\n",
        "        if self.augment and np.random.random() < 0.3:\n",
        "            text = self._augment_text(text)\n",
        "\n",
        "        # Tokenize the text using the pre-trained tokenizer\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,        # Truncate to max_length if longer\n",
        "            padding='max_length',   # Pad to max_length if shorter\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'     # Return PyTorch tensors\n",
        "        )\n",
        "\n",
        "        # Return a FloatTensor of shape [num_labels] for multi-label classification\n",
        "        # Ensure labels are converted to float32\n",
        "        labels_tensor = torch.FloatTensor(self.labels.iloc[idx].values)\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),      # Flatten input_ids tensor\n",
        "            'attention_mask': encoding['attention_mask'].flatten(), # Flatten attention_mask tensor\n",
        "            'labels': labels_tensor # Tensor of shape [num_labels]\n",
        "        }\n",
        "\n",
        "    def _augment_text(self, text):\n",
        "        \"\"\"\n",
        "        Applies simple text augmentation techniques.\n",
        "        Currently implements random case changes for a single word.\n",
        "        \"\"\"\n",
        "        words = text.split()\n",
        "        if len(words) > 2:\n",
        "            # Randomly select a word and change its case\n",
        "            idx = np.random.randint(0, len(words))\n",
        "            if np.random.random() < 0.5:\n",
        "                words[idx] = words[idx].upper() # Convert to uppercase\n",
        "            else:\n",
        "                words[idx] = words[idx].lower() # Convert to lowercase\n",
        "        return ' '.join(words)\n",
        "\n",
        "# AdvancedTrainer Class\n",
        "class AdvancedTrainer(Trainer):\n",
        "    \"\"\"\n",
        "    Custom Hugging Face Trainer with advanced features:\n",
        "    - Custom loss function for class weighting (BCEWithLogitsLoss with pos_weight).\n",
        "    - Stores prediction thresholds for evaluation.\n",
        "    \"\"\"\n",
        "    def __init__(self, pos_weights=None, thresholds=None, **kwargs):\n",
        "        _pos_weights = pos_weights\n",
        "        _thresholds = thresholds\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # pos_weights should now be a tensor of shape [num_labels]\n",
        "        self.pos_weights = _pos_weights\n",
        "        # thresholds will be a list of floats, one for each label\n",
        "        self.thresholds = _thresholds or [0.5] * len(Config.LABEL_COLS)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        \"\"\"\n",
        "        Custom loss computation using BCEWithLogitsLoss for multi-label classification.\n",
        "        Applies `pos_weight` for class imbalance handling if provided.\n",
        "        \"\"\"\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "\n",
        "        # Logits will be [batch_size, num_labels], labels will be [batch_size, num_labels]\n",
        "        # No squeezing needed here, as BCEWithLogitsLoss expects this shape for multi-label\n",
        "\n",
        "        # Explicitly cast to float32 to prevent potential dtype mismatches with CUDA kernels\n",
        "        if labels.dtype != torch.float32:\n",
        "            labels = labels.to(torch.float32)\n",
        "        if logits.dtype != torch.float32:\n",
        "            logits = logits.to(torch.float32)\n",
        "\n",
        "        # Use BCEWithLogitsLoss which is numerically stable and handles sigmoid internally.\n",
        "        # Apply pos_weight for class balancing as recommended.\n",
        "        if self.pos_weights is not None:\n",
        "            # pos_weight needs to be a tensor of shape [num_labels]\n",
        "            loss_fct = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights.to(logits.device))\n",
        "        else:\n",
        "            loss_fct = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        # The 'num_items_in_batch' argument is now accepted to align with Hugging Face Trainer API changes.\n",
        "        # You do not need to explicitly use this argument within your loss calculation for BCEWithLogitsLoss,\n",
        "        # but its presence in the signature is essential to avoid the TypeError.\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# MetricsCalculator Class\n",
        "class MetricsCalculator:\n",
        "    \"\"\"\n",
        "    Handles calculation of various classification metrics and threshold optimization\n",
        "    for multi-label classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, label_cols):\n",
        "        self.label_cols = label_cols\n",
        "\n",
        "    def compute_metrics(self, eval_pred, thresholds=None):\n",
        "        \"\"\"\n",
        "        Computes comprehensive evaluation metrics (F1, Precision, Recall, AUC, PR-AUC)\n",
        "        for multi-label classification, including per-label, micro, and macro averages.\n",
        "        \"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "\n",
        "        # Apply sigmoid to logits to get probabilities\n",
        "        sigmoid_preds = torch.sigmoid(torch.tensor(predictions)).numpy()\n",
        "        labels = labels.astype(int) # Ensure labels are integers for sklearn metrics\n",
        "\n",
        "        # Use provided thresholds or default to 0.5 for all labels\n",
        "        thresholds = thresholds if thresholds is not None else [0.5] * len(self.label_cols)\n",
        "\n",
        "        metrics = {}\n",
        "        all_binary_preds = []\n",
        "        all_y_true = []\n",
        "        all_y_proba = []\n",
        "\n",
        "        # Calculate metrics for each label and store for macro/micro averaging\n",
        "        for i, label_name in enumerate(self.label_cols):\n",
        "            y_true_label = labels[:, i]\n",
        "            y_pred_proba_label = sigmoid_preds[:, i]\n",
        "            threshold_label = thresholds[i]\n",
        "\n",
        "            binary_preds_label = (y_pred_proba_label > threshold_label).astype(int)\n",
        "\n",
        "            # Store flattened arrays for micro averaging later\n",
        "            all_y_true.extend(y_true_label)\n",
        "            all_binary_preds.extend(binary_preds_label)\n",
        "            all_y_proba.extend(y_pred_proba_label)\n",
        "\n",
        "            # Per-label metrics with robust error handling for AUC/PR-AUC\n",
        "            try:\n",
        "                f1 = f1_score(y_true_label, binary_preds_label, zero_division=0)\n",
        "                precision = precision_score(y_true_label, binary_preds_label, zero_division=0)\n",
        "                recall = recall_score(y_true_label, binary_preds_label, zero_division=0)\n",
        "\n",
        "                auc_score = 0.0\n",
        "                if len(np.unique(y_true_label)) > 1: # AUC needs at least two unique classes\n",
        "                    auc_score = roc_auc_score(y_true_label, y_pred_proba_label)\n",
        "\n",
        "                avg_precision = 0.0\n",
        "                if len(np.unique(y_true_label)) > 1: # PR-AUC also needs at least two unique classes\n",
        "                    avg_precision = average_precision_score(y_true_label, y_pred_proba_label)\n",
        "\n",
        "                tn, fp, fn, tp = confusion_matrix(y_true_label, binary_preds_label).ravel()\n",
        "            except Exception as e:\n",
        "                # Catch any error during per-label calculation and assign defaults\n",
        "                print(f\"Warning: Error computing per-label metrics for '{label_name}': {e}\", flush=True)\n",
        "                f1, precision, recall, auc_score, avg_precision = 0.0, 0.0, 0.0, 0.0, 0.0\n",
        "                tn, fp, fn, tp = 0, 0, 0, 0\n",
        "\n",
        "            metrics[f'{label_name}_f1'] = f1\n",
        "            metrics[f'{label_name}_precision'] = precision\n",
        "            metrics[f'{label_name}_recall'] = recall\n",
        "            metrics[f'{label_name}_roc_auc'] = auc_score\n",
        "            metrics[f'{label_name}_pr_auc'] = avg_precision # Average Precision (PR AUC)\n",
        "            metrics[f'{label_name}_tn'] = tn\n",
        "            metrics[f'{label_name}_fp'] = fp\n",
        "            metrics[f'{label_name}_fn'] = fn\n",
        "            metrics[f'{label_name}_tp'] = tp\n",
        "\n",
        "        # Calculate Micro F1/Precision/Recall/AUC\n",
        "        try:\n",
        "            metrics['micro_f1'] = f1_score(all_y_true, all_binary_preds, average='micro', zero_division=0)\n",
        "            metrics['micro_precision'] = precision_score(all_y_true, all_binary_preds, average='micro', zero_division=0)\n",
        "            metrics['micro_recall'] = recall_score(all_y_true, all_binary_preds, average='micro', zero_division=0)\n",
        "\n",
        "            # Micro-AUC on flattened arrays\n",
        "            if len(np.unique(all_y_true)) > 1 and len(np.unique(all_y_proba)) > 1:\n",
        "                metrics['micro_roc_auc'] = roc_auc_score(all_y_true, all_y_proba)\n",
        "            else:\n",
        "                metrics['micro_roc_auc'] = 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Error computing micro metrics: {e}\", flush=True)\n",
        "            metrics['micro_f1'], metrics['micro_precision'], metrics['micro_recall'], metrics['micro_roc_auc'] = 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "\n",
        "        # Calculate Macro F1/Precision/Recall/AUC\n",
        "        binary_preds_all_labels = (sigmoid_preds > np.array(thresholds)).astype(int)\n",
        "\n",
        "        try:\n",
        "            metrics['macro_f1'] = f1_score(labels, binary_preds_all_labels, average='macro', zero_division=0)\n",
        "            metrics['macro_precision'] = precision_score(labels, binary_preds_all_labels, average='macro', zero_division=0)\n",
        "            metrics['macro_recall'] = recall_score(labels, binary_preds_all_labels, average='macro', zero_division=0)\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Failed to compute overall macro F1/Precision/Recall: {e}\", flush=True)\n",
        "            metrics['macro_f1'], metrics['macro_precision'], metrics['macro_recall'] = 0.0, 0.0, 0.0\n",
        "\n",
        "        # Macro AUC (average of per-label AUCs)\n",
        "        metrics['macro_roc_auc'] = np.mean([metrics[f'{label_name}_roc_auc'] for label_name in self.label_cols])\n",
        "\n",
        "        # Trainer uses this as the primary metric for best model selection.\n",
        "        # This key must match `metric_for_best_model` in your TrainingArguments.\n",
        "        # We're setting it to macro_f1 as discussed for Optuna optimization.\n",
        "        metrics['eval_f1'] = metrics['macro_f1']\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def optimize_thresholds(self, y_true, y_pred_proba, n_trials=100):\n",
        "        \"\"\"\n",
        "        Optimizes classification thresholds for each label in a multi-label setting using Optuna.\n",
        "        The objective is to maximize the macro F1 score across all labels.\n",
        "        \"\"\"\n",
        "        num_labels = y_true.shape[1]\n",
        "        best_thresholds = []\n",
        "\n",
        "        def objective(trial):\n",
        "            thresholds = []\n",
        "            for i, label_name in enumerate(self.label_cols):\n",
        "                # Suggest a threshold for each label\n",
        "                threshold = trial.suggest_float(f'threshold_{label_name}', 0.1, 0.9)\n",
        "                thresholds.append(threshold)\n",
        "\n",
        "            # Binarize predictions using the suggested thresholds\n",
        "            binary_preds = (y_pred_proba > np.array(thresholds)).astype(int)\n",
        "\n",
        "            # Calculate macro F1 score across all labels (CHANGED TO MACRO F1)\n",
        "            macro_f1 = f1_score(y_true, binary_preds, average='macro', zero_division=0)\n",
        "\n",
        "            return macro_f1\n",
        "\n",
        "        # Create an Optuna study to maximize the macro F1 score\n",
        "        study = optuna.create_study(direction='maximize', study_name='multilabel_threshold_optimization')\n",
        "        study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "        # Extract the best thresholds found by Optuna\n",
        "        for i, label_name in enumerate(self.label_cols):\n",
        "            best_thresholds.append(study.best_params[f'threshold_{label_name}'])\n",
        "\n",
        "        return best_thresholds, study.best_value # Return as a list and the best score\n",
        "\n",
        "# ModelOptimizer Class\n",
        "class ModelOptimizer:\n",
        "    \"\"\"\n",
        "    Main class for orchestrating multi-label model training and hyperparameter optimization\n",
        "    using Optuna and cross-validation, incorporating imbalance handling.\n",
        "    \"\"\"\n",
        "    def __init__(self, train_df, val_df=None):\n",
        "        self.train_df = train_df\n",
        "        self.val_df = val_df\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "        self.metrics_calculator = MetricsCalculator(Config.LABEL_COLS)\n",
        "\n",
        "        # Calculate positive weights for all labels\n",
        "        self.pos_weights = self._calculate_pos_weights()\n",
        "\n",
        "    def _calculate_pos_weights(self):\n",
        "        \"\"\"\n",
        "        Calculates positive weights for each label to be used in BCEWithLogitsLoss.\n",
        "        Weight_i = Number of negative samples_i / Number of positive samples_i.\n",
        "        \"\"\"\n",
        "        pos_weights = []\n",
        "        for label_col in Config.LABEL_COLS:\n",
        "            pos_count = self.train_df[label_col].sum()\n",
        "            neg_count = len(self.train_df) - pos_count\n",
        "            # Avoid division by zero, set min pos_count to 1\n",
        "            pos_weight = neg_count / max(pos_count, 1)\n",
        "            pos_weights.append(pos_weight)\n",
        "            print(f\"Positive weight for '{label_col}': {pos_weight:.2f}\", flush=True)\n",
        "\n",
        "        return torch.FloatTensor(pos_weights)\n",
        "\n",
        "    def _create_model(self, trial=None):\n",
        "        \"\"\"\n",
        "        Creates an AutoModelForSequenceClassification model from the pre-trained name.\n",
        "        Applies trial-specific dropout hyperparameters if an Optuna trial is provided.\n",
        "        \"\"\"\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            Config.MODEL_NAME,\n",
        "            num_labels=len(Config.LABEL_COLS), # Now based on all labels\n",
        "            problem_type=\"multi_label_classification\", # Correct for multi-label BCEWithLogitsLoss\n",
        "            use_safetensors=True\n",
        "        )\n",
        "\n",
        "        # Apply dropout hyperparameters suggested by Optuna if in a trial\n",
        "        if trial is not None:\n",
        "            hidden_dropout = trial.suggest_float('hidden_dropout_prob', *Config.SEARCH_SPACE['hidden_dropout_prob'])\n",
        "            attention_dropout = trial.suggest_float('attention_probs_dropout_prob', *Config.SEARCH_SPACE['attention_probs_dropout_prob'])\n",
        "            model.config.hidden_dropout_prob = hidden_dropout\n",
        "            model.config.attention_probs_dropout_prob = attention_dropout\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _apply_sampling(self, X_train, y_train, oversampling_ratio, sampling_strategy='hybrid'):\n",
        "        \"\"\"\n",
        "        Applies synthetic oversampling (SMOTE) or hybrid sampling (SMOTETomek) to the training data.\n",
        "        Only applies to the training set.\n",
        "        For text data with imblearn, we oversample the *indices* based on a pseudo-label\n",
        "        (whether a comment has ANY toxic label).\n",
        "        \"\"\"\n",
        "        # Create a \"pseudo-label\" for sampling: 1 if any label is positive, 0 otherwise\n",
        "        y_pseudo = (y_train.sum(axis=1) > 0).astype(int)\n",
        "\n",
        "        if len(np.unique(y_pseudo)) < 2:\n",
        "            print(\"Warning: Only one class present in pseudo-labels for sampling. Skipping oversampling.\", flush=True)\n",
        "            return X_train, y_train\n",
        "\n",
        "        original_indices = np.arange(len(X_train))\n",
        "        y_pseudo_for_sampling = pd.Series(y_pseudo, index=original_indices) # Keep original indices\n",
        "\n",
        "        resampled_indices = original_indices\n",
        "        if sampling_strategy == 'smote':\n",
        "            # SMOTE works on features. Here we use indices as a proxy.\n",
        "            # k_neighbors must be less than the number of samples in the minority class.\n",
        "            # If your minority class is very small, k_neighbors might need adjustment.\n",
        "            smote_sampler = SMOTE(random_state=Config.RANDOM_SEED, sampling_strategy=oversampling_ratio, k_neighbors=min(3, y_pseudo_for_sampling.value_counts().min() - 1))\n",
        "            try:\n",
        "                resampled_indices, _ = smote_sampler.fit_resample(original_indices.reshape(-1, 1), y_pseudo_for_sampling)\n",
        "            except ValueError as e:\n",
        "                print(f\"SMOTE failed: {e}. Skipping oversampling.\", flush=True)\n",
        "                return X_train, y_train\n",
        "            resampled_indices = resampled_indices.flatten()\n",
        "\n",
        "        elif sampling_strategy == 'hybrid':\n",
        "            # SMOTETomek also works on features.\n",
        "            smotetomek_sampler = SMOTETomek(random_state=Config.RANDOM_SEED, sampling_strategy=oversampling_ratio, smote=SMOTE(k_neighbors=min(3, y_pseudo_for_sampling.value_counts().min() - 1)))\n",
        "            try:\n",
        "                resampled_indices, _ = smotetomek_sampler.fit_resample(original_indices.reshape(-1, 1), y_pseudo_for_sampling)\n",
        "            except ValueError as e:\n",
        "                print(f\"SMOTETomek failed: {e}. Skipping oversampling.\", flush=True)\n",
        "                return X_train, y_train\n",
        "            resampled_indices = resampled_indices.flatten()\n",
        "\n",
        "        # Reconstruct the resampled DataFrame using the resampled indices\n",
        "        resampled_X_train = X_train.iloc[resampled_indices].reset_index(drop=True)\n",
        "        resampled_y_train = y_train.iloc[resampled_indices].reset_index(drop=True)\n",
        "\n",
        "        return resampled_X_train, resampled_y_train\n",
        "\n",
        "    def _plot_training_history(self, history, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots training and evaluation metrics over epochs for multi-label.\n",
        "        Focuses on loss and the main 'eval_f1' (micro-f1).\n",
        "        \"\"\"\n",
        "        epochs = [entry['epoch'] for entry in history if 'loss' in entry]\n",
        "        train_losses = [entry['loss'] for entry in history if 'loss' in entry]\n",
        "\n",
        "        eval_epochs = [entry['epoch'] for entry in history if 'eval_loss' in entry]\n",
        "        val_losses = [entry['eval_loss'] for entry in history if 'eval_loss' in entry]\n",
        "        val_micro_f1s = [entry['eval_f1'] for entry in history if 'eval_f1' in entry] # eval_f1 is micro_f1\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, train_losses, label='Training Loss')\n",
        "        plt.plot(eval_epochs, val_losses, label='Validation Loss')\n",
        "        plt.title(f'Loss per Epoch {title_suffix}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(eval_epochs, val_micro_f1s, label='Validation Micro F1-Score', color='orange')\n",
        "        plt.title(f'Micro F1-Score per Epoch {title_suffix}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Micro F1-Score')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'training_metrics_plot_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved training history plot to {plot_filename}\", flush=True)\n",
        "\n",
        "    def _plot_multilabel_confusion_matrix(self, y_true, y_pred_binary, label_cols, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots confusion matrices for each label in a multi-label setting.\n",
        "        \"\"\"\n",
        "        num_labels = len(label_cols)\n",
        "        # Calculate number of rows needed for subplots\n",
        "        nrows = int(np.ceil(num_labels / 3))\n",
        "        fig, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(15, 5 * nrows))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            ax = axes[i]\n",
        "            cm = confusion_matrix(y_true[:, i], y_pred_binary[:, i])\n",
        "            tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "            ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "            ax.set_title(f'CM for {label_name} {title_suffix}')\n",
        "            tick_marks = np.arange(2)\n",
        "            ax.set_xticks(tick_marks, ['0', '1'])\n",
        "            ax.set_yticks(tick_marks, ['0', '1'])\n",
        "            ax.set_xlabel('Predicted')\n",
        "            ax.set_ylabel('True')\n",
        "\n",
        "            thresh = cm.max() / 2.\n",
        "            for x in range(cm.shape[0]):\n",
        "                for y in range(cm.shape[1]):\n",
        "                    ax.text(y, x, format(cm[x, y], 'd'),\n",
        "                            ha=\"center\", va=\"center\",\n",
        "                            color=\"white\" if cm[x, y] > thresh else \"black\")\n",
        "        # Hide unused subplots\n",
        "        for i in range(num_labels, len(axes)):\n",
        "            fig.delaxes(axes[i])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'multilabel_confusion_matrices_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved multilabel confusion matrix plots to {plot_filename}\", flush=True)\n",
        "\n",
        "    def _plot_precision_recall_curve_multilabel(self, y_true, y_pred_proba, label_cols, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots Precision-Recall Curves for each label.\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            precision, recall, _ = precision_recall_curve(y_true[:, i], y_pred_proba[:, i])\n",
        "            pr_auc = average_precision_score(y_true[:, i], y_pred_proba[:, i])\n",
        "            plt.plot(recall, precision, label=f'{label_name} (PR-AUC = {pr_auc:.2f})')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title(f'Precision-Recall Curves {title_suffix}')\n",
        "        plt.legend(loc='lower left')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'multilabel_precision_recall_curves_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved Multi-label Precision-Recall Curves to {plot_filename}\", flush=True)\n",
        "\n",
        "    def _plot_roc_curve_multilabel(self, y_true, y_pred_proba, label_cols, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots ROC Curves for each label.\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            fpr, tpr, _ = roc_curve(y_true[:, i], y_pred_proba[:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label=f'{label_name} (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'Receiver Operating Characteristic (ROC) Curves {title_suffix}')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'multilabel_roc_curves_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved Multi-label ROC Curves to {plot_filename}\", flush=True)\n",
        "\n",
        "    def _plot_probability_distribution_multilabel(self, y_true, y_pred_proba, label_cols, output_dir, title_suffix=\"\"):\n",
        "        \"\"\"\n",
        "        Plots the distribution of predicted probabilities for each class (true positive/negative split).\n",
        "        \"\"\"\n",
        "        num_labels = len(label_cols)\n",
        "        nrows = int(np.ceil(num_labels / 2))\n",
        "        fig, axes = plt.subplots(nrows=nrows, ncols=2, figsize=(12, 4 * nrows))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i, label_name in enumerate(label_cols):\n",
        "            ax = axes[i]\n",
        "            # Probabilities for true negatives for this label\n",
        "            ax.hist(y_pred_proba[y_true[:, i] == 0, i], bins=50, alpha=0.7, label=f'{label_name} (True Negative)', color='skyblue')\n",
        "            # Probabilities for true positives for this label\n",
        "            ax.hist(y_pred_proba[y_true[:, i] == 1, i], bins=50, alpha=0.7, label=f'{label_name} (True Positive)', color='lightcoral')\n",
        "\n",
        "            ax.set_xlabel('Predicted Probability')\n",
        "            ax.set_ylabel('Frequency')\n",
        "            ax.set_title(f'Prob. Dist. for {label_name} {title_suffix}')\n",
        "            ax.legend()\n",
        "            ax.grid(True)\n",
        "        # Hide unused subplots\n",
        "        for i in range(num_labels, len(axes)):\n",
        "            fig.delaxes(axes[i])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plot_filename = os.path.join(output_dir, f'multilabel_probability_distributions_{title_suffix.replace(\" \", \"_\")}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.close()\n",
        "        print(f\"    Saved Multi-label Probability Distributions to {plot_filename}\", flush=True)\n",
        "\n",
        "\n",
        "    def objective(self, trial):\n",
        "        \"\"\"\n",
        "        The main Optuna objective function for hyperparameter optimization for multi-label.\n",
        "        It performs cross-validation for each trial to get a robust evaluation score.\n",
        "        \"\"\"\n",
        "        # Suggest hyperparameters for the current trial based on the search space\n",
        "        params = {\n",
        "            'learning_rate': trial.suggest_loguniform('learning_rate', *Config.SEARCH_SPACE['learning_rate']),\n",
        "            'per_device_train_batch_size': trial.suggest_categorical('batch_size', Config.SEARCH_SPACE['batch_size']),\n",
        "            'num_train_epochs': trial.suggest_int('num_train_epochs', *Config.SEARCH_SPACE['num_train_epochs']),\n",
        "            'warmup_ratio': trial.suggest_float('warmup_ratio', *Config.SEARCH_SPACE['warmup_ratio']),\n",
        "            'weight_decay': trial.suggest_float('weight_decay', *Config.SEARCH_SPACE['weight_decay']),\n",
        "            'gradient_accumulation_steps': trial.suggest_categorical('gradient_accumulation_steps', Config.SEARCH_SPACE['gradient_accumulation_steps']),\n",
        "            'lr_scheduler_type': trial.suggest_categorical('lr_scheduler_type', Config.SEARCH_SPACE['lr_scheduler_type']),\n",
        "            'oversampling_ratio': trial.suggest_float('oversampling_ratio', *Config.SEARCH_SPACE['oversampling_ratio'])\n",
        "        }\n",
        "\n",
        "        # Extract oversampling_ratio as it's a custom parameter, not for TrainingArguments\n",
        "        oversampling_ratio = params.pop('oversampling_ratio') # Use .pop() to remove it from params\n",
        "\n",
        "        print(f\"\\nTrial {trial.number} parameters:\", flush=True)\n",
        "        for key, value in params.items():\n",
        "            print(f\"    {key}: {value}\", flush=True)\n",
        "        print(f\"    oversampling_ratio: {oversampling_ratio}\", flush=True)\n",
        "\n",
        "        cv_scores = [] # To store micro-F1 scores from each fold\n",
        "\n",
        "        # Use KFold for cross-validation on indices.\n",
        "        kf = KFold(n_splits=Config.CV_FOLDS, shuffle=True, random_state=Config.RANDOM_SEED)\n",
        "\n",
        "        # Split on the indices of the original dataframe\n",
        "        for fold, (train_idx, val_idx) in enumerate(kf.split(self.train_df)):\n",
        "            print(f\"\\n    Fold {fold + 1}/{Config.CV_FOLDS}\", flush=True)\n",
        "\n",
        "            fold_train_df_original = self.train_df.iloc[train_idx].reset_index(drop=True)\n",
        "            fold_val_df = self.train_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "            # --- Apply Hybrid Sampling only on the training set for this fold ---\n",
        "            resampled_texts, resampled_labels_df = self._apply_sampling(\n",
        "                X_train=fold_train_df_original['comment_text'],\n",
        "                y_train=fold_train_df_original[Config.LABEL_COLS],\n",
        "                oversampling_ratio=oversampling_ratio, # Use the extracted oversampling_ratio\n",
        "                sampling_strategy='hybrid' # Using hybrid sampling (SMOTETomek)\n",
        "            )\n",
        "            print(f\"    Training data after sampling: {len(resampled_texts)} samples\", flush=True)\n",
        "\n",
        "            train_dataset = ToxicDataset(\n",
        "                resampled_texts, # Use resampled texts\n",
        "                resampled_labels_df, # Use resampled labels\n",
        "                self.tokenizer,\n",
        "                Config.MAX_LENGTH,\n",
        "                augment=True\n",
        "            )\n",
        "\n",
        "            val_dataset = ToxicDataset(\n",
        "                fold_val_df['comment_text'],\n",
        "                fold_val_df[Config.LABEL_COLS],\n",
        "                self.tokenizer,\n",
        "                Config.MAX_LENGTH\n",
        "            )\n",
        "\n",
        "            safety_model = self._create_model(trial)\n",
        "\n",
        "            output_dir_fold = os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, f'results_trial_{trial.number}_fold_{fold}')\n",
        "            os.makedirs(output_dir_fold, exist_ok=True)\n",
        "\n",
        "            training_args = TrainingArguments(\n",
        "                output_dir=output_dir_fold,\n",
        "                eval_strategy=\"epoch\",\n",
        "                save_strategy=\"epoch\",\n",
        "                logging_strategy=\"epoch\",\n",
        "                per_device_eval_batch_size=params['per_device_train_batch_size'],\n",
        "                save_total_limit=2,\n",
        "                load_best_model_at_end=True,\n",
        "                metric_for_best_model=\"eval_f1\",\n",
        "                greater_is_better=True,\n",
        "                report_to=\"none\",\n",
        "                seed=Config.RANDOM_SEED,\n",
        "                fp16=torch.cuda.is_available(),\n",
        "                dataloader_pin_memory=False,\n",
        "                learning_rate=params['learning_rate'],\n",
        "                per_device_train_batch_size=params['per_device_train_batch_size'],\n",
        "                num_train_epochs=params['num_train_epochs'],\n",
        "                warmup_ratio=params['warmup_ratio'],\n",
        "                weight_decay=params['weight_decay'],\n",
        "                gradient_accumulation_steps=params['gradient_accumulation_steps'],\n",
        "                lr_scheduler_type=params['lr_scheduler_type']\n",
        "            )\n",
        "\n",
        "            trainer = AdvancedTrainer(\n",
        "                model=safety_model,\n",
        "                args=training_args,\n",
        "                train_dataset=train_dataset,\n",
        "                eval_dataset=val_dataset,\n",
        "                compute_metrics=self.metrics_calculator.compute_metrics,\n",
        "                pos_weights=self.pos_weights,\n",
        "                callbacks=[EarlyStoppingCallback(early_stopping_patience=Config.PATIENCE)],\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                trainer.train()\n",
        "                eval_results = trainer.evaluate()\n",
        "                # 'eval_f1' is correctly used as the primary metric, which your\n",
        "                # compute_metrics function should set to be the macro F1 for optimization.\n",
        "                fold_score = eval_results['eval_f1']\n",
        "\n",
        "                print(f\"    Fold {fold + 1} Results (Optimized Metric: Macro F1): {fold_score:.4f}\", flush=True)\n",
        "                print(f\"      Macro F1 (from eval_results): {eval_results.get('eval_macro_f1', fold_score):.4f}\", flush=True)\n",
        "                print(f\"      Micro F1: {eval_results.get('eval_micro_f1', 'N/A'):.4f}\", flush=True)\n",
        "                print(f\"      Micro Precision: {eval_results.get('eval_micro_precision', 'N/A'):.4f}\", flush=True)\n",
        "                print(f\"      Micro Recall: {eval_results.get('eval_micro_recall', 'N/A'):.4f}\", flush=True)\n",
        "                print(f\"      Micro ROC-AUC: {eval_results.get('eval_micro_roc_auc', 'N/A'):.4f}\", flush=True)\n",
        "\n",
        "                self._plot_training_history(trainer.state.log_history, output_dir_fold, f\"Fold {fold + 1}\")\n",
        "\n",
        "                cv_scores.append(fold_score)\n",
        "            except Exception as e:\n",
        "                # Improved error reporting for easier debugging\n",
        "                print(f\"    Fold {fold + 1} failed: {type(e).__name__}: {str(e)}\", flush=True)\n",
        "                cv_scores.append(0.0) # Append 0.0 or handle as per your Optuna study design\n",
        "\n",
        "        mean_cv_score = np.mean(cv_scores)\n",
        "        std_cv_score = np.std(cv_scores)\n",
        "\n",
        "        print(f\"\\nTrial {trial.number} Results:\", flush=True)\n",
        "        print(f\"    Mean CV Micro F1: {mean_cv_score:.4f} ± {std_cv_score:.4f}\", flush=True)\n",
        "\n",
        "        return mean_cv_score\n",
        "\n",
        "    def run_optimization(self): # Renamed from optimize to run_optimization for clarity\n",
        "        \"\"\"\n",
        "        Runs the Optuna hyperparameter optimization study for multi-label classification.\n",
        "        Incorporates Hyperband pruning for efficient search.\n",
        "        \"\"\"\n",
        "        print(\"Starting hyperparameter optimization...\", flush=True)\n",
        "        print(f\"Search space: {Config.SEARCH_SPACE}\", flush=True)\n",
        "\n",
        "        # Determine max_resource for Hyperband Pruner based on your Config.N_TRAIN_EPOCHS range\n",
        "        # Assuming Config.SEARCH_SPACE['num_train_epochs'] is the upper bound of your epochs search space\n",
        "        max_epochs_for_pruner = Config.SEARCH_SPACE['num_train_epochs'][1]\n",
        "\n",
        "        # Initialize Hyperband Pruner\n",
        "        pruner = HyperbandPruner(\n",
        "            min_resource=1,         # Pruning can start after the first epoch/step\n",
        "            max_resource=max_epochs_for_pruner, # Max epochs a trial can run, matching your search space\n",
        "            reduction_factor=3      # Common reduction factor for Hyperband\n",
        "        )\n",
        "\n",
        "        # Ensure the directory for the Optuna DB exists\n",
        "        db_dir = os.path.dirname(Config.OPTUNA_DB_PATH.replace(\"sqlite:///\", \"\"))\n",
        "        os.makedirs(db_dir, exist_ok=True)\n",
        "        print(f\"Optuna DB directory ensured: {db_dir}\", flush=True)\n",
        "\n",
        "        study = optuna.create_study(\n",
        "            direction='maximize',\n",
        "            study_name='electra_toxic_multilabel_classification',\n",
        "            storage=f'sqlite:///{Config.OPTUNA_DB_PATH}',\n",
        "            load_if_exists=True,\n",
        "            sampler=TPESampler(seed=Config.RANDOM_SEED), # Use TPESampler for efficient search\n",
        "            pruner=pruner # Use the Hyperband Pruner\n",
        "        )\n",
        "\n",
        "        print(f\"Running {Config.N_TRIALS} trials with Hyperband Pruner...\", flush=True)\n",
        "        study.optimize(self.objective, n_trials=Config.N_TRIALS, show_progress_bar=True)\n",
        "\n",
        "        print(\"\\nOptimization completed! ✨\", flush=True)\n",
        "        print(f\"Best trial number: {study.best_trial.number}\", flush=True)\n",
        "\n",
        "        # Ensure this matches your metric_for_best_model, which should be 'macro_f1'\n",
        "        print(f\"Best Macro F1: {study.best_value:.4f}\", flush=True)\n",
        "\n",
        "        print(\"Best parameters found: 🚀\", flush=True)\n",
        "        for key, value in study.best_params.items():\n",
        "            print(f\"   {key}: {value}\", flush=True)\n",
        "\n",
        "        return study\n",
        "\n",
        "    def get_optuna_summary_data(self, study):\n",
        "        \"\"\"\n",
        "        Collects summary data for all Optuna trials.\n",
        "        \"\"\"\n",
        "        summary_data = {\n",
        "            \"total_trials_completed\": len(study.trials),\n",
        "            \"best_trial_number\": study.best_trial.number,\n",
        "            \"best_objective_value\": study.best_value,\n",
        "            \"best_hyperparameters\": study.best_trial.params,\n",
        "            \"trial_history\": []\n",
        "        }\n",
        "\n",
        "        # Collect summary for each trial\n",
        "        for trial in study.trials:\n",
        "            trial_info = {\n",
        "                \"trial_number\": trial.number,\n",
        "                \"state\": str(trial.state),\n",
        "                \"value\": trial.value,\n",
        "                \"params\": trial.params,\n",
        "                \"duration_seconds\": trial.duration.total_seconds() if trial.duration else None\n",
        "            }\n",
        "            summary_data[\"trial_history\"].append(trial_info)\n",
        "\n",
        "        return summary_data\n",
        "\n",
        "    def train_final_model(self, best_params, save_path=None):\n",
        "        \"\"\"\n",
        "        Trains the final model using the best hyperparameters found during optimization.\n",
        "        \"\"\"\n",
        "        if save_path is None:\n",
        "            save_path = os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, \"best_electra_multilabel_model\")\n",
        "\n",
        "        print(\"\\nTraining final model with best parameters...\", flush=True)\n",
        "\n",
        "        # Apply sampling to the entire training set for the final model\n",
        "        resampled_texts, resampled_labels_df = self._apply_sampling(\n",
        "            X_train=self.train_df['comment_text'],\n",
        "            y_train=self.train_df[Config.LABEL_COLS],\n",
        "            oversampling_ratio=best_params.get('oversampling_ratio', 0.5), # Use optimized ratio or default\n",
        "            sampling_strategy='hybrid'\n",
        "        )\n",
        "        print(f\"Final training data after sampling: {len(resampled_texts)} samples\", flush=True)\n",
        "\n",
        "\n",
        "        train_dataset = ToxicDataset(\n",
        "            resampled_texts,\n",
        "            resampled_labels_df,\n",
        "            self.tokenizer,\n",
        "            Config.MAX_LENGTH,\n",
        "            augment=True\n",
        "        )\n",
        "\n",
        "        val_dataset = None\n",
        "        if self.val_df is not None:\n",
        "            val_dataset = ToxicDataset(\n",
        "                self.val_df['comment_text'],\n",
        "                self.val_df[Config.LABEL_COLS], # Pass all labels for validation\n",
        "                self.tokenizer,\n",
        "                Config.MAX_LENGTH\n",
        "            )\n",
        "\n",
        "        safety_model = self._create_model()\n",
        "        # Apply dropout parameters from best_params if they exist\n",
        "        if 'hidden_dropout_prob' in best_params:\n",
        "            safety_model.config.hidden_dropout_prob = best_params['hidden_dropout_prob']\n",
        "        if 'attention_probs_dropout_prob' in best_params:\n",
        "            safety_model.config.attention_probs_dropout_prob = best_params['attention_probs_dropout_prob']\n",
        "\n",
        "        output_dir_final = os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, 'final_electra_multilabel_model_results')\n",
        "        os.makedirs(output_dir_final, exist_ok=True)\n",
        "\n",
        "        # Prepare TrainingArguments for the final training run\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir_final,\n",
        "            eval_strategy=\"epoch\" if val_dataset else \"no\",\n",
        "            save_strategy=\"epoch\",\n",
        "            logging_strategy=\"epoch\",\n",
        "            per_device_train_batch_size=best_params.get('batch_size', 16),\n",
        "            per_device_eval_batch_size=best_params.get('batch_size', 16),\n",
        "            num_train_epochs=best_params.get('num_train_epochs', 3),\n",
        "            learning_rate=best_params.get('learning_rate', 2e-5),\n",
        "            warmup_ratio=best_params.get('warmup_ratio', 0.1),\n",
        "            weight_decay=best_params.get('weight_decay', 0.01),\n",
        "            gradient_accumulation_steps=best_params.get('gradient_accumulation_steps', 1),\n",
        "            lr_scheduler_type=best_params.get('lr_scheduler_type', 'linear'),\n",
        "            save_total_limit=3, # Keep up to 3 best checkpoints\n",
        "            load_best_model_at_end=True if val_dataset else False,\n",
        "            metric_for_best_model=\"eval_f1\" if val_dataset else None, # Micro F1 for multilabel\n",
        "            greater_is_better=True,\n",
        "            report_to=\"none\",\n",
        "            seed=Config.RANDOM_SEED,\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            dataloader_pin_memory=False,\n",
        "        )\n",
        "\n",
        "        trainer = AdvancedTrainer(\n",
        "            model=safety_model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            compute_metrics=self.metrics_calculator.compute_metrics,\n",
        "            pos_weights=self.pos_weights, # Pass tensor of pos_weights\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=Config.PATIENCE)] if val_dataset else [],\n",
        "        )\n",
        "\n",
        "        trainer.train()\n",
        "\n",
        "        if val_dataset:\n",
        "            final_eval_results = trainer.evaluate()\n",
        "            print(\"\\nFinal Model Evaluation Results:\", flush=True)\n",
        "            for k, v in final_eval_results.items():\n",
        "                if k.startswith('eval_'): # Print metrics that were evaluated\n",
        "                    print(f\"    {k.replace('eval_', '')}: {v:.4f}\", flush=True)\n",
        "                elif k.endswith('_f1') or k.endswith('_precision') or k.endswith('_recall') or k.endswith('_roc_auc') or k.endswith('_pr_auc'):\n",
        "                    print(f\"    {k}: {v:.4f}\", flush=True)\n",
        "\n",
        "\n",
        "            # Get true labels and predicted probabilities from the final evaluation\n",
        "            predictions = trainer.predict(val_dataset)\n",
        "            y_true_final = predictions.label_ids\n",
        "            y_pred_proba_final = torch.sigmoid(torch.tensor(predictions.predictions)).numpy()\n",
        "\n",
        "            # Optimize thresholds on the final validation set for comprehensive evaluation\n",
        "            print(\"\\nOptimizing classification thresholds for final model evaluation...\", flush=True)\n",
        "            best_thresholds_final, best_threshold_score_final = self.metrics_calculator.optimize_thresholds(\n",
        "                y_true_final, y_pred_proba_final, n_trials=100\n",
        "            )\n",
        "            print(f\"Optimized macro F1 (threshold tuning): {best_threshold_score_final:.4f}\", flush=True)\n",
        "            print(\"Optimized thresholds:\", flush=True)\n",
        "            for i, label_name in enumerate(Config.LABEL_COLS):\n",
        "                print(f\"    {best_thresholds_final[i]:.3f}\", flush=True) # Corrected variable name\n",
        "\n",
        "            # Re-evaluate with optimized thresholds to get final confusion matrices and plots\n",
        "            final_binary_preds = (y_pred_proba_final > np.array(best_thresholds_final)).astype(int)\n",
        "\n",
        "            self._plot_training_history(trainer.state.log_history, output_dir_final, \"Final Model\")\n",
        "            self._plot_multilabel_confusion_matrix(y_true_final, final_binary_preds, Config.LABEL_COLS, output_dir_final, \"Final Model\")\n",
        "            self._plot_precision_recall_curve_multilabel(y_true_final, y_pred_proba_final, Config.LABEL_COLS, output_dir_final, \"Final Model\")\n",
        "            self._plot_roc_curve_multilabel(y_true_final, y_pred_proba_final, Config.LABEL_COLS, output_dir_final, \"Final Model\")\n",
        "            self._plot_probability_distribution_multilabel(y_true_final, y_pred_proba_final, Config.LABEL_COLS, output_dir_final, \"Final Model\")\n",
        "\n",
        "            # Save the optimized thresholds to a CSV file\n",
        "            threshold_df = pd.DataFrame({\n",
        "                'label': Config.LABEL_COLS,\n",
        "                'threshold': best_thresholds_final\n",
        "            })\n",
        "            threshold_df.to_csv(os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, 'optimized_thresholds_multilabel.csv'), index=False)\n",
        "            print(f\"Final optimized thresholds saved to {os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, 'optimized_thresholds_multilabel.csv')}\", flush=True)\n",
        "\n",
        "\n",
        "        trainer.save_model(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "\n",
        "        print(f\"Final model saved to {save_path}\", flush=True)\n",
        "\n",
        "        # Save the training log history for the final model\n",
        "        log_history_path = os.path.join(output_dir_final, 'final_model_training_log_history.json')\n",
        "        with open(log_history_path, 'w') as f:\n",
        "            json.dump(trainer.state.log_history, f, indent=4)\n",
        "        print(f\"Final model training log history saved to {log_history_path}\", flush=True)\n",
        "\n",
        "\n",
        "        return trainer\n",
        "\n",
        "\n",
        "# Helper function for LIME predictions (needs to be outside classes to be easily callable by LIME)\n",
        "def predict_proba_for_lime(texts, model, tokenizer, max_length, device):\n",
        "    \"\"\"\n",
        "    Predictor function required by LIME. Takes a list of raw texts and returns\n",
        "    prediction probabilities for each class.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        return_tensors='pt'\n",
        "    ).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probabilities = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "    return probabilities\n",
        "\n",
        "def main():\n",
        "    set_seed(Config.RANDOM_SEED) # Ensure reproducibility\n",
        "\n",
        "    # Create the base directory for saving results\n",
        "    os.makedirs(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, exist_ok=True)\n",
        "    print(f\"Google Drive base save path ensured: {Config.GOOGLE_DRIVE_SAVE_BASE_PATH}\", flush=True)\n",
        "\n",
        "    print(\"Loading data...\", flush=True)\n",
        "    try:\n",
        "        # Load your datasets as specified\n",
        "        train_df = pd.read_csv(\"train.csv\")\n",
        "        test_df = pd.read_csv(\"test.csv\")\n",
        "        test_labels = pd.read_csv(\"test_labels.csv\")\n",
        "        sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "        print(\"Data loaded successfully.\", flush=True)\n",
        "        print(f\"Train DataFrame shape: {train_df.shape}\", flush=True)\n",
        "        print(f\"Test DataFrame shape: {test_df.shape}\", flush=True)\n",
        "        print(f\"Test Labels DataFrame shape: {test_labels.shape}\", flush=True)\n",
        "        print(f\"Sample Submission DataFrame shape: {sample_submission.shape}\", flush=True)\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: One or more dataset files (train.csv, test.csv, test.csv, sample_submission.csv) not found.\", flush=True)\n",
        "        print(\"Please ensure all required CSV files are in the same directory as the script.\", flush=True)\n",
        "        return\n",
        "\n",
        "    # Fill NaN values in 'comment_text'\n",
        "    train_df['comment_text'] = train_df['comment_text'].fillna('')\n",
        "    test_df['comment_text'] = test_df['comment_text'].fillna('') # Also fill for test_df if needed\n",
        "\n",
        "    # --- Use all original labels directly for multilabel classification ---\n",
        "    # Ensure all label columns are present\n",
        "    if not all(col in train_df.columns for col in Config.LABEL_COLS):\n",
        "        print(f\"Error: One or more label columns {Config.LABEL_COLS} not found in the training dataset. Exiting.\", flush=True)\n",
        "        return\n",
        "\n",
        "    print(f\"\\nLabel columns being used for training: {Config.LABEL_COLS}\", flush=True)\n",
        "\n",
        "    # Display class distribution for each label (important for multilabel)\n",
        "    print(\"\\nMultilabel Class distribution (Positive count and percentage in training data):\", flush=True)\n",
        "    for col in Config.LABEL_COLS:\n",
        "        pos_count = train_df[col].sum()\n",
        "        total_count = len(train_df)\n",
        "        pos_pct = (pos_count / total_count) * 100\n",
        "        print(f\"  '{col}': {pos_count:,} positive samples ({pos_pct:.2f}%)\", flush=True)\n",
        "\n",
        "    # Splitting the main training data into a training and validation set\n",
        "    # This validation set is used for the *final model training* and evaluation,\n",
        "    # distinct from the CV folds within Optuna.\n",
        "    print(\"\\nSplitting training data into train and validation sets (80/20 split)...\", flush=True)\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        train_df['comment_text'],\n",
        "        train_df[Config.LABEL_COLS],\n",
        "        test_size=0.2,\n",
        "        random_state=Config.RANDOM_SEED,\n",
        "        stratify=train_df['toxic'] # Stratify by 'toxic' label for a more balanced split\n",
        "    )\n",
        "\n",
        "    # Reconstruct dataframes for ModelOptimizer\n",
        "    train_df_for_optimizer = pd.DataFrame({'comment_text': train_texts}).reset_index(drop=True)\n",
        "    train_labels_for_optimizer = train_labels.reset_index(drop=True)\n",
        "    val_df_for_optimizer = pd.DataFrame({'comment_text': val_texts}).reset_index(drop=True)\n",
        "    val_labels_for_optimizer = val_labels.reset_index(drop=True)\n",
        "\n",
        "    # Merge texts and labels back for convenience in ModelOptimizer initialization\n",
        "    # (ModelOptimizer expects the full train_df with 'comment_text' and all label columns)\n",
        "    train_combined_df = pd.concat([train_df_for_optimizer, train_labels_for_optimizer], axis=1)\n",
        "    val_combined_df = pd.concat([val_df_for_optimizer, val_labels_for_optimizer], axis=1) # Pass this to ModelOptimizer\n",
        "\n",
        "    print(f\"Training set size for final model: {len(train_combined_df)}\", flush=True)\n",
        "    print(f\"Validation set size for final model: {len(val_combined_df)}\", flush=True)\n",
        "\n",
        "    optimizer = ModelOptimizer(train_combined_df, val_combined_df) # Pass val_combined_df here\n",
        "\n",
        "    best_params = {}\n",
        "    study = None # Initialize study to None\n",
        "    if Config.LOAD_EXISTING_STUDY_RESULTS:\n",
        "        print(f\"\\nAttempting to load existing Optuna study from {Config.OPTUNA_DB_PATH}...\", flush=True)\n",
        "        try:\n",
        "            study = optuna.load_study(\n",
        "                study_name='electra_toxic_multilabel_classification',\n",
        "                storage=f'sqlite:///{Config.OPTUNA_DB_PATH}'\n",
        "            )\n",
        "            best_params = study.best_trial.params\n",
        "            print(\"Successfully loaded best parameters from existing study:\", flush=True)\n",
        "            for k, v in best_params.items():\n",
        "                print(f\"    {k}: {v}\", flush=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load existing study: {e}. Starting new optimization.\", flush=True)\n",
        "            Config.LOAD_EXISTING_STUDY_RESULTS = False # Fallback to running optimization\n",
        "\n",
        "    if not Config.LOAD_EXISTING_STUDY_RESULTS:\n",
        "        study = optimizer.run_optimization() # Changed from .optimize() to .run_optimization()\n",
        "        best_params = study.best_trial.params\n",
        "\n",
        "    # Train the final model with the best parameters\n",
        "    final_trainer = optimizer.train_final_model(best_params)\n",
        "\n",
        "    print(\"\\nTraining and optimization complete! \", flush=True)\n",
        "    print(f\"Results, model checkpoints, and plots are saved in: {Config.GOOGLE_DRIVE_SAVE_BASE_PATH}\", flush=True)\n",
        "\n",
        "    # --- Generate Optuna Summary Data ---\n",
        "    if study: # Only generate summary if a study object is available\n",
        "        optuna_summary = optimizer.get_optuna_summary_data(study)\n",
        "        print(\"\\n--- Optuna Optimization Summary Data ---\", flush=True)\n",
        "        print(json.dumps(optuna_summary, indent=2), flush=True)\n",
        "        print(\"\\n--- End of Optuna Optimization Summary Data ---\", flush=True)\n",
        "    else:\n",
        "        print(\"\\nSkipping Optuna summary data generation as no study object was available.\", flush=True)\n",
        "\n",
        "\n",
        "    # --- Explainability (XAI) Section using LIME ---\n",
        "    print(\"\\n--- Starting Explainable AI (XAI) Analysis with LIME ---\", flush=True)\n",
        "\n",
        "    # Load the best trained model and tokenizer for XAI\n",
        "    final_model_path = os.path.join(Config.GOOGLE_DRIVE_SAVE_BASE_PATH, \"best_electra_multilabel_model\")\n",
        "    try:\n",
        "        final_model = AutoModelForSequenceClassification.from_pretrained(final_model_path).to(Config.DEVICE)\n",
        "        final_tokenizer = AutoTokenizer.from_pretrained(final_model_path)\n",
        "        print(f\"Loaded final model and tokenizer from {final_model_path}\", flush=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading final model for XAI: {e}. Skipping XAI analysis.\", flush=True)\n",
        "        final_model = None # Set to None to prevent further errors if loading failed\n",
        "\n",
        "    if final_model:\n",
        "        # Prepare the predictor function for LIME\n",
        "        lime_predictor = lambda texts: predict_proba_for_lime(\n",
        "            texts, final_model, final_tokenizer, Config.MAX_LENGTH, Config.DEVICE\n",
        "        )\n",
        "\n",
        "        # Initialize LIME Explainer\n",
        "        explainer = LimeTextExplainer(class_names=Config.LABEL_COLS)\n",
        "\n",
        "        # Select a few examples for explanation from the validation set\n",
        "        # You can adjust the number of examples or criteria for selection\n",
        "        num_xai_examples = min(5, len(val_combined_df)) # Explain up to 5 examples from validation set\n",
        "        xai_examples_df = val_combined_df.sample(n=num_xai_examples, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "        for idx in range(num_xai_examples):\n",
        "            example_comment_text = xai_examples_df['comment_text'].iloc[idx]\n",
        "            true_labels = xai_examples_df[Config.LABEL_COLS].iloc[idx].values\n",
        "\n",
        "            # Get model's raw probabilities for this example\n",
        "            model_probabilities = lime_predictor([example_comment_text])[0]\n",
        "\n",
        "            print(f\"\\n--- XAI Example {idx + 1} ---\", flush=True)\n",
        "            print(f\"Comment: '{example_comment_text}'\", flush=True)\n",
        "            print(f\"True Labels: {true_labels}\", flush=True)\n",
        "            print(f\"Model Probabilities: {model_probabilities.round(3)}\", flush=True)\n",
        "\n",
        "            # Generate explanation for each relevant label\n",
        "            for i, label_name in enumerate(Config.LABEL_COLS):\n",
        "                # Decide which labels to explain: e.g., true positive, or high predicted probability\n",
        "                if true_labels[i] == 1 or model_probabilities[i] > 0.5:\n",
        "                    print(f\"\\n  Explanation for label: '{label_name}' (True: {true_labels[i]}, Predicted Prob: {model_probabilities[i]:.3f})\", flush=True)\n",
        "                    try:\n",
        "                        # Attempt to generate explanation\n",
        "                        exp = explainer.explain_instance(\n",
        "                            example_comment_text,\n",
        "                            lime_predictor,\n",
        "                            labels=[i],  # Request explanation specifically for this label's index\n",
        "                            num_features=10,\n",
        "                            num_samples=1000\n",
        "                        )\n",
        "\n",
        "                        # Check if the explanation object is valid and has content for the label\n",
        "                        if exp and hasattr(exp, 'as_list'):\n",
        "                            explanation_list = exp.as_list(label=i)\n",
        "                            if explanation_list:\n",
        "                                print(explanation_list, flush=True)\n",
        "                            else:\n",
        "                                print(f\"  No LIME explanation features found for label '{label_name}' (label index {i}). This can happen if the model's prediction for this label is very stable across perturbed samples.\", flush=True)\n",
        "                        else:\n",
        "                            print(f\"  LIME explainer returned an invalid explanation object for label '{label_name}' (label index {i}).\", flush=True)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        # Catch any other unexpected errors during LIME explanation\n",
        "                        print(f\"  An unexpected error occurred during LIME explanation for label '{label_name}' (label index {i}): {type(e).__name__}: {str(e)}\", flush=True)\n",
        "                else:\n",
        "                    print(f\"  Skipping explanation for label '{label_name}' (True: {true_labels[i]}, Predicted Prob: {model_probabilities[i]:.3f} - not a strong prediction or true positive)\", flush=True)\n",
        "\n",
        "    print(\"\\n--- XAI Analysis Complete ---\", flush=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Mount Google Drive if running in Colab\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    # print(\"\\nGoogle Drive mounted!\", flush=True)\n",
        "\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "56a40d30e6f34661bd343371dc74d8c8",
            "d27f60ff84a04a23a3eb3d61b83c7736",
            "57264bae39534fed9f8d11a79aac79e3",
            "307d262e2efc4953b1bfee9f841dc67c",
            "2fe412da15074077ba68061bf702e675",
            "116e1381196243898a8df4bc1dcab8f7",
            "4e99001ba5094803b54d7db46c0de9b1",
            "acbebf5fc9e341c79481c3478f9b3af4",
            "042567ac1de14eafb17bb6c3783cb0fe",
            "c2869a28d6764839b6b2d59f8c83effb",
            "83b3ca11309944a38021ef3221fc1634"
          ]
        },
        "id": "g6Wn7YSIGSAV",
        "outputId": "c662f944-c2c5-4f3b-8aaf-1f1f45b69ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive base save path ensured: /content/drive/MyDrive/my_electra_multilabel_classifier_results\n",
            "Loading data...\n",
            "Data loaded successfully.\n",
            "Train DataFrame shape: (159571, 8)\n",
            "Test DataFrame shape: (153164, 2)\n",
            "Test Labels DataFrame shape: (153164, 7)\n",
            "Sample Submission DataFrame shape: (153164, 7)\n",
            "\n",
            "Label columns being used for training: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "\n",
            "Multilabel Class distribution (Positive count and percentage in training data):\n",
            "  'toxic': 15,294 positive samples (9.58%)\n",
            "  'severe_toxic': 1,595 positive samples (1.00%)\n",
            "  'obscene': 8,449 positive samples (5.29%)\n",
            "  'threat': 478 positive samples (0.30%)\n",
            "  'insult': 7,877 positive samples (4.94%)\n",
            "  'identity_hate': 1,405 positive samples (0.88%)\n",
            "\n",
            "Splitting training data into train and validation sets (80/20 split)...\n",
            "Training set size for final model: 127656\n",
            "Validation set size for final model: 31915\n",
            "Positive weight for 'toxic': 9.43\n",
            "Positive weight for 'severe_toxic': 98.42\n",
            "Positive weight for 'obscene': 17.94\n",
            "Positive weight for 'threat': 334.06\n",
            "Positive weight for 'insult': 19.30\n",
            "Positive weight for 'identity_hate': 113.39\n",
            "\n",
            "Attempting to load existing Optuna study from /content/drive/MyDrive/my_electra_multilabel_classifier_results/optuna_electra_multilabel_study.db...\n",
            "Successfully loaded best parameters from existing study:\n",
            "    learning_rate: 1.1844319751820392e-05\n",
            "    batch_size: 16\n",
            "    num_train_epochs: 4\n",
            "    warmup_ratio: 0.07340279606636549\n",
            "    weight_decay: 0.015599452033620266\n",
            "    gradient_accumulation_steps: 2\n",
            "    lr_scheduler_type: linear\n",
            "    oversampling_ratio: 0.9729188669457949\n",
            "    hidden_dropout_prob: 0.26648852816008434\n",
            "    attention_probs_dropout_prob: 0.12123391106782762\n",
            "\n",
            "Training final model with best parameters...\n",
            "Final training data after sampling: 228262 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='28536' max='28536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [28536/28536 1:07:53, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Toxic F1</th>\n",
              "      <th>Toxic Precision</th>\n",
              "      <th>Toxic Recall</th>\n",
              "      <th>Toxic Roc Auc</th>\n",
              "      <th>Toxic Pr Auc</th>\n",
              "      <th>Toxic Tn</th>\n",
              "      <th>Toxic Fp</th>\n",
              "      <th>Toxic Fn</th>\n",
              "      <th>Toxic Tp</th>\n",
              "      <th>Severe Toxic F1</th>\n",
              "      <th>Severe Toxic Precision</th>\n",
              "      <th>Severe Toxic Recall</th>\n",
              "      <th>Severe Toxic Roc Auc</th>\n",
              "      <th>Severe Toxic Pr Auc</th>\n",
              "      <th>Severe Toxic Tn</th>\n",
              "      <th>Severe Toxic Fp</th>\n",
              "      <th>Severe Toxic Fn</th>\n",
              "      <th>Severe Toxic Tp</th>\n",
              "      <th>Obscene F1</th>\n",
              "      <th>Obscene Precision</th>\n",
              "      <th>Obscene Recall</th>\n",
              "      <th>Obscene Roc Auc</th>\n",
              "      <th>Obscene Pr Auc</th>\n",
              "      <th>Obscene Tn</th>\n",
              "      <th>Obscene Fp</th>\n",
              "      <th>Obscene Fn</th>\n",
              "      <th>Obscene Tp</th>\n",
              "      <th>Threat F1</th>\n",
              "      <th>Threat Precision</th>\n",
              "      <th>Threat Recall</th>\n",
              "      <th>Threat Roc Auc</th>\n",
              "      <th>Threat Pr Auc</th>\n",
              "      <th>Threat Tn</th>\n",
              "      <th>Threat Fp</th>\n",
              "      <th>Threat Fn</th>\n",
              "      <th>Threat Tp</th>\n",
              "      <th>Insult F1</th>\n",
              "      <th>Insult Precision</th>\n",
              "      <th>Insult Recall</th>\n",
              "      <th>Insult Roc Auc</th>\n",
              "      <th>Insult Pr Auc</th>\n",
              "      <th>Insult Tn</th>\n",
              "      <th>Insult Fp</th>\n",
              "      <th>Insult Fn</th>\n",
              "      <th>Insult Tp</th>\n",
              "      <th>Identity Hate F1</th>\n",
              "      <th>Identity Hate Precision</th>\n",
              "      <th>Identity Hate Recall</th>\n",
              "      <th>Identity Hate Roc Auc</th>\n",
              "      <th>Identity Hate Pr Auc</th>\n",
              "      <th>Identity Hate Tn</th>\n",
              "      <th>Identity Hate Fp</th>\n",
              "      <th>Identity Hate Fn</th>\n",
              "      <th>Identity Hate Tp</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Micro Roc Auc</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Macro Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.608100</td>\n",
              "      <td>0.590379</td>\n",
              "      <td>0.645714</td>\n",
              "      <td>0.808664</td>\n",
              "      <td>0.724263</td>\n",
              "      <td>0.915332</td>\n",
              "      <td>0.987858</td>\n",
              "      <td>0.914454</td>\n",
              "      <td>27790</td>\n",
              "      <td>1066</td>\n",
              "      <td>259</td>\n",
              "      <td>2800</td>\n",
              "      <td>0.452830</td>\n",
              "      <td>0.320427</td>\n",
              "      <td>0.771704</td>\n",
              "      <td>0.988627</td>\n",
              "      <td>0.422795</td>\n",
              "      <td>31095</td>\n",
              "      <td>509</td>\n",
              "      <td>71</td>\n",
              "      <td>240</td>\n",
              "      <td>0.773661</td>\n",
              "      <td>0.648595</td>\n",
              "      <td>0.958480</td>\n",
              "      <td>0.993527</td>\n",
              "      <td>0.900544</td>\n",
              "      <td>29317</td>\n",
              "      <td>888</td>\n",
              "      <td>71</td>\n",
              "      <td>1639</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.503817</td>\n",
              "      <td>0.680412</td>\n",
              "      <td>0.977405</td>\n",
              "      <td>0.464883</td>\n",
              "      <td>31753</td>\n",
              "      <td>65</td>\n",
              "      <td>31</td>\n",
              "      <td>66</td>\n",
              "      <td>0.731134</td>\n",
              "      <td>0.606551</td>\n",
              "      <td>0.920126</td>\n",
              "      <td>0.988642</td>\n",
              "      <td>0.811740</td>\n",
              "      <td>29376</td>\n",
              "      <td>949</td>\n",
              "      <td>127</td>\n",
              "      <td>1463</td>\n",
              "      <td>0.529048</td>\n",
              "      <td>0.411538</td>\n",
              "      <td>0.740484</td>\n",
              "      <td>0.987191</td>\n",
              "      <td>0.574177</td>\n",
              "      <td>31320</td>\n",
              "      <td>306</td>\n",
              "      <td>75</td>\n",
              "      <td>214</td>\n",
              "      <td>0.976934</td>\n",
              "      <td>0.976934</td>\n",
              "      <td>0.976934</td>\n",
              "      <td>0.990926</td>\n",
              "      <td>0.645714</td>\n",
              "      <td>0.535865</td>\n",
              "      <td>0.831090</td>\n",
              "      <td>0.987209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.302900</td>\n",
              "      <td>0.627065</td>\n",
              "      <td>0.647134</td>\n",
              "      <td>0.793801</td>\n",
              "      <td>0.692739</td>\n",
              "      <td>0.929389</td>\n",
              "      <td>0.986835</td>\n",
              "      <td>0.909787</td>\n",
              "      <td>27595</td>\n",
              "      <td>1261</td>\n",
              "      <td>216</td>\n",
              "      <td>2843</td>\n",
              "      <td>0.477273</td>\n",
              "      <td>0.351598</td>\n",
              "      <td>0.742765</td>\n",
              "      <td>0.989455</td>\n",
              "      <td>0.449779</td>\n",
              "      <td>31178</td>\n",
              "      <td>426</td>\n",
              "      <td>80</td>\n",
              "      <td>231</td>\n",
              "      <td>0.811999</td>\n",
              "      <td>0.727863</td>\n",
              "      <td>0.918129</td>\n",
              "      <td>0.993558</td>\n",
              "      <td>0.895570</td>\n",
              "      <td>29618</td>\n",
              "      <td>587</td>\n",
              "      <td>140</td>\n",
              "      <td>1570</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.442308</td>\n",
              "      <td>0.711340</td>\n",
              "      <td>0.979765</td>\n",
              "      <td>0.483205</td>\n",
              "      <td>31731</td>\n",
              "      <td>87</td>\n",
              "      <td>28</td>\n",
              "      <td>69</td>\n",
              "      <td>0.741230</td>\n",
              "      <td>0.622014</td>\n",
              "      <td>0.916981</td>\n",
              "      <td>0.988653</td>\n",
              "      <td>0.799376</td>\n",
              "      <td>29439</td>\n",
              "      <td>886</td>\n",
              "      <td>132</td>\n",
              "      <td>1458</td>\n",
              "      <td>0.513043</td>\n",
              "      <td>0.374010</td>\n",
              "      <td>0.816609</td>\n",
              "      <td>0.988585</td>\n",
              "      <td>0.572882</td>\n",
              "      <td>31231</td>\n",
              "      <td>395</td>\n",
              "      <td>53</td>\n",
              "      <td>236</td>\n",
              "      <td>0.977592</td>\n",
              "      <td>0.977592</td>\n",
              "      <td>0.977592</td>\n",
              "      <td>0.991236</td>\n",
              "      <td>0.647134</td>\n",
              "      <td>0.535088</td>\n",
              "      <td>0.839202</td>\n",
              "      <td>0.987809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.205500</td>\n",
              "      <td>0.887501</td>\n",
              "      <td>0.663888</td>\n",
              "      <td>0.792669</td>\n",
              "      <td>0.692834</td>\n",
              "      <td>0.926120</td>\n",
              "      <td>0.984219</td>\n",
              "      <td>0.886975</td>\n",
              "      <td>27600</td>\n",
              "      <td>1256</td>\n",
              "      <td>226</td>\n",
              "      <td>2833</td>\n",
              "      <td>0.493082</td>\n",
              "      <td>0.404959</td>\n",
              "      <td>0.630225</td>\n",
              "      <td>0.989108</td>\n",
              "      <td>0.441843</td>\n",
              "      <td>31316</td>\n",
              "      <td>288</td>\n",
              "      <td>115</td>\n",
              "      <td>196</td>\n",
              "      <td>0.821238</td>\n",
              "      <td>0.755152</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.992221</td>\n",
              "      <td>0.891017</td>\n",
              "      <td>29706</td>\n",
              "      <td>499</td>\n",
              "      <td>171</td>\n",
              "      <td>1539</td>\n",
              "      <td>0.546154</td>\n",
              "      <td>0.435583</td>\n",
              "      <td>0.731959</td>\n",
              "      <td>0.980264</td>\n",
              "      <td>0.470178</td>\n",
              "      <td>31726</td>\n",
              "      <td>92</td>\n",
              "      <td>26</td>\n",
              "      <td>71</td>\n",
              "      <td>0.757559</td>\n",
              "      <td>0.663671</td>\n",
              "      <td>0.882390</td>\n",
              "      <td>0.987728</td>\n",
              "      <td>0.792052</td>\n",
              "      <td>29614</td>\n",
              "      <td>711</td>\n",
              "      <td>187</td>\n",
              "      <td>1403</td>\n",
              "      <td>0.572626</td>\n",
              "      <td>0.480094</td>\n",
              "      <td>0.709343</td>\n",
              "      <td>0.985552</td>\n",
              "      <td>0.562001</td>\n",
              "      <td>31404</td>\n",
              "      <td>222</td>\n",
              "      <td>84</td>\n",
              "      <td>205</td>\n",
              "      <td>0.979754</td>\n",
              "      <td>0.979754</td>\n",
              "      <td>0.979754</td>\n",
              "      <td>0.990480</td>\n",
              "      <td>0.663888</td>\n",
              "      <td>0.572049</td>\n",
              "      <td>0.796673</td>\n",
              "      <td>0.986515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.145100</td>\n",
              "      <td>1.006753</td>\n",
              "      <td>0.667716</td>\n",
              "      <td>0.816482</td>\n",
              "      <td>0.738177</td>\n",
              "      <td>0.913370</td>\n",
              "      <td>0.985344</td>\n",
              "      <td>0.900385</td>\n",
              "      <td>27865</td>\n",
              "      <td>991</td>\n",
              "      <td>265</td>\n",
              "      <td>2794</td>\n",
              "      <td>0.483173</td>\n",
              "      <td>0.385797</td>\n",
              "      <td>0.646302</td>\n",
              "      <td>0.988721</td>\n",
              "      <td>0.421466</td>\n",
              "      <td>31284</td>\n",
              "      <td>320</td>\n",
              "      <td>110</td>\n",
              "      <td>201</td>\n",
              "      <td>0.822872</td>\n",
              "      <td>0.754634</td>\n",
              "      <td>0.904678</td>\n",
              "      <td>0.991831</td>\n",
              "      <td>0.886228</td>\n",
              "      <td>29702</td>\n",
              "      <td>503</td>\n",
              "      <td>163</td>\n",
              "      <td>1547</td>\n",
              "      <td>0.541833</td>\n",
              "      <td>0.441558</td>\n",
              "      <td>0.701031</td>\n",
              "      <td>0.978552</td>\n",
              "      <td>0.455903</td>\n",
              "      <td>31732</td>\n",
              "      <td>86</td>\n",
              "      <td>29</td>\n",
              "      <td>68</td>\n",
              "      <td>0.759804</td>\n",
              "      <td>0.670029</td>\n",
              "      <td>0.877358</td>\n",
              "      <td>0.987401</td>\n",
              "      <td>0.776451</td>\n",
              "      <td>29638</td>\n",
              "      <td>687</td>\n",
              "      <td>195</td>\n",
              "      <td>1395</td>\n",
              "      <td>0.582133</td>\n",
              "      <td>0.498765</td>\n",
              "      <td>0.698962</td>\n",
              "      <td>0.982079</td>\n",
              "      <td>0.561049</td>\n",
              "      <td>31423</td>\n",
              "      <td>203</td>\n",
              "      <td>87</td>\n",
              "      <td>202</td>\n",
              "      <td>0.980996</td>\n",
              "      <td>0.980996</td>\n",
              "      <td>0.980996</td>\n",
              "      <td>0.990346</td>\n",
              "      <td>0.667716</td>\n",
              "      <td>0.581493</td>\n",
              "      <td>0.790284</td>\n",
              "      <td>0.985655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Model Evaluation Results:\n",
            "    f1: 0.6677\n",
            "    loss: 1.0068\n",
            "    toxic_f1: 0.8165\n",
            "    toxic_precision: 0.7382\n",
            "    toxic_recall: 0.9134\n",
            "    toxic_roc_auc: 0.9853\n",
            "    toxic_pr_auc: 0.9004\n",
            "    toxic_tn: 27865.0000\n",
            "    toxic_fp: 991.0000\n",
            "    toxic_fn: 265.0000\n",
            "    toxic_tp: 2794.0000\n",
            "    severe_toxic_f1: 0.4832\n",
            "    severe_toxic_precision: 0.3858\n",
            "    severe_toxic_recall: 0.6463\n",
            "    severe_toxic_roc_auc: 0.9887\n",
            "    severe_toxic_pr_auc: 0.4215\n",
            "    severe_toxic_tn: 31284.0000\n",
            "    severe_toxic_fp: 320.0000\n",
            "    severe_toxic_fn: 110.0000\n",
            "    severe_toxic_tp: 201.0000\n",
            "    obscene_f1: 0.8229\n",
            "    obscene_precision: 0.7546\n",
            "    obscene_recall: 0.9047\n",
            "    obscene_roc_auc: 0.9918\n",
            "    obscene_pr_auc: 0.8862\n",
            "    obscene_tn: 29702.0000\n",
            "    obscene_fp: 503.0000\n",
            "    obscene_fn: 163.0000\n",
            "    obscene_tp: 1547.0000\n",
            "    threat_f1: 0.5418\n",
            "    threat_precision: 0.4416\n",
            "    threat_recall: 0.7010\n",
            "    threat_roc_auc: 0.9786\n",
            "    threat_pr_auc: 0.4559\n",
            "    threat_tn: 31732.0000\n",
            "    threat_fp: 86.0000\n",
            "    threat_fn: 29.0000\n",
            "    threat_tp: 68.0000\n",
            "    insult_f1: 0.7598\n",
            "    insult_precision: 0.6700\n",
            "    insult_recall: 0.8774\n",
            "    insult_roc_auc: 0.9874\n",
            "    insult_pr_auc: 0.7765\n",
            "    insult_tn: 29638.0000\n",
            "    insult_fp: 687.0000\n",
            "    insult_fn: 195.0000\n",
            "    insult_tp: 1395.0000\n",
            "    identity_hate_f1: 0.5821\n",
            "    identity_hate_precision: 0.4988\n",
            "    identity_hate_recall: 0.6990\n",
            "    identity_hate_roc_auc: 0.9821\n",
            "    identity_hate_pr_auc: 0.5610\n",
            "    identity_hate_tn: 31423.0000\n",
            "    identity_hate_fp: 203.0000\n",
            "    identity_hate_fn: 87.0000\n",
            "    identity_hate_tp: 202.0000\n",
            "    micro_f1: 0.9810\n",
            "    micro_precision: 0.9810\n",
            "    micro_recall: 0.9810\n",
            "    micro_roc_auc: 0.9903\n",
            "    macro_f1: 0.6677\n",
            "    macro_precision: 0.5815\n",
            "    macro_recall: 0.7903\n",
            "    macro_roc_auc: 0.9857\n",
            "    runtime: 61.9888\n",
            "    samples_per_second: 514.8510\n",
            "    steps_per_second: 32.1830\n",
            "\n",
            "Optimizing classification thresholds for final model evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-09 22:45:28,513] A new study created in memory with name: multilabel_threshold_optimization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56a40d30e6f34661bd343371dc74d8c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-07-09 22:45:28,536] Trial 0 finished with value: 0.6709520813971118 and parameters: {'threshold_toxic': 0.4547605488666665, 'threshold_severe_toxic': 0.524701025941887, 'threshold_obscene': 0.5879247327353317, 'threshold_threat': 0.5103572445858705, 'threshold_insult': 0.874816273954321, 'threshold_identity_hate': 0.6095196155204955}. Best is trial 0 with value: 0.6709520813971118.\n",
            "[I 2025-07-09 22:45:28,549] Trial 1 finished with value: 0.6622658221236178 and parameters: {'threshold_toxic': 0.8801252346468774, 'threshold_severe_toxic': 0.16463014965786815, 'threshold_obscene': 0.10256780644602169, 'threshold_threat': 0.13121456555077968, 'threshold_insult': 0.3911755571747306, 'threshold_identity_hate': 0.3679013112678855}. Best is trial 0 with value: 0.6709520813971118.\n",
            "[I 2025-07-09 22:45:28,563] Trial 2 finished with value: 0.6691552204620769 and parameters: {'threshold_toxic': 0.7250511737010551, 'threshold_severe_toxic': 0.6494576250283648, 'threshold_obscene': 0.1149370752205372, 'threshold_threat': 0.8311386827413877, 'threshold_insult': 0.852434069590153, 'threshold_identity_hate': 0.7436714377302334}. Best is trial 0 with value: 0.6709520813971118.\n",
            "[I 2025-07-09 22:45:28,576] Trial 3 finished with value: 0.6569629161074305 and parameters: {'threshold_toxic': 0.1891624077943127, 'threshold_severe_toxic': 0.25507396667787124, 'threshold_obscene': 0.14289379200582122, 'threshold_threat': 0.1213814306963533, 'threshold_insult': 0.44668873583612423, 'threshold_identity_hate': 0.41133718440391054}. Best is trial 0 with value: 0.6709520813971118.\n",
            "[I 2025-07-09 22:45:28,589] Trial 4 finished with value: 0.6600549327487572 and parameters: {'threshold_toxic': 0.2220892789281977, 'threshold_severe_toxic': 0.26318826172503346, 'threshold_obscene': 0.6377150168994041, 'threshold_threat': 0.5666723056697499, 'threshold_insult': 0.35348190302021365, 'threshold_identity_hate': 0.10971168369404004}. Best is trial 0 with value: 0.6709520813971118.\n",
            "[I 2025-07-09 22:45:28,604] Trial 5 finished with value: 0.6708462328159001 and parameters: {'threshold_toxic': 0.7700457898949389, 'threshold_severe_toxic': 0.6254767932171121, 'threshold_obscene': 0.8315887481712073, 'threshold_threat': 0.2402983149283502, 'threshold_insult': 0.5239668320647803, 'threshold_identity_hate': 0.7170276971983837}. Best is trial 0 with value: 0.6709520813971118.\n",
            "[I 2025-07-09 22:45:28,618] Trial 6 finished with value: 0.6690819929489362 and parameters: {'threshold_toxic': 0.4267341587598027, 'threshold_severe_toxic': 0.29788941687906156, 'threshold_obscene': 0.5974458153145402, 'threshold_threat': 0.6775217973495997, 'threshold_insult': 0.1660048002071596, 'threshold_identity_hate': 0.8229976072038389}. Best is trial 0 with value: 0.6709520813971118.\n",
            "[I 2025-07-09 22:45:28,632] Trial 7 finished with value: 0.6647400574240597 and parameters: {'threshold_toxic': 0.4567593434239312, 'threshold_severe_toxic': 0.5222145660316251, 'threshold_obscene': 0.5251219132227425, 'threshold_threat': 0.22680890032237172, 'threshold_insult': 0.2611725807234714, 'threshold_identity_hate': 0.5923765991191687}. Best is trial 0 with value: 0.6709520813971118.\n",
            "[I 2025-07-09 22:45:28,644] Trial 8 finished with value: 0.6720078907074382 and parameters: {'threshold_toxic': 0.6040205634729048, 'threshold_severe_toxic': 0.7047161679341037, 'threshold_obscene': 0.4693739531671838, 'threshold_threat': 0.6160168461119616, 'threshold_insult': 0.11417932412388634, 'threshold_identity_hate': 0.7621976065158224}. Best is trial 8 with value: 0.6720078907074382.\n",
            "[I 2025-07-09 22:45:28,658] Trial 9 finished with value: 0.6593324091150982 and parameters: {'threshold_toxic': 0.3433546457219595, 'threshold_severe_toxic': 0.11460464760792269, 'threshold_obscene': 0.4472805829527483, 'threshold_threat': 0.12177030742660594, 'threshold_insult': 0.22539388738807287, 'threshold_identity_hate': 0.4829007615964497}. Best is trial 8 with value: 0.6720078907074382.\n",
            "[I 2025-07-09 22:45:28,693] Trial 10 finished with value: 0.6706954542103065 and parameters: {'threshold_toxic': 0.6114110881182986, 'threshold_severe_toxic': 0.849322283708333, 'threshold_obscene': 0.3337471743537561, 'threshold_threat': 0.8893222141797256, 'threshold_insult': 0.6257691041159058, 'threshold_identity_hate': 0.8990248046937707}. Best is trial 8 with value: 0.6720078907074382.\n",
            "[I 2025-07-09 22:45:28,728] Trial 11 finished with value: 0.6728329867202235 and parameters: {'threshold_toxic': 0.5848997496570442, 'threshold_severe_toxic': 0.8230757031808041, 'threshold_obscene': 0.7457329762366152, 'threshold_threat': 0.4362188563900713, 'threshold_insult': 0.899076765049631, 'threshold_identity_hate': 0.5985731927257406}. Best is trial 11 with value: 0.6728329867202235.\n",
            "[I 2025-07-09 22:45:28,763] Trial 12 finished with value: 0.6720288543271077 and parameters: {'threshold_toxic': 0.6129507948249411, 'threshold_severe_toxic': 0.8729824151365939, 'threshold_obscene': 0.7904954349185944, 'threshold_threat': 0.38338585694504534, 'threshold_insult': 0.695638877665458, 'threshold_identity_hate': 0.6517007063697584}. Best is trial 11 with value: 0.6728329867202235.\n",
            "[I 2025-07-09 22:45:28,797] Trial 13 finished with value: 0.6707977137848702 and parameters: {'threshold_toxic': 0.5989224898645873, 'threshold_severe_toxic': 0.8767868567937487, 'threshold_obscene': 0.8400843874032953, 'threshold_threat': 0.38063716522324914, 'threshold_insult': 0.7131918697409171, 'threshold_identity_hate': 0.6015645269526705}. Best is trial 11 with value: 0.6728329867202235.\n",
            "[I 2025-07-09 22:45:28,833] Trial 14 finished with value: 0.668675277624915 and parameters: {'threshold_toxic': 0.6963949531097712, 'threshold_severe_toxic': 0.7957127186585053, 'threshold_obscene': 0.731913712004223, 'threshold_threat': 0.3984410564741135, 'threshold_insult': 0.7543548346530992, 'threshold_identity_hate': 0.2744670239796132}. Best is trial 11 with value: 0.6728329867202235.\n",
            "[I 2025-07-09 22:45:28,865] Trial 15 finished with value: 0.6712182827510186 and parameters: {'threshold_toxic': 0.32328880157111767, 'threshold_severe_toxic': 0.74990073746175, 'threshold_obscene': 0.7343857045183906, 'threshold_threat': 0.39104168404066736, 'threshold_insult': 0.7532514184698856, 'threshold_identity_hate': 0.6347979409831466}. Best is trial 11 with value: 0.6728329867202235.\n",
            "[I 2025-07-09 22:45:28,899] Trial 16 finished with value: 0.6687049534665145 and parameters: {'threshold_toxic': 0.5521993616900545, 'threshold_severe_toxic': 0.8954965176574963, 'threshold_obscene': 0.8974839434689983, 'threshold_threat': 0.31375392692090837, 'threshold_insult': 0.6092234457008285, 'threshold_identity_hate': 0.52338491330675}. Best is trial 11 with value: 0.6728329867202235.\n",
            "[I 2025-07-09 22:45:28,933] Trial 17 finished with value: 0.6730188115610853 and parameters: {'threshold_toxic': 0.8289352972131792, 'threshold_severe_toxic': 0.6183465228546121, 'threshold_obscene': 0.7313980771403221, 'threshold_threat': 0.7189101294911232, 'threshold_insult': 0.829011582887728, 'threshold_identity_hate': 0.4727478054369292}. Best is trial 17 with value: 0.6730188115610853.\n",
            "[I 2025-07-09 22:45:28,968] Trial 18 finished with value: 0.6696728384363432 and parameters: {'threshold_toxic': 0.8785165606207884, 'threshold_severe_toxic': 0.40818271311306853, 'threshold_obscene': 0.6962655654546498, 'threshold_threat': 0.7051915596821272, 'threshold_insult': 0.8982619837480085, 'threshold_identity_hate': 0.3059730399682498}. Best is trial 17 with value: 0.6730188115610853.\n",
            "[I 2025-07-09 22:45:29,003] Trial 19 finished with value: 0.6716124826672644 and parameters: {'threshold_toxic': 0.7933332236645472, 'threshold_severe_toxic': 0.5996391460225902, 'threshold_obscene': 0.37292685602096376, 'threshold_threat': 0.7564910680503901, 'threshold_insult': 0.8054099763578118, 'threshold_identity_hate': 0.5041057291271779}. Best is trial 17 with value: 0.6730188115610853.\n",
            "[I 2025-07-09 22:45:29,040] Trial 20 finished with value: 0.659756949738466 and parameters: {'threshold_toxic': 0.10286405647678015, 'threshold_severe_toxic': 0.4608366151159328, 'threshold_obscene': 0.6539618671072789, 'threshold_threat': 0.481762782449361, 'threshold_insult': 0.5978193009551447, 'threshold_identity_hate': 0.19549050593902162}. Best is trial 17 with value: 0.6730188115610853.\n",
            "[I 2025-07-09 22:45:29,074] Trial 21 finished with value: 0.6710766859685177 and parameters: {'threshold_toxic': 0.667652923357086, 'threshold_severe_toxic': 0.7934286687904798, 'threshold_obscene': 0.7871116496344445, 'threshold_threat': 0.47327692472073957, 'threshold_insult': 0.6867492353892531, 'threshold_identity_hate': 0.43640115061533846}. Best is trial 17 with value: 0.6730188115610853.\n",
            "[I 2025-07-09 22:45:29,109] Trial 22 finished with value: 0.6764191559298176 and parameters: {'threshold_toxic': 0.5215561946430466, 'threshold_severe_toxic': 0.7107996270035188, 'threshold_obscene': 0.7887771817982193, 'threshold_threat': 0.5655431309360003, 'threshold_insult': 0.80621750523266, 'threshold_identity_hate': 0.6757022418624055}. Best is trial 22 with value: 0.6764191559298176.\n",
            "[I 2025-07-09 22:45:29,146] Trial 23 finished with value: 0.6752553572493994 and parameters: {'threshold_toxic': 0.527474253005343, 'threshold_severe_toxic': 0.7089422751036935, 'threshold_obscene': 0.8978703000850099, 'threshold_threat': 0.6033723914529255, 'threshold_insult': 0.8053940486527491, 'threshold_identity_hate': 0.5416575929906606}. Best is trial 22 with value: 0.6764191559298176.\n",
            "[I 2025-07-09 22:45:29,181] Trial 24 finished with value: 0.673665381306345 and parameters: {'threshold_toxic': 0.3706789808947716, 'threshold_severe_toxic': 0.6887052852860747, 'threshold_obscene': 0.879632083763077, 'threshold_threat': 0.6010615174830163, 'threshold_insult': 0.8016859810418979, 'threshold_identity_hate': 0.5371422929153861}. Best is trial 22 with value: 0.6764191559298176.\n",
            "[I 2025-07-09 22:45:29,219] Trial 25 finished with value: 0.6767881417558589 and parameters: {'threshold_toxic': 0.3687165859600553, 'threshold_severe_toxic': 0.71941634460165, 'threshold_obscene': 0.8879217005532785, 'threshold_threat': 0.6017423205496008, 'threshold_insult': 0.7844652100928831, 'threshold_identity_hate': 0.7082258939349968}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,254] Trial 26 finished with value: 0.6754371443966902 and parameters: {'threshold_toxic': 0.5117593935477056, 'threshold_severe_toxic': 0.7333010658068159, 'threshold_obscene': 0.893245220882025, 'threshold_threat': 0.5448484050819262, 'threshold_insult': 0.5224934218554947, 'threshold_identity_hate': 0.6924926786736132}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,291] Trial 27 finished with value: 0.671946848954839 and parameters: {'threshold_toxic': 0.2926041202276388, 'threshold_severe_toxic': 0.7642455305574686, 'threshold_obscene': 0.8211201679483282, 'threshold_threat': 0.5359051697683569, 'threshold_insult': 0.5123699176594951, 'threshold_identity_hate': 0.689209210714285}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,327] Trial 28 finished with value: 0.6723717685085749 and parameters: {'threshold_toxic': 0.3936091140664106, 'threshold_severe_toxic': 0.5599657208195719, 'threshold_obscene': 0.238435580289297, 'threshold_threat': 0.6571820066146855, 'threshold_insult': 0.5599220694172496, 'threshold_identity_hate': 0.8077437154513835}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,367] Trial 29 finished with value: 0.6737276572663938 and parameters: {'threshold_toxic': 0.5146164250022512, 'threshold_severe_toxic': 0.4311615107733552, 'threshold_obscene': 0.8504345698536431, 'threshold_threat': 0.5241086891225522, 'threshold_insult': 0.6451235102631729, 'threshold_identity_hate': 0.887985599183337}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,403] Trial 30 finished with value: 0.6739914995275654 and parameters: {'threshold_toxic': 0.46686780836458547, 'threshold_severe_toxic': 0.7378725252078827, 'threshold_obscene': 0.5330317988946605, 'threshold_threat': 0.5573087672046545, 'threshold_insult': 0.4562721211934937, 'threshold_identity_hate': 0.8015939166997235}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,440] Trial 31 finished with value: 0.6763213925741657 and parameters: {'threshold_toxic': 0.4981396765354991, 'threshold_severe_toxic': 0.6809458653738104, 'threshold_obscene': 0.8812396182450717, 'threshold_threat': 0.6112668192850527, 'threshold_insult': 0.7633452984776334, 'threshold_identity_hate': 0.6813828634628953}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,475] Trial 32 finished with value: 0.675952339639093 and parameters: {'threshold_toxic': 0.48414765412865, 'threshold_severe_toxic': 0.6717283250421292, 'threshold_obscene': 0.787459772969865, 'threshold_threat': 0.6405616540151811, 'threshold_insult': 0.7528174891417022, 'threshold_identity_hate': 0.6811696677858304}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,512] Trial 33 finished with value: 0.6721116287147236 and parameters: {'threshold_toxic': 0.41854972131050444, 'threshold_severe_toxic': 0.6773297278915767, 'threshold_obscene': 0.7871120742379012, 'threshold_threat': 0.7810351584628736, 'threshold_insult': 0.7529581464660224, 'threshold_identity_hate': 0.6642249115980574}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,546] Trial 34 finished with value: 0.6750823141266133 and parameters: {'threshold_toxic': 0.47176259091496614, 'threshold_severe_toxic': 0.5783427105872, 'threshold_obscene': 0.669990634749248, 'threshold_threat': 0.6420289559477114, 'threshold_insult': 0.7566154176059166, 'threshold_identity_hate': 0.7492935569065725}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,582] Trial 35 finished with value: 0.6715121078733525 and parameters: {'threshold_toxic': 0.29442503866131764, 'threshold_severe_toxic': 0.6410742830814701, 'threshold_obscene': 0.7788134404773867, 'threshold_threat': 0.790299709096405, 'threshold_insult': 0.8515158145961434, 'threshold_identity_hate': 0.8437246370476649}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,619] Trial 36 finished with value: 0.6733976564503174 and parameters: {'threshold_toxic': 0.2680028167579705, 'threshold_severe_toxic': 0.6592843943269383, 'threshold_obscene': 0.6073570021607735, 'threshold_threat': 0.585392223800566, 'threshold_insult': 0.6686880802000392, 'threshold_identity_hate': 0.7335885469073011}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,657] Trial 37 finished with value: 0.6710980497070583 and parameters: {'threshold_toxic': 0.4168012012187754, 'threshold_severe_toxic': 0.5558595124157056, 'threshold_obscene': 0.8462569556981507, 'threshold_threat': 0.7088502102224414, 'threshold_insult': 0.8540262867960334, 'threshold_identity_hate': 0.5674455242537011}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,692] Trial 38 finished with value: 0.6753293761231954 and parameters: {'threshold_toxic': 0.5519379603024956, 'threshold_severe_toxic': 0.809155200331661, 'threshold_obscene': 0.6891161648448212, 'threshold_threat': 0.6382608375600966, 'threshold_insult': 0.7308311946298259, 'threshold_identity_hate': 0.7772419683153627}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,727] Trial 39 finished with value: 0.6671404326066814 and parameters: {'threshold_toxic': 0.1838659993964285, 'threshold_severe_toxic': 0.49344205661741214, 'threshold_obscene': 0.8286117827011088, 'threshold_threat': 0.8420726001679298, 'threshold_insult': 0.7889258737487354, 'threshold_identity_hate': 0.7185635534023282}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,764] Trial 40 finished with value: 0.669997943819026 and parameters: {'threshold_toxic': 0.6436897986462531, 'threshold_severe_toxic': 0.37823371905924674, 'threshold_obscene': 0.5548090720647696, 'threshold_threat': 0.496021715205744, 'threshold_insult': 0.35582496005739617, 'threshold_identity_hate': 0.8550402284304819}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,800] Trial 41 finished with value: 0.6752795180531864 and parameters: {'threshold_toxic': 0.46659711978761326, 'threshold_severe_toxic': 0.7213646536404338, 'threshold_obscene': 0.8652820698928918, 'threshold_threat': 0.5629624802238796, 'threshold_insult': 0.4456132373170187, 'threshold_identity_hate': 0.6947158037611497}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,837] Trial 42 finished with value: 0.6743030035026328 and parameters: {'threshold_toxic': 0.5010122439008564, 'threshold_severe_toxic': 0.7577381057571821, 'threshold_obscene': 0.8086236383239072, 'threshold_threat': 0.6773194380332623, 'threshold_insult': 0.56710261884624, 'threshold_identity_hate': 0.6715066394878454}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,875] Trial 43 finished with value: 0.6718433508374505 and parameters: {'threshold_toxic': 0.3744019362989475, 'threshold_severe_toxic': 0.6585653790220424, 'threshold_obscene': 0.8939318872554572, 'threshold_threat': 0.4517427829074482, 'threshold_insult': 0.6518059559509828, 'threshold_identity_hate': 0.778807872387259}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,910] Trial 44 finished with value: 0.6723745172986897 and parameters: {'threshold_toxic': 0.5442419569940394, 'threshold_severe_toxic': 0.8329618762182368, 'threshold_obscene': 0.7606099839138444, 'threshold_threat': 0.5485990272879256, 'threshold_insult': 0.25103812673775855, 'threshold_identity_hate': 0.6194224651516016}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,947] Trial 45 finished with value: 0.6755051566249954 and parameters: {'threshold_toxic': 0.44492153564045567, 'threshold_severe_toxic': 0.7718801491455454, 'threshold_obscene': 0.8599896943476466, 'threshold_threat': 0.6281674045288571, 'threshold_insult': 0.7109301640372447, 'threshold_identity_hate': 0.7181166300206036}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:29,986] Trial 46 finished with value: 0.6723960934096168 and parameters: {'threshold_toxic': 0.42344305454496234, 'threshold_severe_toxic': 0.7843469006660659, 'threshold_obscene': 0.7065109783392919, 'threshold_threat': 0.7448969467255303, 'threshold_insult': 0.7164384136446912, 'threshold_identity_hate': 0.629998779209937}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,022] Trial 47 finished with value: 0.6745156343978657 and parameters: {'threshold_toxic': 0.34188392056640193, 'threshold_severe_toxic': 0.6974718096690183, 'threshold_obscene': 0.8096821708043953, 'threshold_threat': 0.6274444490520195, 'threshold_insult': 0.8620219023506139, 'threshold_identity_hate': 0.5750578558508451}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,060] Trial 48 finished with value: 0.6734022599527422 and parameters: {'threshold_toxic': 0.566310538181752, 'threshold_severe_toxic': 0.8448166541250772, 'threshold_obscene': 0.6284961328625881, 'threshold_threat': 0.6796341203348715, 'threshold_insult': 0.7789383245809337, 'threshold_identity_hate': 0.7264950589267885}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,099] Trial 49 finished with value: 0.6745109265930038 and parameters: {'threshold_toxic': 0.4452344992180367, 'threshold_severe_toxic': 0.618331980384819, 'threshold_obscene': 0.8460793602471182, 'threshold_threat': 0.6693237911890534, 'threshold_insult': 0.8380421622122022, 'threshold_identity_hate': 0.6446000784086057}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,134] Trial 50 finished with value: 0.6737034657836388 and parameters: {'threshold_toxic': 0.48463407243199036, 'threshold_severe_toxic': 0.5315129677148355, 'threshold_obscene': 0.7538143321087841, 'threshold_threat': 0.5787327863960691, 'threshold_insult': 0.7030163902353564, 'threshold_identity_hate': 0.7544762889858887}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,171] Trial 51 finished with value: 0.6758826185007697 and parameters: {'threshold_toxic': 0.504533822368561, 'threshold_severe_toxic': 0.7311397230985623, 'threshold_obscene': 0.8720338765337462, 'threshold_threat': 0.5160887594610385, 'threshold_insult': 0.8217978167310384, 'threshold_identity_hate': 0.6936651343511921}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,210] Trial 52 finished with value: 0.6734738432475286 and parameters: {'threshold_toxic': 0.3897431144272162, 'threshold_severe_toxic': 0.7640802855535209, 'threshold_obscene': 0.8681707335209741, 'threshold_threat': 0.5006986894285381, 'threshold_insult': 0.8235215375804116, 'threshold_identity_hate': 0.7102446143577974}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,248] Trial 53 finished with value: 0.6767813623558654 and parameters: {'threshold_toxic': 0.6314676116401791, 'threshold_severe_toxic': 0.6753298166440951, 'threshold_obscene': 0.8095085297427596, 'threshold_threat': 0.607587840154561, 'threshold_insult': 0.887551743160502, 'threshold_identity_hate': 0.6591078580721171}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,287] Trial 54 finished with value: 0.6738228984693055 and parameters: {'threshold_toxic': 0.6363414147976109, 'threshold_severe_toxic': 0.595911313575016, 'threshold_obscene': 0.8071292925780167, 'threshold_threat': 0.42767353284886955, 'threshold_insult': 0.8696643467938522, 'threshold_identity_hate': 0.6619162715183998}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,326] Trial 55 finished with value: 0.6714661779337562 and parameters: {'threshold_toxic': 0.7416634173494825, 'threshold_severe_toxic': 0.6687692892944737, 'threshold_obscene': 0.7266770606469283, 'threshold_threat': 0.32591856875427216, 'threshold_insult': 0.8957004477132964, 'threshold_identity_hate': 0.5904312157966382}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,362] Trial 56 finished with value: 0.6761475536837166 and parameters: {'threshold_toxic': 0.682834327563852, 'threshold_severe_toxic': 0.6898699220686489, 'threshold_obscene': 0.76875814416179, 'threshold_threat': 0.6014783397875485, 'threshold_insult': 0.7816772994618215, 'threshold_identity_hate': 0.6115365035538635}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,398] Trial 57 finished with value: 0.6754424267252888 and parameters: {'threshold_toxic': 0.7028969609234359, 'threshold_severe_toxic': 0.6314766889945334, 'threshold_obscene': 0.7719229057839958, 'threshold_threat': 0.5832010072682902, 'threshold_insult': 0.7631674371142617, 'threshold_identity_hate': 0.6148680597636021}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,436] Trial 58 finished with value: 0.6725827634721805 and parameters: {'threshold_toxic': 0.5760260131019627, 'threshold_severe_toxic': 0.6957678017831861, 'threshold_obscene': 0.709216168029577, 'threshold_threat': 0.6967645520171513, 'threshold_insult': 0.7843955393247218, 'threshold_identity_hate': 0.5694343709301679}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,473] Trial 59 finished with value: 0.6700887603453213 and parameters: {'threshold_toxic': 0.6737969563320836, 'threshold_severe_toxic': 0.6034238177119606, 'threshold_obscene': 0.3615627976888821, 'threshold_threat': 0.7355316867379833, 'threshold_insult': 0.7291000272810806, 'threshold_identity_hate': 0.44207346530135094}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,510] Trial 60 finished with value: 0.6752860371506738 and parameters: {'threshold_toxic': 0.7481123472928954, 'threshold_severe_toxic': 0.3326368682513711, 'threshold_obscene': 0.8252422259354134, 'threshold_threat': 0.6126008246586175, 'threshold_insult': 0.8868165826146746, 'threshold_identity_hate': 0.6647611871641544}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,548] Trial 61 finished with value: 0.6757335615560365 and parameters: {'threshold_toxic': 0.610222345325024, 'threshold_severe_toxic': 0.7298173150689803, 'threshold_obscene': 0.8019496810223687, 'threshold_threat': 0.5207429057304263, 'threshold_insult': 0.8220804489510087, 'threshold_identity_hate': 0.687871048514369}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,584] Trial 62 finished with value: 0.6753745207525389 and parameters: {'threshold_toxic': 0.528287613446301, 'threshold_severe_toxic': 0.7087536666837563, 'threshold_obscene': 0.4430757720081315, 'threshold_threat': 0.6019756412788585, 'threshold_insult': 0.8247486594925338, 'threshold_identity_hate': 0.6257017520651187}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,620] Trial 63 finished with value: 0.6707731328030438 and parameters: {'threshold_toxic': 0.7812250195644678, 'threshold_severe_toxic': 0.20809963802314568, 'threshold_obscene': 0.8714493061905112, 'threshold_threat': 0.17403588897704148, 'threshold_insult': 0.776927121093936, 'threshold_identity_hate': 0.6452504523522711}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,660] Trial 64 finished with value: 0.672767993725193 and parameters: {'threshold_toxic': 0.6419629729952786, 'threshold_severe_toxic': 0.6462060859101101, 'threshold_obscene': 0.7556316986206874, 'threshold_threat': 0.4651356841255171, 'threshold_insult': 0.741205662695496, 'threshold_identity_hate': 0.7691195137608668}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,696] Trial 65 finished with value: 0.6723810251978851 and parameters: {'threshold_toxic': 0.5857119994884921, 'threshold_severe_toxic': 0.6814548687104915, 'threshold_obscene': 0.8364144390963083, 'threshold_threat': 0.5129313813846076, 'threshold_insult': 0.6780090298269046, 'threshold_identity_hate': 0.5482881569551351}. Best is trial 25 with value: 0.6767881417558589.\n",
            "[I 2025-07-09 22:45:30,735] Trial 66 finished with value: 0.6782270496735493 and parameters: {'threshold_toxic': 0.7031654397415978, 'threshold_severe_toxic': 0.8143805872682972, 'threshold_obscene': 0.8992755514132389, 'threshold_threat': 0.6489672150655806, 'threshold_insult': 0.8131864843070691, 'threshold_identity_hate': 0.6840440100372913}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:30,774] Trial 67 finished with value: 0.677429148509713 and parameters: {'threshold_toxic': 0.8078983190714164, 'threshold_severe_toxic': 0.799667608298261, 'threshold_obscene': 0.794177676119395, 'threshold_threat': 0.6501310987306683, 'threshold_insult': 0.8700334123126117, 'threshold_identity_hate': 0.6001485179519331}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:30,809] Trial 68 finished with value: 0.6724480276728918 and parameters: {'threshold_toxic': 0.8487520073832538, 'threshold_severe_toxic': 0.8747787422357108, 'threshold_obscene': 0.19212789725702695, 'threshold_threat': 0.6538932932129129, 'threshold_insult': 0.8735879418113939, 'threshold_identity_hate': 0.3791721117909713}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:30,846] Trial 69 finished with value: 0.6746938283437154 and parameters: {'threshold_toxic': 0.6946204992906531, 'threshold_severe_toxic': 0.8197845411096625, 'threshold_obscene': 0.8905861971113378, 'threshold_threat': 0.5747371102887613, 'threshold_insult': 0.8460339918492376, 'threshold_identity_hate': 0.5071017791433113}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:30,886] Trial 70 finished with value: 0.6682336866643072 and parameters: {'threshold_toxic': 0.8115986074908985, 'threshold_severe_toxic': 0.8645710655303905, 'threshold_obscene': 0.8367011272546853, 'threshold_threat': 0.688681173171127, 'threshold_insult': 0.8071604509844361, 'threshold_identity_hate': 0.12588570522093218}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:30,922] Trial 71 finished with value: 0.6770007529814572 and parameters: {'threshold_toxic': 0.7223005681066099, 'threshold_severe_toxic': 0.7980392697273602, 'threshold_obscene': 0.777553473549365, 'threshold_threat': 0.6525002358628853, 'threshold_insult': 0.7981556754110684, 'threshold_identity_hate': 0.5862510847529171}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:30,960] Trial 72 finished with value: 0.6759207380445812 and parameters: {'threshold_toxic': 0.753575952699211, 'threshold_severe_toxic': 0.7960732536169165, 'threshold_obscene': 0.7378744799878261, 'threshold_threat': 0.6051625006974729, 'threshold_insult': 0.7960206201763351, 'threshold_identity_hate': 0.5814576385890481}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:30,999] Trial 73 finished with value: 0.6768127921561526 and parameters: {'threshold_toxic': 0.6676287708406713, 'threshold_severe_toxic': 0.8041890850340198, 'threshold_obscene': 0.6772536245836187, 'threshold_threat': 0.6519850228666765, 'threshold_insult': 0.8487080994018805, 'threshold_identity_hate': 0.6053522351330386}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,035] Trial 74 finished with value: 0.6733442535416382 and parameters: {'threshold_toxic': 0.716863718841374, 'threshold_severe_toxic': 0.8128670193864775, 'threshold_obscene': 0.6611589991279571, 'threshold_threat': 0.7226081544071415, 'threshold_insult': 0.8779292817759913, 'threshold_identity_hate': 0.5494976916860848}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,073] Trial 75 finished with value: 0.6730915115526622 and parameters: {'threshold_toxic': 0.8703939328819382, 'threshold_severe_toxic': 0.8948508363901271, 'threshold_obscene': 0.7956039654638928, 'threshold_threat': 0.7675870162083879, 'threshold_insult': 0.8421541918127587, 'threshold_identity_hate': 0.5994947547672331}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,113] Trial 76 finished with value: 0.671772546406573 and parameters: {'threshold_toxic': 0.7288766034252061, 'threshold_severe_toxic': 0.8495796452936589, 'threshold_obscene': 0.8997826074884576, 'threshold_threat': 0.6573977777864045, 'threshold_insult': 0.1214590147855601, 'threshold_identity_hate': 0.47383081867193355}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,151] Trial 77 finished with value: 0.6714095247951768 and parameters: {'threshold_toxic': 0.795939449537501, 'threshold_severe_toxic': 0.7522215707510812, 'threshold_obscene': 0.6783421272075757, 'threshold_threat': 0.8146448771944088, 'threshold_insult': 0.8984664431722976, 'threshold_identity_hate': 0.5191958466215112}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,190] Trial 78 finished with value: 0.6769551976668208 and parameters: {'threshold_toxic': 0.6583089303104295, 'threshold_severe_toxic': 0.7830158733449795, 'threshold_obscene': 0.8554338595371086, 'threshold_threat': 0.5550565010776367, 'threshold_insult': 0.8656021833000758, 'threshold_identity_hate': 0.7075852476143102}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,230] Trial 79 finished with value: 0.6760628341392435 and parameters: {'threshold_toxic': 0.7629370166918727, 'threshold_severe_toxic': 0.7831877731360255, 'threshold_obscene': 0.7153684045295143, 'threshold_threat': 0.5442245471997417, 'threshold_insult': 0.8686998881210216, 'threshold_identity_hate': 0.7393653819680899}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,266] Trial 80 finished with value: 0.6775293818451908 and parameters: {'threshold_toxic': 0.8994732318544466, 'threshold_severe_toxic': 0.8319450619883335, 'threshold_obscene': 0.8222009251289677, 'threshold_threat': 0.6300163191709305, 'threshold_insult': 0.8090159235741589, 'threshold_identity_hate': 0.6409210708646962}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,304] Trial 81 finished with value: 0.6775175975020592 and parameters: {'threshold_toxic': 0.8359994552528385, 'threshold_severe_toxic': 0.7964580923156729, 'threshold_obscene': 0.8211880009219229, 'threshold_threat': 0.6298014856380293, 'threshold_insult': 0.8102400129590847, 'threshold_identity_hate': 0.6428181358388972}. Best is trial 66 with value: 0.6782270496735493.\n",
            "[I 2025-07-09 22:45:31,345] Trial 82 finished with value: 0.679162268159326 and parameters: {'threshold_toxic': 0.8439852818777567, 'threshold_severe_toxic': 0.846502461469659, 'threshold_obscene': 0.8551094966298911, 'threshold_threat': 0.6535037239106992, 'threshold_insult': 0.854463568512299, 'threshold_identity_hate': 0.6430000803226558}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,385] Trial 83 finished with value: 0.6778631292747601 and parameters: {'threshold_toxic': 0.8972510183643629, 'threshold_severe_toxic': 0.8333086624005914, 'threshold_obscene': 0.8506694724710658, 'threshold_threat': 0.6614245900685736, 'threshold_insult': 0.8451550020917852, 'threshold_identity_hate': 0.6310574085860317}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,423] Trial 84 finished with value: 0.6759889660779194 and parameters: {'threshold_toxic': 0.8941873395513216, 'threshold_severe_toxic': 0.8453561226732776, 'threshold_obscene': 0.854006218693295, 'threshold_threat': 0.7132113123592742, 'threshold_insult': 0.8570233731182364, 'threshold_identity_hate': 0.6453956094459196}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,466] Trial 85 finished with value: 0.6759192495634995 and parameters: {'threshold_toxic': 0.8407933266149349, 'threshold_severe_toxic': 0.8979520207367011, 'threshold_obscene': 0.8279630841250555, 'threshold_threat': 0.6635392159506621, 'threshold_insult': 0.811919506317209, 'threshold_identity_hate': 0.6089314046711329}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,505] Trial 86 finished with value: 0.6774571874243248 and parameters: {'threshold_toxic': 0.8545919381986486, 'threshold_severe_toxic': 0.801279648479091, 'threshold_obscene': 0.819207966661261, 'threshold_threat': 0.6371962014441844, 'threshold_insult': 0.8426151835328929, 'threshold_identity_hate': 0.6360472601670015}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,547] Trial 87 finished with value: 0.6756620556292513 and parameters: {'threshold_toxic': 0.859917854455539, 'threshold_severe_toxic': 0.8373814623640025, 'threshold_obscene': 0.8514414224650754, 'threshold_threat': 0.6332694329104561, 'threshold_insult': 0.836406290055171, 'threshold_identity_hate': 0.559907725816032}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,589] Trial 88 finished with value: 0.6758111658827088 and parameters: {'threshold_toxic': 0.8273762034706827, 'threshold_severe_toxic': 0.86258675427273, 'threshold_obscene': 0.8206294215052894, 'threshold_threat': 0.6936187071692383, 'threshold_insult': 0.8051094339785789, 'threshold_identity_hate': 0.632176870180978}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,626] Trial 89 finished with value: 0.6747166739515311 and parameters: {'threshold_toxic': 0.8992601379560179, 'threshold_severe_toxic': 0.824578056055695, 'threshold_obscene': 0.7834798223664706, 'threshold_threat': 0.73313631301192, 'threshold_insult': 0.861835752795849, 'threshold_identity_hate': 0.588874215684571}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,664] Trial 90 finished with value: 0.6756923289244718 and parameters: {'threshold_toxic': 0.8181050039785455, 'threshold_severe_toxic': 0.7843860263152441, 'threshold_obscene': 0.8592013416478577, 'threshold_threat': 0.6276906054357881, 'threshold_insult': 0.8220294121250348, 'threshold_identity_hate': 0.5293370138595029}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,703] Trial 91 finished with value: 0.6788230989618188 and parameters: {'threshold_toxic': 0.8771353317779201, 'threshold_severe_toxic': 0.8041914543166664, 'threshold_obscene': 0.8224634272402163, 'threshold_threat': 0.6557826264445666, 'threshold_insult': 0.8481327868609317, 'threshold_identity_hate': 0.6350594051277402}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,740] Trial 92 finished with value: 0.6776870019681801 and parameters: {'threshold_toxic': 0.8812824634217199, 'threshold_severe_toxic': 0.8105659381441709, 'threshold_obscene': 0.8783835347714763, 'threshold_threat': 0.6761893126583031, 'threshold_insult': 0.8382625970004343, 'threshold_identity_hate': 0.7057933632500512}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,779] Trial 93 finished with value: 0.6773526684621941 and parameters: {'threshold_toxic': 0.8718950086084534, 'threshold_severe_toxic': 0.8101488359675442, 'threshold_obscene': 0.8739073238294459, 'threshold_threat': 0.6697028818290752, 'threshold_insult': 0.83365905570429, 'threshold_identity_hate': 0.6397990416751443}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,818] Trial 94 finished with value: 0.6762521915343149 and parameters: {'threshold_toxic': 0.8740250293676531, 'threshold_severe_toxic': 0.8821440801352153, 'threshold_obscene': 0.8816253534958309, 'threshold_threat': 0.6781821184938917, 'threshold_insult': 0.8381257250709587, 'threshold_identity_hate': 0.6477445386968106}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,856] Trial 95 finished with value: 0.6734556739018135 and parameters: {'threshold_toxic': 0.8518424040762101, 'threshold_severe_toxic': 0.856789965614651, 'threshold_obscene': 0.8205164320812858, 'threshold_threat': 0.7048385880648202, 'threshold_insult': 0.3252032119847169, 'threshold_identity_hate': 0.6757144701186778}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,894] Trial 96 finished with value: 0.6754212207266637 and parameters: {'threshold_toxic': 0.8008923122967522, 'threshold_severe_toxic': 0.8144644061231292, 'threshold_obscene': 0.8699189508567322, 'threshold_threat': 0.7544682339351835, 'threshold_insult': 0.7705094249603647, 'threshold_identity_hate': 0.6665335711065468}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,933] Trial 97 finished with value: 0.6772593995049055 and parameters: {'threshold_toxic': 0.88894466175284, 'threshold_severe_toxic': 0.8289917485672391, 'threshold_obscene': 0.8427280936317535, 'threshold_threat': 0.6716031724058602, 'threshold_insult': 0.875673937223116, 'threshold_identity_hate': 0.6356931886349411}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:31,969] Trial 98 finished with value: 0.6784346437247608 and parameters: {'threshold_toxic': 0.8403804739679139, 'threshold_severe_toxic': 0.7493385379328739, 'threshold_obscene': 0.8806676487432842, 'threshold_threat': 0.6286169297424659, 'threshold_insult': 0.7391481326352318, 'threshold_identity_hate': 0.7056765076320841}. Best is trial 82 with value: 0.679162268159326.\n",
            "[I 2025-07-09 22:45:32,006] Trial 99 finished with value: 0.6773232759778439 and parameters: {'threshold_toxic': 0.8364147018462914, 'threshold_severe_toxic': 0.770957531867247, 'threshold_obscene': 0.7964455974395163, 'threshold_threat': 0.585365040055574, 'threshold_insult': 0.7404659865768712, 'threshold_identity_hate': 0.7038691572433655}. Best is trial 82 with value: 0.679162268159326.\n",
            "Optimized macro F1 (threshold tuning): 0.6792\n",
            "Optimized thresholds:\n",
            "    0.844\n",
            "    0.847\n",
            "    0.855\n",
            "    0.654\n",
            "    0.854\n",
            "    0.643\n",
            "    Saved training history plot to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/training_metrics_plot_Final_Model.png\n",
            "    Saved multilabel confusion matrix plots to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/multilabel_confusion_matrices_Final_Model.png\n",
            "    Saved Multi-label Precision-Recall Curves to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/multilabel_precision_recall_curves_Final_Model.png\n",
            "    Saved Multi-label ROC Curves to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/multilabel_roc_curves_Final_Model.png\n",
            "    Saved Multi-label Probability Distributions to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/multilabel_probability_distributions_Final_Model.png\n",
            "Final optimized thresholds saved to /content/drive/MyDrive/my_electra_multilabel_classifier_results/optimized_thresholds_multilabel.csv\n",
            "Final model saved to /content/drive/MyDrive/my_electra_multilabel_classifier_results/best_electra_multilabel_model\n",
            "Final model training log history saved to /content/drive/MyDrive/my_electra_multilabel_classifier_results/final_electra_multilabel_model_results/final_model_training_log_history.json\n",
            "\n",
            "Training and optimization complete! \n",
            "Results, model checkpoints, and plots are saved in: /content/drive/MyDrive/my_electra_multilabel_classifier_results\n",
            "\n",
            "--- Optuna Optimization Summary Data ---\n",
            "{\n",
            "  \"total_trials_completed\": 7,\n",
            "  \"best_trial_number\": 0,\n",
            "  \"best_objective_value\": 0.6659698987376466,\n",
            "  \"best_hyperparameters\": {\n",
            "    \"learning_rate\": 1.1844319751820392e-05,\n",
            "    \"batch_size\": 16,\n",
            "    \"num_train_epochs\": 4,\n",
            "    \"warmup_ratio\": 0.07340279606636549,\n",
            "    \"weight_decay\": 0.015599452033620266,\n",
            "    \"gradient_accumulation_steps\": 2,\n",
            "    \"lr_scheduler_type\": \"linear\",\n",
            "    \"oversampling_ratio\": 0.9729188669457949,\n",
            "    \"hidden_dropout_prob\": 0.26648852816008434,\n",
            "    \"attention_probs_dropout_prob\": 0.12123391106782762\n",
            "  },\n",
            "  \"trial_history\": [\n",
            "    {\n",
            "      \"trial_number\": 0,\n",
            "      \"state\": \"1\",\n",
            "      \"value\": 0.6659698987376466,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 1.1844319751820392e-05,\n",
            "        \"batch_size\": 16,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.07340279606636549,\n",
            "        \"weight_decay\": 0.015599452033620266,\n",
            "        \"gradient_accumulation_steps\": 2,\n",
            "        \"lr_scheduler_type\": \"linear\",\n",
            "        \"oversampling_ratio\": 0.9729188669457949,\n",
            "        \"hidden_dropout_prob\": 0.26648852816008434,\n",
            "        \"attention_probs_dropout_prob\": 0.12123391106782762\n",
            "      },\n",
            "      \"duration_seconds\": 16009.889635\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 1,\n",
            "      \"state\": \"0\",\n",
            "      \"value\": null,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 7.599674150654901e-06,\n",
            "        \"batch_size\": 32,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.11479175279631737,\n",
            "        \"weight_decay\": 0.029122914019804193,\n",
            "        \"gradient_accumulation_steps\": 1,\n",
            "        \"lr_scheduler_type\": \"cosine\",\n",
            "        \"oversampling_ratio\": 0.8066583652537123,\n",
            "        \"hidden_dropout_prob\": 0.13993475643167194,\n",
            "        \"attention_probs_dropout_prob\": 0.15142344384136117\n",
            "      },\n",
            "      \"duration_seconds\": null\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 2,\n",
            "      \"state\": \"3\",\n",
            "      \"value\": null,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 1.1844319751820392e-05,\n",
            "        \"batch_size\": 16,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.07340279606636549,\n",
            "        \"weight_decay\": 0.015599452033620266,\n",
            "        \"gradient_accumulation_steps\": 2,\n",
            "        \"lr_scheduler_type\": \"linear\",\n",
            "        \"oversampling_ratio\": 0.9729188669457949,\n",
            "        \"hidden_dropout_prob\": 0.26648852816008434,\n",
            "        \"attention_probs_dropout_prob\": 0.12123391106782762\n",
            "      },\n",
            "      \"duration_seconds\": 117.676056\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 3,\n",
            "      \"state\": \"1\",\n",
            "      \"value\": 0.6659698987376466,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 1.1844319751820392e-05,\n",
            "        \"batch_size\": 16,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.07340279606636549,\n",
            "        \"weight_decay\": 0.015599452033620266,\n",
            "        \"gradient_accumulation_steps\": 2,\n",
            "        \"lr_scheduler_type\": \"linear\",\n",
            "        \"oversampling_ratio\": 0.9729188669457949,\n",
            "        \"hidden_dropout_prob\": 0.26648852816008434,\n",
            "        \"attention_probs_dropout_prob\": 0.12123391106782762\n",
            "      },\n",
            "      \"duration_seconds\": 16026.689383\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 4,\n",
            "      \"state\": \"1\",\n",
            "      \"value\": 0.6520154997162748,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 7.599674150654901e-06,\n",
            "        \"batch_size\": 32,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.11479175279631737,\n",
            "        \"weight_decay\": 0.029122914019804193,\n",
            "        \"gradient_accumulation_steps\": 1,\n",
            "        \"lr_scheduler_type\": \"cosine\",\n",
            "        \"oversampling_ratio\": 0.8066583652537123,\n",
            "        \"hidden_dropout_prob\": 0.13993475643167194,\n",
            "        \"attention_probs_dropout_prob\": 0.15142344384136117\n",
            "      },\n",
            "      \"duration_seconds\": 13492.704154\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 5,\n",
            "      \"state\": \"1\",\n",
            "      \"value\": 0.6515064462064342,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 1.9560708142748497e-05,\n",
            "        \"batch_size\": 32,\n",
            "        \"num_train_epochs\": 2,\n",
            "        \"warmup_ratio\": 0.05975773894779193,\n",
            "        \"weight_decay\": 0.09488855372533334,\n",
            "        \"gradient_accumulation_steps\": 1,\n",
            "        \"lr_scheduler_type\": \"cosine\",\n",
            "        \"oversampling_ratio\": 0.4961372443656412,\n",
            "        \"hidden_dropout_prob\": 0.12440764696895577,\n",
            "        \"attention_probs_dropout_prob\": 0.14951769101112702\n",
            "      },\n",
            "      \"duration_seconds\": 6870.479842\n",
            "    },\n",
            "    {\n",
            "      \"trial_number\": 6,\n",
            "      \"state\": \"3\",\n",
            "      \"value\": null,\n",
            "      \"params\": {\n",
            "        \"learning_rate\": 5.412009190750477e-06,\n",
            "        \"batch_size\": 16,\n",
            "        \"num_train_epochs\": 4,\n",
            "        \"warmup_ratio\": 0.09675666141341166,\n",
            "        \"weight_decay\": 0.05200680211778108,\n",
            "        \"gradient_accumulation_steps\": 4,\n",
            "        \"lr_scheduler_type\": \"cosine\",\n",
            "        \"oversampling_ratio\": 0.905344615384884,\n",
            "        \"hidden_dropout_prob\": 0.21957999576221704,\n",
            "        \"attention_probs_dropout_prob\": 0.1921874235023117\n",
            "      },\n",
            "      \"duration_seconds\": 3407.762144\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "--- End of Optuna Optimization Summary Data ---\n",
            "\n",
            "--- Starting Explainable AI (XAI) Analysis with LIME ---\n",
            "Loaded final model and tokenizer from /content/drive/MyDrive/my_electra_multilabel_classifier_results/best_electra_multilabel_model\n",
            "\n",
            "--- XAI Example 1 ---\n",
            "Comment: '\"\n",
            "Welcome!\n",
            "\n",
            "Hello, , and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are a few good links for newcomers:\n",
            "The five pillars of Wikipedia\n",
            "How to edit a page\n",
            "Help pages\n",
            "Tutorial\n",
            "How to write a great article\n",
            "Manual of Style\n",
            "I hope you enjoy editing here and being a Wikipedian! Please sign your name on talk pages using four tildes (~~~~); this will automatically produce your name and the date. If you need help, check out Wikipedia:Questions, ask me on my talk page, or place {{helpme}} on your talk page and someone will show up shortly to answer your questions. Again, welcome!  '''''' (E@) T \"'\n",
            "True Labels: [0 0 0 0 0 0]\n",
            "Model Probabilities: [0. 0. 0. 0. 0. 0.]\n",
            "  Skipping explanation for label 'toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'severe_toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'obscene' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'insult' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Example 2 ---\n",
            "Comment: 'Heads up\n",
            "You're being discussed here, in regards to that Sheree Silver articles for deletion. The creator, Spring12, seems bound and determined to belittle and discount anyone who voted delete.'\n",
            "True Labels: [0 0 0 0 0 0]\n",
            "Model Probabilities: [0. 0. 0. 0. 0. 0.]\n",
            "  Skipping explanation for label 'toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'severe_toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'obscene' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'insult' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Example 3 ---\n",
            "Comment: 'You're an asshole.  Seriously.  I've been  here for three years.  I know edit summaries are encouraged.  But I've  never heard that it is encouraged that we revert articles simply because no edit summary is provided.  That's ridiculous.'\n",
            "True Labels: [1 0 1 0 0 0]\n",
            "Model Probabilities: [1.    0.593 1.    0.001 1.    0.002]\n",
            "\n",
            "  Explanation for label: 'toxic' (True: 1, Predicted Prob: 1.000)\n",
            "[(np.str_('asshole'), 0.549280793994119), (np.str_('ridiculous'), 0.19375430108118313), (np.str_('You'), 0.12985114980260523), (np.str_('no'), 0.06479844562897914), (np.str_('re'), 0.06040016179074532), (np.str_('Seriously'), 0.054604821264122534), (np.str_('But'), -0.0487922973352476), (np.str_('That'), -0.04721873533753866), (np.str_('three'), -0.03743954651666489), (np.str_('summary'), 0.036647007273078756)]\n",
            "\n",
            "  Explanation for label: 'severe_toxic' (True: 0, Predicted Prob: 0.593)\n",
            "[(np.str_('asshole'), 0.26647796612763397), (np.str_('Seriously'), -0.24446966805897602), (np.str_('an'), 0.21437262383295508), (np.str_('it'), 0.11115372154587501), (np.str_('because'), 0.09393212311476809), (np.str_('years'), 0.09193198468220667), (np.str_('know'), 0.07642662794137413), (np.str_('are'), 0.06618174029441068), (np.str_('here'), 0.0593706537418324), (np.str_('You'), 0.05655487261655271)]\n",
            "\n",
            "  Explanation for label: 'obscene' (True: 1, Predicted Prob: 1.000)\n",
            "[(np.str_('asshole'), 0.9871412756704884), (np.str_('That'), 0.0016420336737306548), (np.str_('I'), 0.001542264255795526), (np.str_('Seriously'), 0.0014980613658059799), (np.str_('ridiculous'), 0.0013841414605987002), (np.str_('You'), 0.0010836919681814683), (np.str_('an'), 0.0007983680161620239), (np.str_('three'), 0.000714250477218257), (np.str_('it'), 0.0001960477438570683), (np.str_('articles'), 4.948404808034775e-05)]\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.001 - not a strong prediction or true positive)\n",
            "\n",
            "  Explanation for label: 'insult' (True: 0, Predicted Prob: 1.000)\n",
            "[(np.str_('asshole'), 0.9731508181765193), (np.str_('You'), 0.01415962411473615), (np.str_('an'), 0.013964115676242082), (np.str_('re'), 0.01306861963742278), (np.str_('I'), 0.00842475266594423), (np.str_('ve'), 0.008271574053596553), (np.str_('that'), 0.0057383997051780435), (np.str_('we'), -0.004641307056608886), (np.str_('revert'), -0.003476473095158455), (np.str_('here'), -0.0033618739778942374)]\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.002 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Example 4 ---\n",
            "Comment: '\"\n",
            "Ha, so if I quote only the relevant bits, I'm \"\"selectively quoting\"\"?  Should I have copied and pasted the entire MOS?  Anyway the thing still seems extremely clear to me.  Putting \"\"best known as...\"\" is redundant because the article title shows that, and it also carries the implication that he was known by at least one other name in daily life.  190.44.158.38  \"'\n",
            "True Labels: [0 0 0 0 0 0]\n",
            "Model Probabilities: [0. 0. 0. 0. 0. 0.]\n",
            "  Skipping explanation for label 'toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'severe_toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'obscene' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'insult' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Example 5 ---\n",
            "Comment: '\" \n",
            "(Note: If the above link doesn't work manually add a colon \"\":\"\" to end of address bar)\"'\n",
            "True Labels: [0 0 0 0 0 0]\n",
            "Model Probabilities: [0. 0. 0. 0. 0. 0.]\n",
            "  Skipping explanation for label 'toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'severe_toxic' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'obscene' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'threat' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'insult' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "  Skipping explanation for label 'identity_hate' (True: 0, Predicted Prob: 0.000 - not a strong prediction or true positive)\n",
            "\n",
            "--- XAI Analysis Complete ---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "114osnbSxgawQPkn9FA_edBPLfeV4RnKo",
      "authorship_tag": "ABX9TyNze94vE0rowV6OsZX42ftp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8084e161a9f9444e9f734138bf55a538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4634458a059e4703bc6c18f81ac7dc99",
              "IPY_MODEL_2c6c9bc384e74c4f86864060cb82369f",
              "IPY_MODEL_6af8f0eaf9be4899b676dfb1e831b8d3"
            ],
            "layout": "IPY_MODEL_89fefb4ddbbd40c7a29b454ffcb747c9"
          }
        },
        "4634458a059e4703bc6c18f81ac7dc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e60e5acd804c36a1d36f982d055d70",
            "placeholder": "​",
            "style": "IPY_MODEL_a62966aac43b49b0993f1bfc24a34b10",
            "value": "Best trial: 91. Best value: 0.982574: 100%"
          }
        },
        "2c6c9bc384e74c4f86864060cb82369f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6dc32ff15f431e809b6fe06bc50e4c",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e39fb454de04bb485af2c74f6b591b2",
            "value": 100
          }
        },
        "6af8f0eaf9be4899b676dfb1e831b8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e02fc971cc944b7b71ada6aa96d1690",
            "placeholder": "​",
            "style": "IPY_MODEL_29cb660f961c44229ab613d25ed81ad4",
            "value": " 100/100 [00:03&lt;00:00, 26.58it/s]"
          }
        },
        "89fefb4ddbbd40c7a29b454ffcb747c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e60e5acd804c36a1d36f982d055d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62966aac43b49b0993f1bfc24a34b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c6dc32ff15f431e809b6fe06bc50e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e39fb454de04bb485af2c74f6b591b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e02fc971cc944b7b71ada6aa96d1690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cb660f961c44229ab613d25ed81ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56a40d30e6f34661bd343371dc74d8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d27f60ff84a04a23a3eb3d61b83c7736",
              "IPY_MODEL_57264bae39534fed9f8d11a79aac79e3",
              "IPY_MODEL_307d262e2efc4953b1bfee9f841dc67c"
            ],
            "layout": "IPY_MODEL_2fe412da15074077ba68061bf702e675"
          }
        },
        "d27f60ff84a04a23a3eb3d61b83c7736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_116e1381196243898a8df4bc1dcab8f7",
            "placeholder": "​",
            "style": "IPY_MODEL_4e99001ba5094803b54d7db46c0de9b1",
            "value": "Best trial: 82. Best value: 0.679162: 100%"
          }
        },
        "57264bae39534fed9f8d11a79aac79e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acbebf5fc9e341c79481c3478f9b3af4",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_042567ac1de14eafb17bb6c3783cb0fe",
            "value": 100
          }
        },
        "307d262e2efc4953b1bfee9f841dc67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2869a28d6764839b6b2d59f8c83effb",
            "placeholder": "​",
            "style": "IPY_MODEL_83b3ca11309944a38021ef3221fc1634",
            "value": " 100/100 [00:03&lt;00:00, 26.12it/s]"
          }
        },
        "2fe412da15074077ba68061bf702e675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "116e1381196243898a8df4bc1dcab8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e99001ba5094803b54d7db46c0de9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acbebf5fc9e341c79481c3478f9b3af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "042567ac1de14eafb17bb6c3783cb0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2869a28d6764839b6b2d59f8c83effb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b3ca11309944a38021ef3221fc1634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}